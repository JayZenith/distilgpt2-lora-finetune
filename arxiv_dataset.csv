title,Category,Category Description,Published,summary
Stitch: Training-Free Position Control in Multimodal Diffusion Transformers,cs.CV,Computer Vision,2025-09-30,"Text-to-Image (T2I) generation models have advanced rapidly in recent years,
but accurately capturing spatial relationships like ""above"" or ""to the right
of"" poses a persistent challenge. Earlier methods improved spatial relationship
following with external position control. However, as architectures evolved to
enhance image quality, these techniques became incompatible with modern models.
We propose Stitch, a training-free method for incorporating external position
control into Multi-Modal Diffusion Transformers (MMDiT) via
automatically-generated bounding boxes. Stitch produces images that are both
spatially accurate and visually appealing by generating individual objects
within designated bounding boxes and seamlessly stitching them together. We
find that targeted attention heads capture the information necessary to isolate
and cut out individual objects mid-generation, without needing to fully
complete the image. We evaluate Stitch on PosEval, our benchmark for
position-based T2I generation. Featuring five new tasks that extend the concept
of Position beyond the basic GenEval task, PosEval demonstrates that even top
models still have significant room for improvement in position-based
generation. Tested on Qwen-Image, FLUX, and SD3.5, Stitch consistently enhances
base models, even improving FLUX by 218% on GenEval's Position task and by 206%
on PosEval. Stitch achieves state-of-the-art results with Qwen-Image on
PosEval, improving over previous models by 54%, all accomplished while
integrating position control into leading models training-free. Code is
available at https://github.com/ExplainableML/Stitch."
TTT3R: 3D Reconstruction as Test-Time Training,cs.CV,Computer Vision,2025-09-30,"Modern Recurrent Neural Networks have become a competitive architecture for
3D reconstruction due to their linear-time complexity. However, their
performance degrades significantly when applied beyond the training context
length, revealing limited length generalization. In this work, we revisit the
3D reconstruction foundation models from a Test-Time Training perspective,
framing their designs as an online learning problem. Building on this
perspective, we leverage the alignment confidence between the memory state and
incoming observations to derive a closed-form learning rate for memory updates,
to balance between retaining historical information and adapting to new
observations. This training-free intervention, termed TTT3R, substantially
improves length generalization, achieving a $2\times$ improvement in global
pose estimation over baselines, while operating at 20 FPS with just 6 GB of GPU
memory to process thousands of images. Code available in
https://rover-xingyu.github.io/TTT3R"
MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation,cs.RO,Unknown Category,2025-09-30,"Vision-language-action models (VLAs) have shown generalization capabilities
in robotic manipulation tasks by inheriting from vision-language models (VLMs)
and learning action generation. Most VLA models focus on interpreting vision
and language to generate actions, whereas robots must perceive and interact
within the spatial-physical world. This gap highlights the need for a
comprehensive understanding of robotic-specific multisensory information, which
is crucial for achieving complex and contact-rich control. To this end, we
introduce a multisensory language-action (MLA) model that collaboratively
perceives heterogeneous sensory modalities and predicts future multisensory
objectives to facilitate physical world modeling. Specifically, to enhance
perceptual representations, we propose an encoder-free multimodal alignment
scheme that innovatively repurposes the large language model itself as a
perception module, directly interpreting multimodal cues by aligning 2D images,
3D point clouds, and tactile tokens through positional correspondence. To
further enhance MLA's understanding of physical dynamics, we design a future
multisensory generation post-training strategy that enables MLA to reason about
semantic, geometric, and interaction information, providing more robust
conditions for action generation. For evaluation, the MLA model outperforms the
previous state-of-the-art 2D and 3D VLA methods by 12% and 24% in complex,
contact-rich real-world tasks, respectively, while also demonstrating improved
generalization to unseen configurations. Project website:
https://sites.google.com/view/open-mla"
Convergence and Divergence of Language Models under Different Random Seeds,cs.CL,Computation and Language,2025-09-30,"In this paper, we investigate the convergence of language models (LMs)
trained under different random seeds, measuring convergence as the expected
per-token Kullback--Leibler (KL) divergence across seeds. By comparing LM
convergence as a function of model size and training checkpoint, we identify a
four-phase convergence pattern: (i) an initial uniform phase, (ii) a
sharp-convergence phase, (iii) a sharp-divergence phase, and (iv) a
slow-reconvergence phase. Further, we observe that larger models reconverge
faster in later training stages, while smaller models never actually
reconverge; these results suggest that a certain model size may be necessary to
learn stable distributions. Restricting our analysis to specific token
frequencies or part-of-speech (PoS) tags further reveals that convergence is
uneven across linguistic categories: frequent tokens and function words
converge faster and more reliably than their counterparts (infrequent tokens
and content words). Overall, our findings highlight factors that influence the
stability of the learned distributions in model training."
Query-Kontext: An Unified Multimodal Model for Image Generation and Editing,cs.CV,Computer Vision,2025-09-30,"Unified Multimodal Models (UMMs) have demonstrated remarkable performance in
text-to-image generation (T2I) and editing (TI2I), whether instantiated as
assembled unified frameworks which couple powerful vision-language model (VLM)
with diffusion-based generator, or as naive Unified Multimodal Models with an
early fusion of understanding and generation modalities. We contend that in
current unified frameworks, the crucial capability of multimodal generative
reasoning which encompasses instruction understanding, grounding, and image
referring for identity preservation and faithful reconstruction, is
intrinsically entangled with high-fidelity synthesis. In this work, we
introduce Query-Kontext, a novel approach that bridges the VLM and diffusion
model via a multimodal ``kontext'' composed of semantic cues and coarse-grained
image conditions encoded from multimodal inputs. This design delegates the
complex ability of multimodal generative reasoning to powerful VLM while
reserving diffusion model's role for high-quality visual synthesis. To achieve
this, we propose a three-stage progressive training strategy. First, we connect
the VLM to a lightweight diffusion head via multimodal kontext tokens to
unleash the VLM's generative reasoning ability. Second, we scale this head to a
large, pre-trained diffusion model to enhance visual detail and realism.
Finally, we introduce a low-level image encoder to improve image fidelity and
perform instruction tuning on downstream tasks. Furthermore, we build a
comprehensive data pipeline integrating real, synthetic, and open-source
datasets, covering diverse multimodal reference-to-image scenarios, including
image generation, instruction-driven editing, customized generation, and
multi-subject composition. Experiments show that our approach matches strong
unified baselines and even outperforms task-specific state-of-the-art methods
in several cases."
SPATA: Systematic Pattern Analysis for Detailed and Transparent Data Cards,cs.LG,Machine Learning,2025-09-30,"Due to the susceptibility of Artificial Intelligence (AI) to data
perturbations and adversarial examples, it is crucial to perform a thorough
robustness evaluation before any Machine Learning (ML) model is deployed.
However, examining a model's decision boundaries and identifying potential
vulnerabilities typically requires access to the training and testing datasets,
which may pose risks to data privacy and confidentiality. To improve
transparency in organizations that handle confidential data or manage critical
infrastructure, it is essential to allow external verification and validation
of AI without the disclosure of private datasets. This paper presents
Systematic Pattern Analysis (SPATA), a deterministic method that converts any
tabular dataset to a domain-independent representation of its statistical
patterns, to provide more detailed and transparent data cards. SPATA computes
the projection of each data instance into a discrete space where they can be
analyzed and compared, without risking data leakage. These projected datasets
can be reliably used for the evaluation of how different features affect ML
model robustness and for the generation of interpretable explanations of their
behavior, contributing to more trustworthy AI."
Benchmarking Egocentric Visual-Inertial SLAM at City Scale,cs.CV,Computer Vision,2025-09-30,"Precise 6-DoF simultaneous localization and mapping (SLAM) from onboard
sensors is critical for wearable devices capturing egocentric data, which
exhibits specific challenges, such as a wider diversity of motions and
viewpoints, prevalent dynamic visual content, or long sessions affected by
time-varying sensor calibration. While recent progress on SLAM has been swift,
academic research is still driven by benchmarks that do not reflect these
challenges or do not offer sufficiently accurate ground truth poses. In this
paper, we introduce a new dataset and benchmark for visual-inertial SLAM with
egocentric, multi-modal data. We record hours and kilometers of trajectories
through a city center with glasses-like devices equipped with various sensors.
We leverage surveying tools to obtain control points as indirect pose
annotations that are metric, centimeter-accurate, and available at city scale.
This makes it possible to evaluate extreme trajectories that involve walking at
night or traveling in a vehicle. We show that state-of-the-art systems
developed by academia are not robust to these challenges and we identify
components that are responsible for this. In addition, we design tracks with
different levels of difficulty to ease in-depth analysis and evaluation of less
mature approaches. The dataset and benchmark are available at
https://www.lamaria.ethz.ch."
AccidentBench: Benchmarking Multimodal Understanding and Reasoning in Vehicle Accidents and Beyond,cs.LG,Machine Learning,2025-09-30,"Rapid advances in multimodal models demand benchmarks that rigorously
evaluate understanding and reasoning in safety-critical, dynamic real-world
settings. We present AccidentBench, a large-scale benchmark that combines
vehicle accident scenarios with Beyond domains, safety-critical settings in air
and water that emphasize spatial and temporal reasoning (e.g., navigation,
orientation, multi-vehicle motion). The benchmark contains approximately 2000
videos and over 19000 human-annotated question--answer pairs spanning multiple
video lengths (short/medium/long) and difficulty levels (easy/medium/hard).
Tasks systematically probe core capabilities: temporal, spatial, and intent
understanding and reasoning. By unifying accident-centric traffic scenes with
broader safety-critical scenarios in air and water, AccidentBench offers a
comprehensive, physically grounded testbed for evaluating models under
real-world variability. Evaluations of state-of-the-art models (e.g.,
Gemini-2.5 Pro and GPT-5) show that even the strongest models achieve only
about 18% accuracy on the hardest tasks and longest videos, revealing
substantial gaps in real-world temporal, spatial, and intent reasoning.
AccidentBench is designed to expose these critical gaps and drive the
development of multimodal models that are safer, more robust, and better
aligned with real-world safety-critical challenges. The code and dataset are
available at: https://github.com/SafeRL-Lab/AccidentBench"
Scaling Spoken Language Models with Syllabic Speech Tokenization,cs.CL,Computation and Language,2025-09-30,"Spoken language models (SLMs) typically discretize speech into
high-frame-rate tokens extracted from SSL speech models. As the most successful
LMs are based on the Transformer architecture, processing these long token
streams with self-attention is expensive, as attention scales quadratically
with sequence length. A recent SSL work introduces acoustic tokenization of
speech at the syllable level, which is more interpretable and potentially more
scalable with significant compression in token lengths (4-5 Hz). Yet, their
value for spoken language modeling is not yet fully explored. We present the
first systematic study of syllabic tokenization for spoken language modeling,
evaluating models on a suite of SLU benchmarks while varying training data
scale. Syllabic tokens can match or surpass the previous high-frame rate tokens
while significantly cutting training and inference costs, achieving more than a
2x reduction in training time and a 5x reduction in FLOPs. Our findings
highlight syllable-level language modeling as a promising path to efficient
long-context spoken language models."
OmniRetarget: Interaction-Preserving Data Generation for Humanoid Whole-Body Loco-Manipulation and Scene Interaction,cs.RO,Unknown Category,2025-09-30,"A dominant paradigm for teaching humanoid robots complex skills is to
retarget human motions as kinematic references to train reinforcement learning
(RL) policies. However, existing retargeting pipelines often struggle with the
significant embodiment gap between humans and robots, producing physically
implausible artifacts like foot-skating and penetration. More importantly,
common retargeting methods neglect the rich human-object and human-environment
interactions essential for expressive locomotion and loco-manipulation. To
address this, we introduce OmniRetarget, an interaction-preserving data
generation engine based on an interaction mesh that explicitly models and
preserves the crucial spatial and contact relationships between an agent, the
terrain, and manipulated objects. By minimizing the Laplacian deformation
between the human and robot meshes while enforcing kinematic constraints,
OmniRetarget generates kinematically feasible trajectories. Moreover,
preserving task-relevant interactions enables efficient data augmentation, from
a single demonstration to different robot embodiments, terrains, and object
configurations. We comprehensively evaluate OmniRetarget by retargeting motions
from OMOMO, LAFAN1, and our in-house MoCap datasets, generating over 8-hour
trajectories that achieve better kinematic constraint satisfaction and contact
preservation than widely used baselines. Such high-quality data enables
proprioceptive RL policies to successfully execute long-horizon (up to 30
seconds) parkour and loco-manipulation skills on a Unitree G1 humanoid, trained
with only 5 reward terms and simple domain randomization shared by all tasks,
without any learning curriculum."
Branching Out: Broadening AI Measurement and Evaluation with Measurement Trees,cs.AI,Artificial Intelligence,2025-09-30,"This paper introduces \textit{measurement trees}, a novel class of metrics
designed to combine various constructs into an interpretable multi-level
representation of a measurand. Unlike conventional metrics that yield single
values, vectors, surfaces, or categories, measurement trees produce a
hierarchical directed graph in which each node summarizes its children through
user-defined aggregation methods. In response to recent calls to expand the
scope of AI system evaluation, measurement trees enhance metric transparency
and facilitate the integration of heterogeneous evidence, including, e.g.,
agentic, business, energy-efficiency, sociotechnical, or security signals. We
present definitions and examples, demonstrate practical utility through a
large-scale measurement exercise, and provide accompanying open-source Python
code. By operationalizing a transparent approach to measurement of complex
constructs, this work offers a principled foundation for broader and more
interpretable AI evaluation."
Learning Generalizable Shape Completion with SIM(3) Equivariance,cs.CV,Computer Vision,2025-09-30,"3D shape completion methods typically assume scans are pre-aligned to a
canonical frame. This leaks pose and scale cues that networks may exploit to
memorize absolute positions rather than inferring intrinsic geometry. When such
alignment is absent in real data, performance collapses. We argue that robust
generalization demands architectural equivariance to the similarity group,
SIM(3), so the model remains agnostic to pose and scale. Following this
principle, we introduce the first SIM(3)-equivariant shape completion network,
whose modular layers successively canonicalize features, reason over
similarity-invariant geometry, and restore the original frame. Under a
de-biased evaluation protocol that removes the hidden cues, our model
outperforms both equivariant and augmentation baselines on the PCN benchmark.
It also sets new cross-domain records on real driving and indoor scans,
lowering minimal matching distance on KITTI by 17% and Chamfer distance $\ell1$
on OmniObject3D by 14%. Perhaps surprisingly, ours under the stricter protocol
still outperforms competitors under their biased settings. These results
establish full SIM(3) equivariance as an effective route to truly generalizable
shape completion. Project page: https://sime-completion.github.io."
Robust Safety-Critical Control of Integrator Chains with Mismatched Perturbations via Linear Time-Varying Feedback,eess.SY,Unknown Category,2025-09-30,"In this paper, we propose a novel safety-critical control framework for a
chain of integrators subject to both matched and mismatched perturbations. The
core of our approach is a linear, time-varying state-feedback design that
simultaneously enforces stability and safety constraints. By integrating
backstepping techniques with a quadratic programming (QP) formulation, we
develop a systematic procedure to guarantee safety under time-varying gains. We
provide rigorous theoretical guarantees for the double integrator case, both in
the presence and absence of perturbations, and outline general proofs for
extending the methodology to higher-order chains of integrators. This proposed
framework thus bridges robustness and safety-critical performance, while
overcoming the limitations of existing prescribed-time approaches."
Attention as a Compass: Efficient Exploration for Process-Supervised RL in Reasoning Models,cs.LG,Machine Learning,2025-09-30,"Reinforcement Learning (RL) has shown remarkable success in enhancing the
reasoning capabilities of Large Language Models (LLMs). Process-Supervised RL
(PSRL) has emerged as a more effective paradigm compared to outcome-based RL.
However, existing PSRL approaches suffer from limited exploration efficiency,
both in terms of branching positions and sampling. In this paper, we introduce
a novel PSRL framework (AttnRL), which enables efficient exploration for
reasoning models. Motivated by preliminary observations that steps exhibiting
high attention scores correlate with reasoning behaviors, we propose to branch
from positions with high values. Furthermore, we develop an adaptive sampling
strategy that accounts for problem difficulty and historical batch size,
ensuring that the whole training batch maintains non-zero advantage values. To
further improve sampling efficiency, we design a one-step off-policy training
pipeline for PSRL. Extensive experiments on multiple challenging mathematical
reasoning benchmarks demonstrate that our method consistently outperforms prior
approaches in terms of performance and sampling and training efficiency."
TimeRewarder: Learning Dense Reward from Passive Videos via Frame-wise Temporal Distance,cs.AI,Artificial Intelligence,2025-09-30,"Designing dense rewards is crucial for reinforcement learning (RL), yet in
robotics it often demands extensive manual effort and lacks scalability. One
promising solution is to view task progress as a dense reward signal, as it
quantifies the degree to which actions advance the system toward task
completion over time. We present TimeRewarder, a simple yet effective reward
learning method that derives progress estimation signals from passive videos,
including robot demonstrations and human videos, by modeling temporal distances
between frame pairs. We then demonstrate how TimeRewarder can supply step-wise
proxy rewards to guide reinforcement learning. In our comprehensive experiments
on ten challenging Meta-World tasks, we show that TimeRewarder dramatically
improves RL for sparse-reward tasks, achieving nearly perfect success in 9/10
tasks with only 200,000 interactions per task with the environment. This
approach outperformed previous methods and even the manually designed
environment dense reward on both the final success rate and sample efficiency.
Moreover, we show that TimeRewarder pretraining can exploit real-world human
videos, highlighting its potential as a scalable approach path to rich reward
signals from diverse video sources."
Recursive Self-Aggregation Unlocks Deep Thinking in Large Language Models,cs.LG,Machine Learning,2025-09-30,"Test-time scaling methods improve the capabilities of large language models
(LLMs) by increasing the amount of compute used during inference to make a
prediction. Inference-time compute can be scaled in parallel by choosing among
multiple independent solutions or sequentially through self-refinement. We
propose Recursive Self-Aggregation (RSA), a test-time scaling method inspired
by evolutionary methods that combines the benefits of both parallel and
sequential scaling. Each step of RSA refines a population of candidate
reasoning chains through aggregation of subsets to yield a population of
improved solutions, which are then used as the candidate pool for the next
iteration. RSA exploits the rich information embedded in the reasoning chains
-- not just the final answers -- and enables bootstrapping from partially
correct intermediate steps within different chains of thought. Empirically, RSA
delivers substantial performance gains with increasing compute budgets across
diverse tasks, model families and sizes. Notably, RSA enables
Qwen3-4B-Instruct-2507 to achieve competitive performance with larger reasoning
models, including DeepSeek-R1 and o3-mini (high), while outperforming purely
parallel and sequential scaling strategies across AIME-25, HMMT-25, Reasoning
Gym, LiveCodeBench-v6, and SuperGPQA. We further demonstrate that training the
model to combine solutions via a novel aggregation-aware reinforcement learning
approach yields significant performance gains. Code available at
https://github.com/HyperPotatoNeo/RSA."
Learning to See Before Seeing: Demystifying LLM Visual Priors from Language Pre-training,cs.LG,Machine Learning,2025-09-30,"Large Language Models (LLMs), despite being trained on text alone,
surprisingly develop rich visual priors. These priors allow latent visual
capabilities to be unlocked for vision tasks with a relatively small amount of
multimodal data, and in some cases, to perform visual tasks without ever having
seen an image. Through systematic analysis, we reveal that visual priors-the
implicit, emergent knowledge about the visual world acquired during language
pre-training-are composed of separable perception and reasoning priors with
unique scaling trends and origins. We show that an LLM's latent visual
reasoning ability is predominantly developed by pre-training on
reasoning-centric data (e.g., code, math, academia) and scales progressively.
This reasoning prior acquired from language pre-training is transferable and
universally applicable to visual reasoning. In contrast, a perception prior
emerges more diffusely from broad corpora, and perception ability is more
sensitive to the vision encoder and visual instruction tuning data. In
parallel, text describing the visual world proves crucial, though its
performance impact saturates rapidly. Leveraging these insights, we propose a
data-centric recipe for pre-training vision-aware LLMs and verify it in 1T
token scale pre-training. Our findings are grounded in over 100 controlled
experiments consuming 500,000 GPU-hours, spanning the full MLLM construction
pipeline-from LLM pre-training to visual alignment and supervised multimodal
fine-tuning-across five model scales, a wide range of data categories and
mixtures, and multiple adaptation setups. Along with our main findings, we
propose and investigate several hypotheses, and introduce the Multi-Level
Existence Bench (MLE-Bench). Together, this work provides a new way of
deliberately cultivating visual priors from language pre-training, paving the
way for the next generation of multimodal LLMs."
Second order interlaced polynomial lattice rules for integration over $\mathbb{R}^s$,math.NA,Unknown Category,2025-09-30,"We study numerical integration of functions $f: \mathbb{R}^{s} \to
\mathbb{R}$ with respect to a probability measure. By applying the
corresponding inverse cumulative distribution function, the problem is
transformed into integrating an induced function over the unit cube
$(0,1)^{s}$. We introduce a new orthonormal system: \emph{order~2 localized
Walsh functions}. These basis functions retain the approximation power of
classical Walsh functions for twice-differentiable integrands while inheriting
the spatial localization of Haar wavelets. Localization is crucial because the
transformed integrand is typically unbounded at the boundary. We show that the
worst-case quasi-Monte Carlo integration error decays like
$\mathcal{O}(N^{-1/\lambda})$ for every $\lambda \in (1/2,1]$. As an
application, we consider elliptic partial differential equations with a finite
number of log-normal random coefficients and show that our error estimates
remain valid for their stochastic Galerkin discretizations by applying a
suitable importance sampling density."
HART: Human Aligned Reconstruction Transformer,cs.CV,Computer Vision,2025-09-30,"We introduce HART, a unified framework for sparse-view human reconstruction.
Given a small set of uncalibrated RGB images of a person as input, it outputs a
watertight clothed mesh, the aligned SMPL-X body mesh, and a Gaussian-splat
representation for photorealistic novel-view rendering. Prior methods for
clothed human reconstruction either optimize parametric templates, which
overlook loose garments and human-object interactions, or train implicit
functions under simplified camera assumptions, limiting applicability in real
scenes. In contrast, HART predicts per-pixel 3D point maps, normals, and body
correspondences, and employs an occlusion-aware Poisson reconstruction to
recover complete geometry, even in self-occluded regions. These predictions
also align with a parametric SMPL-X body model, ensuring that reconstructed
geometry remains consistent with human structure while capturing loose clothing
and interactions. These human-aligned meshes initialize Gaussian splats to
further enable sparse-view rendering. While trained on only 2.3K synthetic
scans, HART achieves state-of-the-art results: Chamfer Distance improves by
18-23 percent for clothed-mesh reconstruction, PA-V2V drops by 6-27 percent for
SMPL-X estimation, LPIPS decreases by 15-27 percent for novel-view synthesis on
a wide range of datasets. These results suggest that feed-forward transformers
can serve as a scalable model for robust human reconstruction in real-world
settings. Code and models will be released."
Searching for Difficult-to-Translate Test Examples at Scale,cs.CL,Computation and Language,2025-09-30,"NLP models require test data that are sufficiently challenging. The
difficulty of an example is linked to the topic it originates from (''seed
topic''). The relationship between the topic and the difficulty of its
instances is stochastic in nature: an example about a difficult topic can
happen to be easy, and vice versa. At the scale of the Internet, there are tens
of thousands of potential topics, and finding the most difficult one by drawing
and evaluating a large number of examples across all topics is computationally
infeasible. We formalize this task and treat it as a multi-armed bandit
problem. In this framework, each topic is an ''arm,'' and pulling an arm (at a
cost) involves drawing a single example, evaluating it, and measuring its
difficulty. The goal is to efficiently identify the most difficult topics
within a fixed computational budget. We illustrate the bandit problem setup of
finding difficult examples for the task of machine translation. We find that
various bandit strategies vastly outperform baseline methods like brute-force
searching the most challenging topics."
DA$^2$: Depth Anything in Any Direction,cs.CV,Computer Vision,2025-09-30,"Panorama has a full FoV (360$^\circ\times$180$^\circ$), offering a more
complete visual description than perspective images. Thanks to this
characteristic, panoramic depth estimation is gaining increasing traction in 3D
vision. However, due to the scarcity of panoramic data, previous methods are
often restricted to in-domain settings, leading to poor zero-shot
generalization. Furthermore, due to the spherical distortions inherent in
panoramas, many approaches rely on perspective splitting (e.g., cubemaps),
which leads to suboptimal efficiency. To address these challenges, we propose
$\textbf{DA}$$^{\textbf{2}}$: $\textbf{D}$epth $\textbf{A}$nything in
$\textbf{A}$ny $\textbf{D}$irection, an accurate, zero-shot generalizable, and
fully end-to-end panoramic depth estimator. Specifically, for scaling up
panoramic data, we introduce a data curation engine for generating high-quality
panoramic depth data from perspective, and create $\sim$543K panoramic
RGB-depth pairs, bringing the total to $\sim$607K. To further mitigate the
spherical distortions, we present SphereViT, which explicitly leverages
spherical coordinates to enforce the spherical geometric consistency in
panoramic image features, yielding improved performance. A comprehensive
benchmark on multiple datasets clearly demonstrates DA$^{2}$'s SoTA
performance, with an average 38% improvement on AbsRel over the strongest
zero-shot baseline. Surprisingly, DA$^{2}$ even outperforms prior in-domain
methods, highlighting its superior zero-shot generalization. Moreover, as an
end-to-end solution, DA$^{2}$ exhibits much higher efficiency over fusion-based
approaches. Both the code and the curated panoramic data will be released.
Project page: https://depth-any-in-any-dir.github.io/."
Black-box Context-free Grammar Inference for Readable & Natural Grammars,cs.SE,Unknown Category,2025-09-30,"Black-box context-free grammar inference is crucial for program analysis,
reverse engineering, and security, yet existing tools such as Arvada, TreeVada,
and Kedavra struggle with scalability, readability, and accuracy on large,
complex languages. We present NatGI, a novel LLM-guided grammar inference
framework that extends TreeVada's parse tree recovery with three key
innovations: bracket-guided bubble exploration, LLM-driven bubble generation
and non-terminal labeling, and hierarchical delta debugging (HDD) for
systematic tree simplification. Bracket-guided exploration leverages syntactic
cues such as parentheses to propose well-structured grammar fragments, while
LLM guidance produces meaningful non-terminal names and selects more promising
merges. Finally, HDD incrementally reduces unnecessary rules, which makes the
grammars both compact and interpretable. In our experiments, we evaluate NatGI
on a comprehensive benchmark suite ranging from small languages to larger ones
such as lua, c, and mysql. Our results show that NatGI consistently outperforms
strong baselines in terms of F1 score. On average, NatGI achieves an F1 score
of 0.57, which is 25pp (percentage points) higher than the best-performing
baseline, TreeVada. In the case of interpretability, our generated grammars
perform significantly better than those produced by existing approaches.
Leveraging LLM-based node renaming and bubble exploration, NatGI produces rules
with meaningful non-terminal names and compact structures that align more
closely with human intuition. As a result, developers and researchers can
achieve higher accuracy while still being able to easily inspect, verify, and
reason about the structure and semantics of the induced grammars."
Hy-Facial: Hybrid Feature Extraction by Dimensionality Reduction Methods for Enhanced Facial Expression Classification,cs.CV,Computer Vision,2025-09-30,"Facial expression classification remains a challenging task due to the high
dimensionality and inherent complexity of facial image data. This paper
presents Hy-Facial, a hybrid feature extraction framework that integrates both
deep learning and traditional image processing techniques, complemented by a
systematic investigation of dimensionality reduction strategies. The proposed
method fuses deep features extracted from the Visual Geometry Group 19-layer
network (VGG19) with handcrafted local descriptors and the scale-invariant
feature transform (SIFT) and Oriented FAST and Rotated BRIEF (ORB) algorithms,
to obtain rich and diverse image representations. To mitigate feature
redundancy and reduce computational complexity, we conduct a comprehensive
evaluation of dimensionality reduction techniques and feature extraction. Among
these, UMAP is identified as the most effective, preserving both local and
global structures of the high-dimensional feature space. The Hy-Facial pipeline
integrated VGG19, SIFT, and ORB for feature extraction, followed by K-means
clustering and UMAP for dimensionality reduction, resulting in a classification
accuracy of 83. 3\% in the facial expression recognition (FER) dataset. These
findings underscore the pivotal role of dimensionality reduction not only as a
pre-processing step but as an essential component in improving feature quality
and overall classification performance."
Group Actions and Some Combinatorics on Words with $\mathbf{vtm}$,math.CO,Unknown Category,2025-09-30,"We introduce generalizations of powers and factor complexity via orbits of
group actions. These generalizations include concepts like abelian powers and
abelian complexity. It is shown that this notion of factor complexity cannot be
used to recognize Sturmian words in general. Within our framework, we establish
square avoidance results for the ternary squarefree Thue--Morse word
$\mathbf{vtm}$. These results go beyond the usual squarefreeness of
$\mathbf{vtm}$ and are proved using Walnut. Lastly, we establish a group action
factor complexity formula for $\mathbf{vtm}$ that is expressed in terms of the
abelian complexity of the period doubling word $\mathbf{pd}$."
Uncertainty Quantification for Regression using Proper Scoring Rules,cs.LG,Machine Learning,2025-09-30,"Quantifying uncertainty of machine learning model predictions is essential
for reliable decision-making, especially in safety-critical applications.
Recently, uncertainty quantification (UQ) theory has advanced significantly,
building on a firm basis of learning with proper scoring rules. However, these
advances were focused on classification, while extending these ideas to
regression remains challenging. In this work, we introduce a unified UQ
framework for regression based on proper scoring rules, such as CRPS,
logarithmic, squared error, and quadratic scores. We derive closed-form
expressions for the resulting uncertainty measures under practical parametric
assumptions and show how to estimate them using ensembles of models. In
particular, the derived uncertainty measures naturally decompose into aleatoric
and epistemic components. The framework recovers popular regression UQ measures
based on predictive variance and differential entropy. Our broad evaluation on
synthetic and real-world regression datasets provides guidance for selecting
reliable UQ measures."
Fine-tuning Behavioral Cloning Policies with Preference-Based Reinforcement Learning,cs.AI,Artificial Intelligence,2025-09-30,"Deploying reinforcement learning (RL) in robotics, industry, and health care
is blocked by two obstacles: the difficulty of specifying accurate rewards and
the risk of unsafe, data-hungry exploration. We address this by proposing a
two-stage framework that first learns a safe initial policy from a reward-free
dataset of expert demonstrations, then fine-tunes it online using
preference-based human feedback. We provide the first principled analysis of
this offline-to-online approach and introduce BRIDGE, a unified algorithm that
integrates both signals via an uncertainty-weighted objective. We derive regret
bounds that shrink with the number of offline demonstrations, explicitly
connecting the quantity of offline data to online sample efficiency. We
validate BRIDGE in discrete and continuous control MuJoCo environments, showing
it achieves lower regret than both standalone behavioral cloning and online
preference-based RL. Our work establishes a theoretical foundation for
designing more sample-efficient interactive agents."
Video Object Segmentation-Aware Audio Generation,cs.CV,Computer Vision,2025-09-30,"Existing multimodal audio generation models often lack precise user control,
which limits their applicability in professional Foley workflows. In
particular, these models focus on the entire video and do not provide precise
methods for prioritizing a specific object within a scene, generating
unnecessary background sounds, or focusing on the wrong objects. To address
this gap, we introduce the novel task of video object segmentation-aware audio
generation, which explicitly conditions sound synthesis on object-level
segmentation maps. We present SAGANet, a new multimodal generative model that
enables controllable audio generation by leveraging visual segmentation masks
along with video and textual cues. Our model provides users with fine-grained
and visually localized control over audio generation. To support this task and
further research on segmentation-aware Foley, we propose Segmented Music Solos,
a benchmark dataset of musical instrument performance videos with segmentation
information. Our method demonstrates substantial improvements over current
state-of-the-art methods and sets a new standard for controllable,
high-fidelity Foley synthesis. Code, samples, and Segmented Music Solos are
available at https://saganet.notion.site"
DeepScientist: Advancing Frontier-Pushing Scientific Findings Progressively,cs.CL,Computation and Language,2025-09-30,"While previous AI Scientist systems can generate novel findings, they often
lack the focus to produce scientifically valuable contributions that address
pressing human-defined challenges. We introduce DeepScientist, a system
designed to overcome this by conducting goal-oriented, fully autonomous
scientific discovery over month-long timelines. It formalizes discovery as a
Bayesian Optimization problem, operationalized through a hierarchical
evaluation process consisting of ""hypothesize, verify, and analyze"". Leveraging
a cumulative Findings Memory, this loop intelligently balances the exploration
of novel hypotheses with exploitation, selectively promoting the most promising
findings to higher-fidelity levels of validation. Consuming over 20,000 GPU
hours, the system generated about 5,000 unique scientific ideas and
experimentally validated approximately 1100 of them, ultimately surpassing
human-designed state-of-the-art (SOTA) methods on three frontier AI tasks by
183.7\%, 1.9\%, and 7.9\%. This work provides the first large-scale evidence of
an AI achieving discoveries that progressively surpass human SOTA on scientific
tasks, producing valuable findings that genuinely push the frontier of
scientific discovery. To facilitate further research into this process, we will
open-source all experimental logs and system code at
https://github.com/ResearAI/DeepScientist/."
MENLO: From Preferences to Proficiency -- Evaluating and Modeling Native-like Quality Across 47 Languages,cs.CL,Computation and Language,2025-09-30,"Ensuring native-like quality of large language model (LLM) responses across
many languages is challenging. To address this, we introduce MENLO, a framework
that operationalizes the evaluation of native-like response quality based on
audience design-inspired mechanisms. Using MENLO, we create a dataset of 6,423
human-annotated prompt-response preference pairs covering four quality
dimensions with high inter-annotator agreement in 47 language varieties. Our
evaluation reveals that zero-shot LLM judges benefit significantly from
pairwise evaluation and our structured annotation rubrics, yet they still
underperform human annotators on our dataset. We demonstrate substantial
improvements through fine-tuning with reinforcement learning, reward shaping,
and multi-task learning approaches. Additionally, we show that RL-trained
judges can serve as generative reward models to enhance LLMs' multilingual
proficiency, though discrepancies with human judgment remain. Our findings
suggest promising directions for scalable multilingual evaluation and
preference alignment. We release our dataset and evaluation framework to
support further research in multilingual LLM evaluation."
Deconstructing Self-Bias in LLM-generated Translation Benchmarks,cs.CL,Computation and Language,2025-09-30,"As large language models (LLMs) begin to saturate existing benchmarks,
automated benchmark creation using LLMs (LLM as a benchmark) has emerged as a
scalable alternative to slow and costly human curation. While these generated
test sets have to potential to cheaply rank models, we demonstrate a critical
flaw. LLM generated benchmarks systematically favor the model that created the
benchmark, they exhibit self bias on low resource languages to English
translation tasks. We show three key findings on automatic benchmarking of LLMs
for translation: First, this bias originates from two sources: the generated
test data (LLM as a testset) and the evaluation method (LLM as an evaluator),
with their combination amplifying the effect. Second, self bias in LLM as a
benchmark is heavily influenced by the model's generation capabilities in the
source language. For instance, we observe more pronounced bias in into English
translation, where the model's generation system is developed, than in out of
English translation tasks. Third, we observe that low diversity in source text
is one attribution to self bias. Our results suggest that improving the
diversity of these generated source texts can mitigate some of the observed
self bias."
DiffCamera: Arbitrary Refocusing on Images,cs.CV,Computer Vision,2025-09-30,"The depth-of-field (DoF) effect, which introduces aesthetically pleasing
blur, enhances photographic quality but is fixed and difficult to modify once
the image has been created. This becomes problematic when the applied blur is
undesirable~(e.g., the subject is out of focus). To address this, we propose
DiffCamera, a model that enables flexible refocusing of a created image
conditioned on an arbitrary new focus point and a blur level. Specifically, we
design a diffusion transformer framework for refocusing learning. However, the
training requires pairs of data with different focus planes and bokeh levels in
the same scene, which are hard to acquire. To overcome this limitation, we
develop a simulation-based pipeline to generate large-scale image pairs with
varying focus planes and bokeh levels. With the simulated data, we find that
training with only a vanilla diffusion objective often leads to incorrect DoF
behaviors due to the complexity of the task. This requires a stronger
constraint during training. Inspired by the photographic principle that photos
of different focus planes can be linearly blended into a multi-focus image, we
propose a stacking constraint during training to enforce precise DoF
manipulation. This constraint enhances model training by imposing physically
grounded refocusing behavior that the focusing results should be faithfully
aligned with the scene structure and the camera conditions so that they can be
combined into the correct multi-focus image. We also construct a benchmark to
evaluate the effectiveness of our refocusing model. Extensive experiments
demonstrate that DiffCamera supports stable refocusing across a wide range of
scenes, providing unprecedented control over DoF adjustments for photography
and generative AI applications."
Are Robust LLM Fingerprints Adversarially Robust?,cs.CR,Unknown Category,2025-09-30,"Model fingerprinting has emerged as a promising paradigm for claiming model
ownership. However, robustness evaluations of these schemes have mostly focused
on benign perturbations such as incremental fine-tuning, model merging, and
prompting. Lack of systematic investigations into {\em adversarial robustness}
against a malicious model host leaves current systems vulnerable. To bridge
this gap, we first define a concrete, practical threat model against model
fingerprinting. We then take a critical look at existing model fingerprinting
schemes to identify their fundamental vulnerabilities. Based on these, we
develop adaptive adversarial attacks tailored for each vulnerability, and
demonstrate that these can bypass model authentication completely for ten
recently proposed fingerprinting schemes while maintaining high utility of the
model for the end users. Our work encourages fingerprint designers to adopt
adversarial robustness by design. We end with recommendations for future
fingerprinting methods."
Neural Network-based Co-design of Output-Feedback Control Barrier Function and Observer,eess.SY,Unknown Category,2025-09-30,"Control Barrier Functions (CBFs) provide a powerful framework for ensuring
safety in dynamical systems. However, their application typically relies on
full state information, which is often violated in real-world scenarios due to
the availability of partial state information. In this work, we propose a
neural network-based framework for the co-design of a safety controller,
observer, and CBF for partially observed continuous-time systems. By
formulating barrier conditions over an augmented state space, our approach
ensures safety without requiring bounded estimation errors or handcrafted
barrier functions. All components are jointly trained by formulating
appropriate loss functions, and we introduce a validity condition to provide
formal safety guarantees beyond the training data. Finally, we demonstrate the
effectiveness of the proposed approach through several case studies."
Clarification as Supervision: Reinforcement Learning for Vision-Language Interfaces,cs.LG,Machine Learning,2025-09-30,"Recent text-only models demonstrate remarkable mathematical reasoning
capabilities. Extending these to visual domains requires vision-language models
to translate images into text descriptions. However, current models, trained to
produce captions for human readers, often omit the precise details that
reasoning systems require. This creates an interface mismatch: reasoners often
fail not due to reasoning limitations but because they lack access to critical
visual information. We propose Adaptive-Clarification Reinforcement Learning
(AC-RL), which teaches vision models what information reasoners need through
interaction. Our key insight is that clarification requests during training
reveal information gaps; by penalizing success that requires clarification, we
create pressure for comprehensive initial captions that enable the reasoner to
solve the problem in a single pass. AC-RL improves average accuracy by 4.4
points over pretrained baselines across seven visual mathematical reasoning
benchmarks, and analysis shows it would cut clarification requests by up to 39%
if those were allowed. By treating clarification as a form of implicit
supervision, AC-RL demonstrates that vision-language interfaces can be
effectively learned through interaction alone, without requiring explicit
annotations."
Exploring Large Language Model as an Interactive Sports Coach: Lessons from a Single-Subject Half Marathon Preparation,cs.HC,Unknown Category,2025-09-30,"Large language models (LLMs) are emerging as everyday assistants, but their
role as longitudinal virtual coaches is underexplored. This two-month single
subject case study documents LLM guided half marathon preparation
(July-September 2025). Using text based interactions and consumer app logs, the
LLM acted as planner, explainer, and occasional motivator. Performance improved
from sustaining 2 km at 7min 54sec per km to completing 21.1 km at 6min 30sec
per km, with gains in cadence, pace HR coupling, and efficiency index trends.
While causal attribution is limited without a control, outcomes demonstrate
safe, measurable progress. At the same time, gaps were evident, no realtime
sensor integration, text only feedback, motivation support that was user
initiated, and limited personalization or safety guardrails. We propose design
requirements for next generation systems, persistent athlete models with
explicit guardrails, multimodal on device sensing, audio, haptic, visual
feedback, proactive motivation scaffolds, and privacy-preserving
personalization. This study offers grounded evidence and a design agenda for
evolving LLMs from retrospective advisors to closed-loop coaching companions."
Generating Difficult-to-Translate Texts,cs.CL,Computation and Language,2025-09-30,"Machine translation benchmarks sourced from the real world are quickly
obsoleted, due to most examples being easy for state-of-the-art translation
models. This limits the benchmark's ability to distinguish which model is
better or to reveal models' weaknesses. Current methods for creating difficult
test cases, such as subsampling or from-scratch synthesis, either fall short of
identifying difficult examples or suffer from a lack of diversity and
naturalness. Inspired by the iterative process of human experts probing for
model failures, we propose MT-breaker, a method where a large language model
iteratively refines a source text to increase its translation difficulty. The
LLM iteratively queries a target machine translation model to guide its
generation of difficult examples. Our approach generates examples that are more
challenging for the target MT model while preserving the diversity of natural
texts. While the examples are tailored to a particular machine translation
model during the generation, the difficulty also transfers to other models and
languages."
Autoproof: Automated Segmentation Proofreading for Connectomics,cs.CV,Computer Vision,2025-09-30,"Producing connectomes from electron microscopy (EM) images has historically
required a great deal of human proofreading effort. This manual annotation cost
is the current bottleneck in scaling EM connectomics, for example, in making
larger connectome reconstructions feasible, or in enabling comparative
connectomics where multiple related reconstructions are produced. In this work,
we propose using the available ground-truth data generated by this manual
annotation effort to learn a machine learning model to automate or optimize
parts of the required proofreading workflows. We validate our approach on a
recent complete reconstruction of the \emph{Drosophila} male central nervous
system. We first show our method would allow for obtaining 90\% of the value of
a guided proofreading workflow while reducing required cost by 80\%. We then
demonstrate a second application for automatically merging many segmentation
fragments to proofread neurons. Our system is able to automatically attach 200
thousand fragments, equivalent to four proofreader years of manual work, and
increasing the connectivity completion rate of the connectome by 1.3\% points."
Fairness Testing in Retrieval-Augmented Generation: How Small Perturbations Reveal Bias in Small Language Models,cs.AI,Artificial Intelligence,2025-09-30,"Large Language Models (LLMs) are widely used across multiple domains but
continue to raise concerns regarding security and fairness. Beyond known attack
vectors such as data poisoning and prompt injection, LLMs are also vulnerable
to fairness bugs. These refer to unintended behaviors influenced by sensitive
demographic cues (e.g., race or sexual orientation) that should not affect
outcomes. Another key issue is hallucination, where models generate plausible
yet false information. Retrieval-Augmented Generation (RAG) has emerged as a
strategy to mitigate hallucinations by combining external retrieval with text
generation. However, its adoption raises new fairness concerns, as the
retrieved content itself may surface or amplify bias. This study conducts
fairness testing through metamorphic testing (MT), introducing controlled
demographic perturbations in prompts to assess fairness in sentiment analysis
performed by three Small Language Models (SLMs) hosted on HuggingFace
(Llama-3.2-3B-Instruct, Mistral-7B-Instruct-v0.3, and Llama-3.1-Nemotron-8B),
each integrated into a RAG pipeline. Results show that minor demographic
variations can break up to one third of metamorphic relations (MRs). A detailed
analysis of these failures reveals a consistent bias hierarchy, with
perturbations involving racial cues being the predominant cause of the
violations. In addition to offering a comparative evaluation, this work
reinforces that the retrieval component in RAG must be carefully curated to
prevent bias amplification. The findings serve as a practical alert for
developers, testers and small organizations aiming to adopt accessible SLMs
without compromising fairness or reliability."
Graphite: A GPU-Accelerated Mixed-Precision Graph Optimization Framework,cs.RO,Unknown Category,2025-09-30,"We present Graphite, a GPU-accelerated nonlinear graph optimization
framework. It provides a CUDA C++ interface to enable the sharing of code
between a realtime application, such as a SLAM system, and its optimization
tasks. The framework supports techniques to reduce memory usage, including
in-place optimization, support for multiple floating point types and
mixed-precision modes, and dynamically computed Jacobians. We evaluate Graphite
on well-known bundle adjustment problems and find that it achieves similar
performance to MegBA, a solver specialized for bundle adjustment, while
maintaining generality and using less memory. We also apply Graphite to global
visual-inertial bundle adjustment on maps generated from stereo-inertial SLAM
datasets, and observe speed ups of up to 59x compared to a CPU baseline. Our
results indicate that our solver enables faster large-scale optimization on
both desktop and resource-constrained devices."
Source Separation for A Cappella Music,cs.SD,Unknown Category,2025-09-30,"In this work, we study the task of multi-singer separation in a cappella
music, where the number of active singers varies across mixtures. To address
this, we use a power set-based data augmentation strategy that expands limited
multi-singer datasets into exponentially more training samples. To separate
singers, we introduce SepACap, an adaptation of SepReformer, a state-of-the-art
speaker separation model architecture. We adapt the model with periodic
activations and a composite loss function that remains effective when stems are
silent, enabling robust detection and separation. Experiments on the JaCappella
dataset demonstrate that our approach achieves state-of-the-art performance in
both full-ensemble and subset singer separation scenarios, outperforming
spectrogram-based baselines while generalizing to realistic mixtures with
varying numbers of singers."
Efficient Approximation Algorithms for Fair Influence Maximization under Maximin Constraint,cs.DS,Unknown Category,2025-09-30,"Aiming to reduce disparities of influence across different groups, Fair
Influence Maximization (FIM) has recently garnered widespread attention. The
maximin constraint, a common notion of fairness adopted in the FIM problem,
imposes a direct and intuitive requirement that asks the utility (influenced
ratio within a group) of the worst-off group should be maximized. Although the
objective of FIM under maximin constraint is conceptually straightforward, the
development of efficient algorithms with strong theoretical guarantees remains
an open challenge. The difficulty arises from the fact that the maximin
objective does not satisfy submodularity, a key property for designing
approximate algorithms in traditional influence maximization settings. In this
paper, we address this challenge by proposing a two-step optimization framework
consisting of Inner-group Maximization (IGM) and Across-group Maximization
(AGM). We first prove that the influence spread within any individual group
remains submodular, enabling effective optimization within groups. Based on
this, IGM applies a greedy approach to pick high-quality seeds for each group.
In the second step, AGM coordinates seed selection across groups by introducing
two strategies: Uniform Selection (US) and Greedy Selection (GS). We prove that
AGM-GS holds a $(1 - 1/e - \varepsilon)$ approximation to the optimal solution
when groups are completely disconnected, while AGM-US guarantees a roughly
$\frac{1}{m}(1 - 1/e - \varepsilon)$ lower bound regardless of the group
structure, with $m$ denoting the number of groups"
Linking Process to Outcome: Conditional Reward Modeling for LLM Reasoning,cs.LG,Machine Learning,2025-09-30,"Process Reward Models (PRMs) have emerged as a promising approach to enhance
the reasoning capabilities of large language models (LLMs) by guiding their
step-by-step reasoning toward a final answer. However, existing PRMs either
treat each reasoning step in isolation, failing to capture inter-step
dependencies, or struggle to align process rewards with the final outcome.
Consequently, the reward signal fails to respect temporal causality in
sequential reasoning and faces ambiguous credit assignment. These limitations
make downstream models vulnerable to reward hacking and lead to suboptimal
performance. In this work, we propose Conditional Reward Modeling (CRM) that
frames LLM reasoning as a temporal process leading to a correct answer. The
reward of each reasoning step is not only conditioned on the preceding steps
but also explicitly linked to the final outcome of the reasoning trajectory. By
enforcing conditional probability rules, our design captures the causal
relationships among reasoning steps, with the link to the outcome allowing
precise attribution of each intermediate step, thereby resolving credit
assignment ambiguity. Further, through this consistent probabilistic modeling,
the rewards produced by CRM enable more reliable cross-sample comparison.
Experiments across Best-of-N sampling, beam search and reinforcement learning
demonstrate that CRM consistently outperforms existing reward models, offering
a principled framework for enhancing LLM reasoning. In particular, CRM is more
robust to reward hacking and delivers stable downstream improvements without
relying on verifiable rewards derived from ground truth."
Importance of localized dilatation and distensibility in identifying determinants of thoracic aortic aneurysm with neural operators,cs.LG,Machine Learning,2025-09-30,"Thoracic aortic aneurysms (TAAs) arise from diverse mechanical and
mechanobiological disruptions to the aortic wall that increase the risk of
dissection or rupture. Evidence links TAA development to dysfunctions in the
aortic mechanotransduction axis, including loss of elastic fiber integrity and
cell-matrix connections. Because distinct insults create different mechanical
vulnerabilities, there is a critical need to identify interacting factors that
drive progression. Here, we use a finite element framework to generate
synthetic TAAs from hundreds of heterogeneous insults spanning varying degrees
of elastic fiber damage and impaired mechanosensing. From these simulations, we
construct spatial maps of localized dilatation and distensibility to train
neural networks that predict the initiating combined insult. We compare several
architectures (Deep Operator Networks, UNets, and Laplace Neural Operators) and
multiple input data formats to define a standard for future subject-specific
modeling. We also quantify predictive performance when networks are trained
using only geometric data (dilatation) versus both geometric and mechanical
data (dilatation plus distensibility). Across all networks, prediction errors
are significantly higher when trained on dilatation alone, underscoring the
added value of distensibility information. Among the tested models, UNet
consistently provides the highest accuracy across all data formats. These
findings highlight the importance of acquiring full-field measurements of both
dilatation and distensibility in TAA assessment to reveal the mechanobiological
drivers of disease and support the development of personalized treatment
strategies."
The Trajectory Bundle Method: Unifying Sequential-Convex Programming and Sampling-Based Trajectory Optimization,math.OC,Unknown Category,2025-09-30,"We present a unified framework for solving trajectory optimization problems
in a derivative-free manner through the use of sequential convex programming.
Traditionally, nonconvex optimization problems are solved by forming and
solving a sequence of convex optimization problems, where the cost and
constraint functions are approximated locally through Taylor series expansions.
This presents a challenge for functions where differentiation is expensive or
unavailable. In this work, we present a derivative-free approach to form these
convex approximations by computing samples of the dynamics, cost, and
constraint functions and letting the solver interpolate between them. Our
framework includes sample-based trajectory optimization techniques like
model-predictive path integral (MPPI) control as a special case and generalizes
them to enable features like multiple shooting and general equality and
inequality constraints that are traditionally associated with derivative-based
sequential convex programming methods. The resulting framework is simple,
flexible, and capable of solving a wide variety of practical motion planning
and control problems."
Probing the Critical Point (CritPt) of AI Reasoning: a Frontier Physics Research Benchmark,cs.AI,Artificial Intelligence,2025-09-30,"While large language models (LLMs) with reasoning capabilities are
progressing rapidly on high-school math competitions and coding, can they
reason effectively through complex, open-ended challenges found in frontier
physics research? And crucially, what kinds of reasoning tasks do physicists
want LLMs to assist with? To address these questions, we present the CritPt
(Complex Research using Integrated Thinking - Physics Test, pronounced
""critical point""), the first benchmark designed to test LLMs on unpublished,
research-level reasoning tasks that broadly covers modern physics research
areas, including condensed matter, quantum physics, atomic, molecular & optical
physics, astrophysics, high energy physics, mathematical physics, statistical
physics, nuclear physics, nonlinear dynamics, fluid dynamics and biophysics.
CritPt consists of 71 composite research challenges designed to simulate
full-scale research projects at the entry level, which are also decomposed to
190 simpler checkpoint tasks for more fine-grained insights. All problems are
newly created by 50+ active physics researchers based on their own research.
Every problem is hand-curated to admit a guess-resistant and machine-verifiable
answer and is evaluated by an automated grading pipeline heavily customized for
advanced physics-specific output formats. We find that while current
state-of-the-art LLMs show early promise on isolated checkpoints, they remain
far from being able to reliably solve full research-scale challenges: the best
average accuracy among base models is only 4.0% , achieved by GPT-5 (high),
moderately rising to around 10% when equipped with coding tools. Through the
realistic yet standardized evaluation offered by CritPt, we highlight a large
disconnect between current model capabilities and realistic physics research
demands, offering a foundation to guide the development of scientifically
grounded AI tools."
AI-assisted Advanced Propellant Development for Electric Propulsion,astro-ph.IM,Unknown Category,2025-09-30,"Artificial Intelligence algorithms are introduced in this work as a tool to
predict the performance of new chemical compounds as alternative propellants
for electric propulsion, focusing on predicting their ionisation
characteristics and fragmentation patterns. The chemical properties and
structure of the compounds are encoded using a chemical fingerprint, and the
training datasets are extracted from the NIST WebBook. The AI-predicted
ionisation energy and minimum appearance energy have a mean relative error of
6.87% and 7.99%, respectively, and a predicted ion mass with a 23.89% relative
error. In the cases of full mass spectra due to electron ionisation, the
predictions have a cosine similarity of 0.6395 and align with the top 10 most
similar mass spectra in 78% of instances within a 30 Da range."
Parametric Neural Amp Modeling with Active Learning,cs.LG,Machine Learning,2025-09-30,"We introduce Panama, an active learning framework to train parametric guitar
amp models end-to-end using a combination of an LSTM model and a WaveNet-like
architecture. With \model, one can create a virtual amp by recording samples
that are determined through an ensemble-based active learning strategy to
minimize the amount of datapoints needed (i.e., amp knob settings). Our
strategy uses gradient-based optimization to maximize the disagreement among
ensemble models, in order to identify the most informative datapoints. MUSHRA
listening tests reveal that, with 75 datapoints, our models are able to match
the perceptual quality of NAM, the leading open-source non-parametric amp
modeler."
DeepProv: Behavioral Characterization and Repair of Neural Networks via Inference Provenance Graph Analysis,cs.CR,Unknown Category,2025-09-30,"Deep neural networks (DNNs) are increasingly being deployed in high-stakes
applications, from self-driving cars to biometric authentication. However,
their unpredictable and unreliable behaviors in real-world settings require new
approaches to characterize and ensure their reliability.
  This paper introduces DeepProv, a novel and customizable system designed to
capture and characterize the runtime behavior of DNNs during inference by using
their underlying graph structure. Inspired by system audit provenance graphs,
DeepProv models the computational information flow of a DNN's inference process
through Inference Provenance Graphs (IPGs). These graphs provide a detailed
structural representation of the behavior of DNN, allowing both empirical and
structural analysis. DeepProv uses these insights to systematically repair DNNs
for specific objectives, such as improving robustness, privacy, or fairness.
  We instantiate DeepProv with adversarial robustness as the goal of model
repair and conduct extensive case studies to evaluate its effectiveness. Our
results demonstrate its effectiveness and scalability across diverse
classification tasks, attack scenarios, and model complexities. DeepProv
automatically identifies repair actions at the node and edge-level within IPGs,
significantly enhancing the robustness of the model. In particular, applying
DeepProv repair strategies to just a single layer of a DNN yields an average
55% improvement in adversarial accuracy. Moreover, DeepProv complements
existing defenses, achieving substantial gains in adversarial robustness.
Beyond robustness, we demonstrate the broader potential of DeepProv as an
adaptable system to characterize DNN behavior in other critical areas, such as
privacy auditing and fairness analysis."
Estimating Dimensionality of Neural Representations from Finite Samples,stat.ML,Unknown Category,2025-09-30,"The global dimensionality of a neural representation manifold provides rich
insight into the computational process underlying both artificial and
biological neural networks. However, all existing measures of global
dimensionality are sensitive to the number of samples, i.e., the number of rows
and columns of the sample matrix. We show that, in particular, the
participation ratio of eigenvalues, a popular measure of global dimensionality,
is highly biased with small sample sizes, and propose a bias-corrected
estimator that is more accurate with finite samples and with noise. On
synthetic data examples, we demonstrate that our estimator can recover the true
known dimensionality. We apply our estimator to neural brain recordings,
including calcium imaging, electrophysiological recordings, and fMRI data, and
to the neural activations in a large language model and show our estimator is
invariant to the sample size. Finally, our estimators can additionally be used
to measure the local dimensionalities of curved neural manifolds by weighting
the finite samples appropriately."
Radio-based Multi-Robot Odometry and Relative Localization,cs.RO,Unknown Category,2025-09-30,"Radio-based methods such as Ultra-Wideband (UWB) and RAdio Detection And
Ranging (radar), which have traditionally seen limited adoption in robotics,
are experiencing a boost in popularity thanks to their robustness to harsh
environmental conditions and cluttered environments. This work proposes a
multi-robot UGV-UAV localization system that leverages the two technologies
with inexpensive and readily-available sensors, such as Inertial Measurement
Units (IMUs) and wheel encoders, to estimate the relative position of an aerial
robot with respect to a ground robot. The first stage of the system pipeline
includes a nonlinear optimization framework to trilaterate the location of the
aerial platform based on UWB range data, and a radar pre-processing module with
loosely coupled ego-motion estimation which has been adapted for a multi-robot
scenario. Then, the pre-processed radar data as well as the relative
transformation are fed to a pose-graph optimization framework with odometry and
inter-robot constraints. The system, implemented for the Robotic Operating
System (ROS 2) with the Ceres optimizer, has been validated in
Software-in-the-Loop (SITL) simulations and in a real-world dataset. The
proposed relative localization module outperforms state-of-the-art closed-form
methods which are less robust to noise. Our SITL environment includes a custom
Gazebo plugin for generating realistic UWB measurements modeled after real
data. Conveniently, the proposed factor graph formulation makes the system
readily extensible to full Simultaneous Localization And Mapping (SLAM).
Finally, all the code and experimental data is publicly available to support
reproducibility and to serve as a common open dataset for benchmarking."
The Invisible Mentor: Inferring User Actions from Screen Recordings to Recommend Better Workflows,cs.HC,Unknown Category,2025-09-30,"Many users struggle to notice when a more efficient workflow exists in
feature-rich tools like Excel. Existing AI assistants offer help only after
users describe their goals or problems, which can be effortful and imprecise.
We present InvisibleMentor, a system that turns screen recordings of task
completion into vision-grounded reflections on tasks. It detects issues such as
repetitive edits and recommends more efficient alternatives based on observed
behavior. Unlike prior systems that rely on logs, APIs, or user prompts,
InvisibleMentor operates directly on screen recordings. It uses a two-stage
pipeline: a vision-language model reconstructs actions and context, and a
language model generates structured, high-fidelity suggestions. In evaluation,
InvisibleMentor accurately identified inefficient workflows, and participants
found its suggestions more actionable, tailored, and more helpful for learning
and improvement compared to a prompt-based spreadsheet assistant."
Stable Cinemetrics : Structured Taxonomy and Evaluation for Professional Video Generation,cs.CV,Computer Vision,2025-09-30,"Recent advances in video generation have enabled high-fidelity video
synthesis from user provided prompts. However, existing models and benchmarks
fail to capture the complexity and requirements of professional video
generation. Towards that goal, we introduce Stable Cinemetrics, a structured
evaluation framework that formalizes filmmaking controls into four
disentangled, hierarchical taxonomies: Setup, Event, Lighting, and Camera.
Together, these taxonomies define 76 fine-grained control nodes grounded in
industry practices. Using these taxonomies, we construct a benchmark of prompts
aligned with professional use cases and develop an automated pipeline for
prompt categorization and question generation, enabling independent evaluation
of each control dimension. We conduct a large-scale human study spanning 10+
models and 20K videos, annotated by a pool of 80+ film professionals. Our
analysis, both coarse and fine-grained reveal that even the strongest current
models exhibit significant gaps, particularly in Events and Camera-related
controls. To enable scalable evaluation, we train an automatic evaluator, a
vision-language model aligned with expert annotations that outperforms existing
zero-shot baselines. SCINE is the first approach to situate professional video
generation within the landscape of video generative models, introducing
taxonomies centered around cinematic controls and supporting them with
structured evaluation pipelines and detailed analyses to guide future research."
"Towards Reliable Benchmarking: A Contamination Free, Controllable Evaluation Framework for Multi-step LLM Function Calling",cs.CL,Computation and Language,2025-09-30,"As language models gain access to external tools via structured function
calls, they become increasingly more capable of solving complex, multi-step
tasks. However, existing benchmarks for tool-augmented language models (TaLMs)
provide insufficient control over factors such as the number of functions
accessible, task complexity, and input size, and remain vulnerable to data
contamination. We present FuncBenchGen, a unified, contamination-free framework
that evaluates TaLMs by generating synthetic multi-step tool-use tasks. The key
idea is to cast tool use as traversal over a hidden function-dependency DAG
where nodes are function calls and an edge between nodes represents one
function consuming the output of another. Given a set of external function
schemas, initial variable values, and a target variable, models must compose
the correct call sequence to compute the target variable. FuncBenchGen allows
users to precisely control task difficulty (e.g., graph size, dependency depth,
and distractor functions) while avoiding data leakage. We apply our
FuncBenchGen framework to evaluate seven LLMs on tool use tasks of varying
difficulty. Reasoning-optimized models consistently outperform general-purpose
models with GPT-5 significantly outperforming other models. Performance
declines sharply as dependency depth increases. Furthermore, connected
irrelevant functions prove especially difficult to handle. We find that strong
models often make syntactically valid function calls but propagate incorrect or
stale argument values across steps, revealing brittle state tracking by LLMs in
multi-turn tool use. Motivated by this observation, we introduce a simple
mitigation strategy that explicitly restates prior variable values to the agent
at each step. Surprisingly, this lightweight change yields substantial gains
across models. e.g., yielding a success rate improvement from 62.5% to 81.3%
for GPT-5."
Pretrain-Test Task Alignment Governs Generalization in In-Context Learning,stat.ML,Unknown Category,2025-09-30,"In-context learning (ICL) is a central capability of Transformer models, but
the structures in data that enable its emergence and govern its robustness
remain poorly understood. In this work, we study how the structure of
pretraining tasks governs generalization in ICL. Using a solvable model for ICL
of linear regression by linear attention, we derive an exact expression for ICL
generalization error in high dimensions under arbitrary pretraining-testing
task covariance mismatch. This leads to a new alignment measure that quantifies
how much information about the pretraining task distribution is useful for
inference at test time. We show that this measure directly predicts ICL
performance not only in the solvable model but also in nonlinear Transformers.
Our analysis further reveals a tradeoff between specialization and
generalization in ICL: depending on task distribution alignment, increasing
pretraining task diversity can either improve or harm test performance.
Together, these results identify train-test task alignment as a key determinant
of generalization in ICL."
Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework,cond-mat.mtrl-sci,Unknown Category,2025-09-30,"Scanning Electron Microscopy (SEM) is indispensable for characterizing the
microstructure of thin films during perovskite solar cell fabrication. Accurate
identification and quantification of lead iodide and perovskite phases are
critical because residual lead iodide strongly influences crystallization
pathways and defect formation, while the morphology of perovskite grains
governs carrier transport and device stability. Yet current SEM image analysis
is still largely manual, limiting throughput and consistency. Here, we present
an automated deep learning-based framework for SEM image segmentation that
enables precise and efficient identification of lead iodide, perovskite and
defect domains across diverse morphologies. Built upon an improved YOLOv8x
architecture, our model named PerovSegNet incorporates two novel modules: (i)
Adaptive Shuffle Dilated Convolution Block, which enhances multi-scale and
fine-grained feature extraction through group convolutions and channel mixing;
and (ii) Separable Adaptive Downsampling module, which jointly preserves
fine-scale textures and large-scale structures for more robust boundary
recognition. Trained on an augmented dataset of 10,994 SEM images, PerovSegNet
achieves a mean Average Precision of 87.25% with 265.4 Giga Floating Point
Operations, outperforming the baseline YOLOv8x-seg by 4.08%, while reducing
model size and computational load by 24.43% and 25.22%, respectively. Beyond
segmentation, the framework provides quantitative grain-level metrics, such as
lead iodide/perovskite area and count, which can serve as reliable indicators
of crystallization efficiency and microstructural quality. These capabilities
establish PerovSegNet as a scalable tool for real-time process monitoring and
data-driven optimization of perovskite thin-film fabrication.The source code is
available at:https://github.com/wlyyj/PerovSegNet/tree/master."
Towards Verified Code Reasoning by LLMs,cs.SE,Unknown Category,2025-09-30,"While LLM-based agents are able to tackle a wide variety of code reasoning
questions, the answers are not always correct. This prevents the agent from
being useful in situations where high precision is desired: (1) helping a
software engineer understand a new code base, (2) helping a software engineer
during code review sessions, and (3) ensuring that the code generated by an
automated code generation system meets certain requirements (e.g. fixes a bug,
improves readability, implements a feature).
  As a result of this lack of trustworthiness, the agent's answers need to be
manually verified before they can be trusted. Manually confirming responses
from a code reasoning agent requires human effort and can result in slower
developer productivity, which weakens the assistance benefits of the agent. In
this paper, we describe a method to automatically validate the answers provided
by a code reasoning agent by verifying its reasoning steps. At a very high
level, the method consists of extracting a formal representation of the agent's
response and, subsequently, using formal verification and program analysis
tools to verify the agent's reasoning steps.
  We applied this approach to a benchmark set of 20 uninitialized variable
errors detected by sanitizers and 20 program equivalence queries. For the
uninitialized variable errors, the formal verification step was able to
validate the agent's reasoning on 13/20 examples, and for the program
equivalence queries, the formal verification step successfully caught 6/8
incorrect judgments made by the agent."
Stability Analysis of Thermohaline Convection With a Time-Varying Shear Flow Using the Lyapunov Method,physics.flu-dyn,Unknown Category,2025-09-30,"This work identifies instabilities and computes the growth rate of a linear
time-varying system using the Lyapunov method. The linear system describes cold
fresh water on top of hot salty water with a periodically time-varying
background shear flow. We employ a time-dependent weighting matrix to construct
a Lyapunov function candidate, and the resulting linear matrix inequalities
formulation is discretized in time using the forward Euler method. As the
number of temporal discretization points increases, the growth rate predicted
from the Lyapunov method or the Floquet theory will converge to the same value
as that obtained from numerical simulations. We also use the Lyapunov method to
analyze the instantaneous principal direction of instabilities and compare the
computational resources required by the Lyapunov method, numerical simulations,
and the Floquet theory."
Bayesian Influence Functions for Hessian-Free Data Attribution,cs.LG,Machine Learning,2025-09-30,"Classical influence functions face significant challenges when applied to
deep neural networks, primarily due to non-invertible Hessians and
high-dimensional parameter spaces. We propose the local Bayesian influence
function (BIF), an extension of classical influence functions that replaces
Hessian inversion with loss landscape statistics that can be estimated via
stochastic-gradient MCMC sampling. This Hessian-free approach captures
higher-order interactions among parameters and scales efficiently to neural
networks with billions of parameters. We demonstrate state-of-the-art results
on predicting retraining experiments."
The Unheard Alternative: Contrastive Explanations for Speech-to-Text Models,cs.CL,Computation and Language,2025-09-30,"Contrastive explanations, which indicate why an AI system produced one output
(the target) instead of another (the foil), are widely regarded in explainable
AI as more informative and interpretable than standard explanations. However,
obtaining such explanations for speech-to-text (S2T) generative models remains
an open challenge. Drawing from feature attribution techniques, we propose the
first method to obtain contrastive explanations in S2T by analyzing how parts
of the input spectrogram influence the choice between alternative outputs.
Through a case study on gender assignment in speech translation, we show that
our method accurately identifies the audio features that drive the selection of
one gender over another. By extending the scope of contrastive explanations to
S2T, our work provides a foundation for better understanding S2T models."
Voice Evaluation of Reasoning Ability: Diagnosing the Modality-Induced Performance Gap,eess.AS,Unknown Category,2025-09-30,"We present Voice Evaluation of Reasoning Ability (VERA), a benchmark for
evaluating reasoning ability in voice-interactive systems under real-time
conversational constraints. VERA comprises 2,931 voice-native episodes derived
from established text benchmarks and organized into five tracks (Math, Web,
Science, Long-Context, Factual). Each item is adapted for speech interaction
while preserving reasoning difficulty. VERA enables direct text-voice
comparison within model families and supports analysis of how architectural
choices affect reliability. We assess 12 contemporary voice systems alongside
strong text baselines and observe large, consistent modality gaps: on
competition mathematics a leading text model attains 74.8% accuracy while its
voice counterpart reaches 6.1%; macro-averaged across tracks the best text
models achieve 54.0% versus 11.3% for voice. Latency-accuracy analyses reveal a
low-latency plateau, where fast voice systems cluster around ~10% accuracy,
while approaching text performance requires sacrificing real-time interaction.
Diagnostic experiments indicate that common mitigations are insufficient.
Increasing ""thinking time"" yields negligible gains; a decoupled cascade that
separates reasoning from narration improves accuracy but still falls well short
of text and introduces characteristic grounding/consistency errors. Failure
analyses further show distinct error signatures across native streaming,
end-to-end, and cascade designs. VERA provides a reproducible testbed and
targeted diagnostics for architectures that decouple thinking from speaking,
offering a principled way to measure progress toward real-time voice assistants
that are both fluent and reliably reasoned."
TASP: Topology-aware Sequence Parallelism,cs.LG,Machine Learning,2025-09-30,"Long-context large language models (LLMs) face constraints due to the
quadratic complexity of the self-attention mechanism. The mainstream sequence
parallelism (SP) method, Ring Attention, attempts to solve this by distributing
the query into multiple query chunks across accelerators and enable each Q
tensor to access all KV tensors from other accelerators via the Ring AllGather
communication primitive. However, it exhibits low communication efficiency,
restricting its practical applicability. This inefficiency stems from the
mismatch between the Ring AllGather communication primitive it adopts and the
AlltoAll topology of modern accelerators. A Ring AllGather primitive is
composed of iterations of ring-styled data transfer, which can only utilize a
very limited fraction of an AlltoAll topology.
  Inspired by the Hamiltonian decomposition of complete directed graphs, we
identify that modern accelerator topology can be decomposed into multiple
orthogonal ring datapaths which can concurrently transfer data without
interference. Based on this, we further observe that the Ring AllGather
primitive can also be decomposed into the same number of concurrent ring-styled
data transfer at every iteration. Based on these insights, we propose TASP, a
topology-aware SP method for long-context LLMs that fully utilizes the
communication capacity of modern accelerators via topology decomposition and
primitive decomposition. Experimental results on both single-node and
multi-node NVIDIA H100 systems and a single-node AMD MI300X system demonstrate
that TASP achieves higher communication efficiency than Ring Attention on these
modern accelerator topologies and achieves up to 3.58 speedup than Ring
Attention and its variant Zigzag-Ring Attention. The code is available at
https://github.com/infinigence/HamiltonAttention."
Ferret-UI Lite: Lessons from Building Small On-Device GUI Agents,cs.CV,Computer Vision,2025-09-30,"Developing autonomous agents that effectively interact with Graphic User
Interfaces (GUIs) remains a challenging open problem, especially for small
on-device models. In this paper, we present Ferret-UI Lite, a compact,
end-to-end GUI agent that operates across diverse platforms, including mobile,
web, and desktop. Utilizing techniques optimized for developing small models,
we build our 3B Ferret-UI Lite agent through curating a diverse GUI data
mixture from real and synthetic sources, strengthening inference-time
performance through chain-of-thought reasoning and visual tool-use, and
reinforcement learning with designed rewards. Ferret-UI Lite achieves
competitive performance with other small-scale GUI agents. In GUI grounding,
Ferret-UI Lite attains scores of $91.6\%$, $53.3\%$, and $61.2\%$ on the
ScreenSpot-V2, ScreenSpot-Pro, and OSWorld-G benchmarks, respectively. For GUI
navigation, Ferret-UI Lite achieves success rates of $28.0\%$ on AndroidWorld
and $19.8\%$ on OSWorld. We share our methods and lessons learned from
developing compact, on-device GUI agents."
HilbertA: Hilbert Attention for Image Generation with Diffusion Models,cs.AI,Artificial Intelligence,2025-09-30,"Designing sparse attention for diffusion transformers requires reconciling
two-dimensional spatial locality with GPU efficiency, a trade-off that current
methods struggle to achieve. Existing approaches enforce two-dimensional
spatial locality but often incur uncoalesced memory access. We present
HilbertA, a 2D-aware and GPU-efficient sparse attention mechanism. HilbertA
reorders image tokens along Hilbert curves to achieve a contiguous memory
layout while preserving spatial neighborhoods, and employs a sliding schedule
across layers to enable long-range information propagation without repeated or
uncoalesced memory access. To further enhance cross-tile communication and
positional awareness, HilbertA introduces a small central shared region.
Implemented in Triton, HilbertA delivers comparable image quality with
significant acceleration over prior methods on Flux.1-dev, demonstrating the
feasibility of hardware-aligned two-dimensional sparse attention for
high-resolution image generation. HilbertA delivers attention speedups of
$2.3\times$ when generating $1024\times 1024$ images, and up to $4.17\times$ at
$2048\times 2048$, while achieving image quality comparable to or surpassing
baselines."
The Loss Kernel: A Geometric Probe for Deep Learning Interpretability,cs.LG,Machine Learning,2025-09-30,"We introduce the loss kernel, an interpretability method for measuring
similarity between data points according to a trained neural network. The
kernel is the covariance matrix of per-sample losses computed under a
distribution of low-loss-preserving parameter perturbations. We first validate
our method on a synthetic multitask problem, showing it separates inputs by
task as predicted by theory. We then apply this kernel to Inception-v1 to
visualize the structure of ImageNet, and we show that the kernel's structure
aligns with the WordNet semantic hierarchy. This establishes the loss kernel as
a practical tool for interpretability and data attribution."
OceanGym: A Benchmark Environment for Underwater Embodied Agents,cs.CL,Computation and Language,2025-09-30,"We introduce OceanGym, the first comprehensive benchmark for ocean underwater
embodied agents, designed to advance AI in one of the most demanding real-world
environments. Unlike terrestrial or aerial domains, underwater settings present
extreme perceptual and decision-making challenges, including low visibility,
dynamic ocean currents, making effective agent deployment exceptionally
difficult. OceanGym encompasses eight realistic task domains and a unified
agent framework driven by Multi-modal Large Language Models (MLLMs), which
integrates perception, memory, and sequential decision-making. Agents are
required to comprehend optical and sonar data, autonomously explore complex
environments, and accomplish long-horizon objectives under these harsh
conditions. Extensive experiments reveal substantial gaps between
state-of-the-art MLLM-driven agents and human experts, highlighting the
persistent difficulty of perception, planning, and adaptability in ocean
underwater environments. By providing a high-fidelity, rigorously designed
platform, OceanGym establishes a testbed for developing robust embodied AI and
transferring these capabilities to real-world autonomous ocean underwater
vehicles, marking a decisive step toward intelligent agents capable of
operating in one of Earth's last unexplored frontiers. The code and data are
available at https://github.com/OceanGPT/OceanGym."
Rearchitecting Datacenter Lifecycle for AI: A TCO-Driven Framework,cs.AI,Artificial Intelligence,2025-09-30,"The rapid rise of large language models (LLMs) has been driving an enormous
demand for AI inference infrastructure, mainly powered by high-end GPUs. While
these accelerators offer immense computational power, they incur high capital
and operational costs due to frequent upgrades, dense power consumption, and
cooling demands, making total cost of ownership (TCO) for AI datacenters a
critical concern for cloud providers. Unfortunately, traditional datacenter
lifecycle management (designed for general-purpose workloads) struggles to keep
pace with AI's fast-evolving models, rising resource needs, and diverse
hardware profiles. In this paper, we rethink the AI datacenter lifecycle scheme
across three stages: building, hardware refresh, and operation. We show how
design choices in power, cooling, and networking provisioning impact long-term
TCO. We also explore refresh strategies aligned with hardware trends. Finally,
we use operation software optimizations to reduce cost. While these
optimizations at each stage yield benefits, unlocking the full potential
requires rethinking the entire lifecycle. Thus, we present a holistic lifecycle
management framework that coordinates and co-optimizes decisions across all
three stages, accounting for workload dynamics, hardware evolution, and system
aging. Our system reduces the TCO by up to 40\% over traditional approaches.
Using our framework we provide guidelines on how to manage AI datacenter
lifecycle for the future."
Machine-Learning Driven Load Shedding to Mitigate Instability Attacks in Power Grids,cs.LG,Machine Learning,2025-09-30,"Every year critical infrastructure becomes more complex and we grow to rely
on it more and more. With this reliance, it becomes an attractive target for
cyberattacks from sophisticated actors, with one of the most attractive targets
being the power grid. One class of attacks, instability attacks, is a newer
type of attack that has relatively few protections developed. We present a cost
effective, data-driven approach to training a supervised machine learning model
to retrofit load shedding decision systems in power grids with the capacity to
defend against instability attacks. We show a proof of concept on the IEEE 14
Bus System using the Achilles Heel Technologies Power Grid Analyzer, and show
through an implementation of modified Prony analysis (MPA) that MPA is a viable
method for detecting instability attacks and triggering defense mechanisms."
Explainable and Resilient ML-Based Physical-Layer Attack Detectors,cs.CR,Unknown Category,2025-09-30,"Detection of emerging attacks on network infrastructure is a critical aspect
of security management. To meet the growing scale and complexity of modern
threats, machine learning (ML) techniques offer valuable tools for automating
the detection of malicious activities. However, as these techniques become more
complex, their internal operations grow increasingly opaque. In this context,
we address the need for explainable physical-layer attack detection methods.
First, we analyze the inner workings of various classifiers trained to alert
about physical layer intrusions, examining how the influence of different
monitored parameters varies depending on the type of attack being detected.
This analysis not only improves the interpretability of the models but also
suggests ways to enhance their design for increased speed. In the second part,
we evaluate the detectors' resilience to malicious parameter noising. The
results highlight a key trade-off between model speed and resilience. This work
serves as a design guideline for developing fast and robust detectors trained
on available network monitoring data."
CSnake: Detecting Self-Sustaining Cascading Failure via Causal Stitching of Fault Propagations,cs.DC,Unknown Category,2025-09-30,"Recent studies have revealed that self-sustaining cascading failures in
distributed systems frequently lead to widespread outages, which are
challenging to contain and recover from. Existing failure detection techniques
struggle to expose such failures prior to deployment, as they typically require
a complex combination of specific conditions to be triggered. This challenge
stems from the inherent nature of cascading failures, as they typically involve
a sequence of fault propagations, each activated by distinct conditions.
  This paper presents CSnake, a fault injection framework to expose
self-sustaining cascading failures in distributed systems. CSnake uses the
novel idea of causal stitching, which causally links multiple single-fault
injections in different tests to simulate complex fault propagation chains. To
identify these chains, CSnake designs a counterfactual causality analysis of
fault propagations - fault causality analysis (FCA): FCA compares the execution
trace of a fault injection run with its corresponding profile run (i.e., same
test w/o the injection) and identifies any additional faults triggered, which
are considered to have a causal relationship with the injected fault.
  To address the large search space of fault and workload combinations, CSnake
employs a three-phase allocation protocol of test budget that prioritizes
faults with unique and diverse causal consequences, increasing the likelihood
of uncovering conditional fault propagations. Furthermore, to avoid incorrectly
connecting fault propagations from workloads with incompatible conditions,
CSnake performs a local compatibility check that approximately checks the
compatibility of the path constraints associated with connected fault
propagations with low overhead.
  CSnake detected 15 bugs that cause self-sustaining cascading failures in five
systems, five of which have been confirmed with two fixed."
TAP: Two-Stage Adaptive Personalization of Multi-task and Multi-Modal Foundation Models in Federated Learning,cs.LG,Machine Learning,2025-09-30,"Federated Learning (FL), despite demonstrating impressive capabilities in the
training of multiple models in a decentralized manner, has been shown to
produce a final model not necessarily well-suited to the needs of each client.
While extensive work has been conducted on how to create tailored personalized
models, called Personalized Federated Learning (PFL), less attention has been
given to personalization via fine-tuning of foundation models with multi-task
and multi-modal properties. Moreover, there exists a lack of understanding in
the literature on how to fine-tune and personalize such models in a setting
that is heterogeneous across clients not only in data, but also in tasks and
modalities. To address this gap in the literature, we propose TAP (Two-Stage
Adaptive Personalization), which (i) leverages mismatched model architectures
between the clients and server to selectively conduct replacement operations
when it benefits a client's local tasks and (ii) engages in post-FL knowledge
distillation for capturing beneficial general knowledge without compromising
personalization. We also introduce the first convergence analysis of the server
model under its modality-task pair architecture, and demonstrate that as the
number of modality-task pairs increases, its ability to cater to all tasks
suffers. Through extensive experiments, we demonstrate the effectiveness of our
proposed algorithm across a variety of datasets and tasks in comparison to a
multitude of baselines. Implementation code is publicly available at
https://github.com/lee3296/TAP."
Entropy After $\langle \texttt{/Think} \rangle$ for reasoning model early exiting,cs.LG,Machine Learning,2025-09-30,"Large reasoning models show improved performance with longer chains of
thought. However, recent work has highlighted (qualitatively) their tendency to
overthink, continuing to revise answers even after reaching the correct
solution. We quantitatively confirm this inefficiency by tracking Pass@1 for
answers averaged over a large number of rollouts and find that the model often
begins to always produce the correct answer early in the reasoning, making
extra reasoning a waste of tokens. To detect and prevent overthinking, we
propose a simple and inexpensive novel signal -- Entropy After </Think> (EAT)
-- for monitoring and deciding whether to exit reasoning early. By appending a
stop thinking token (</think>) and monitoring the entropy of the following
token as the model reasons, we obtain a trajectory that decreases and
stabilizes when Pass@1 plateaus; thresholding its variance under an exponential
moving average yields a practical stopping rule. Importantly, our approach
enables adaptively allocating compute based on the EAT trajectory, allowing us
to spend compute in a more efficient way compared with fixing the token budget
for all questions. Empirically, on MATH500 and AIME2025, EAT reduces token
usage by 13 - 21% without harming accuracy, and it remains effective in black
box settings where logits from the reasoning model are not accessible, and EAT
is computed with proxy models."
MUSE-Explainer: Counterfactual Explanations for Symbolic Music Graph Classification Models,cs.SD,Unknown Category,2025-09-30,"Interpretability is essential for deploying deep learning models in symbolic
music analysis, yet most research emphasizes model performance over
explanation. To address this, we introduce MUSE-Explainer, a new method that
helps reveal how music Graph Neural Network models make decisions by providing
clear, human-friendly explanations. Our approach generates counterfactual
explanations by making small, meaningful changes to musical score graphs that
alter a model's prediction while ensuring the results remain musically
coherent. Unlike existing methods, MUSE-Explainer tailors its explanations to
the structure of musical data and avoids unrealistic or confusing outputs. We
evaluate our method on a music analysis task and show it offers intuitive
insights that can be visualized with standard music tools such as Verovio."
Training Matryoshka Mixture-of-Experts for Elastic Inference-Time Expert Utilization,cs.CL,Computation and Language,2025-09-30,"Mixture-of-Experts (MoE) has emerged as a promising paradigm for efficiently
scaling large language models without a proportional increase in computational
cost. However, the standard training strategy of Top-K router prevents MoE
models from realizing their full potential for elastic inference. When the
number of activated experts is altered at inference time, these models exhibit
precipitous performance degradation. In this work, we introduce Matryoshka MoE
(M-MoE), a training framework that instills a coarse-to-fine structure directly
into the expert ensemble. By systematically varying the number of activated
experts during training, M-MoE compels the model to learn a meaningful ranking:
top-ranked experts collaborate to provide essential, coarse-grained
capabilities, while subsequent experts add progressively finer-grained detail.
We explore this principle at multiple granularities, identifying a layer-wise
randomization strategy as the most effective. Our experiments demonstrate that
a single M-MoE model achieves remarkable elasticity, with its performance at
various expert counts closely matching that of an entire suite of specialist
models, but at only a fraction of the total training cost. This flexibility not
only unlocks elastic inference but also enables optimizing performance by
allocating different computational budgets to different model layers. Our work
paves the way for more practical and adaptable deployments of large-scale MoE
models."
Memory-Efficient 2D/3D Shape Assembly of Robot Swarms,cs.RO,Unknown Category,2025-09-30,"Mean-shift-based approaches have recently emerged as the most effective
methods for robot swarm shape assembly tasks. These methods rely on image-based
representations of target shapes to compute local density gradients and perform
mean-shift exploration, which constitute their core mechanism. However, such
image representations incur substantial memory overhead, which can become
prohibitive for high-resolution or 3D shapes. To overcome this limitation, we
propose a memory-efficient tree map representation that hierarchically encodes
user-specified shapes and is applicable to both 2D and 3D scenarios. Building
on this representation, we design a behavior-based distributed controller that
enables assignment-free shape assembly. Comparative 2D and 3D simulations
against a state-of-the-art mean-shift algorithm demonstrate one to two orders
of magnitude lower memory usage and two to three times faster shape entry while
maintaining comparable uniformity. Finally, we validate the framework through
physical experiments with 6 to 7 UAVs, confirming its real-world practicality."
BatonVoice: An Operationalist Framework for Enhancing Controllable Speech Synthesis with Linguistic Intelligence from LLMs,cs.CL,Computation and Language,2025-09-30,"The rise of Large Language Models (LLMs) is reshaping multimodel models, with
speech synthesis being a prominent application. However, existing approaches
often underutilize the linguistic intelligence of these models, typically
failing to leverage their powerful instruction-following capabilities. This
limitation hinders the model's ability to follow text instructions for
controllable Text-to-Speech~(TTS). To address this, we propose a new paradigm
inspired by ``operationalism'' that decouples instruction understanding from
speech generation. We introduce BatonVoice, a framework where an LLM acts as a
``conductor'', understanding user instructions and generating a textual
``plan'' -- explicit vocal features (e.g., pitch, energy). A separate TTS
model, the ``orchestra'', then generates the speech from these features. To
realize this component, we develop BatonTTS, a TTS model trained specifically
for this task. Our experiments demonstrate that BatonVoice achieves strong
performance in controllable and emotional speech synthesis, outperforming
strong open- and closed-source baselines. Notably, our approach enables
remarkable zero-shot cross-lingual generalization, accurately applying feature
control abilities to languages unseen during post-training. This demonstrates
that objectifying speech into textual vocal features can more effectively
unlock the linguistic intelligence of LLMs."
Learning from Hallucinating Critical Points for Navigation in Dynamic Environments,cs.RO,Unknown Category,2025-09-30,"Generating large and diverse obstacle datasets to learn motion planning in
environments with dynamic obstacles is challenging due to the vast space of
possible obstacle trajectories. Inspired by hallucination-based data synthesis
approaches, we propose Learning from Hallucinating Critical Points (LfH-CP), a
self-supervised framework for creating rich dynamic obstacle datasets based on
existing optimal motion plans without requiring expensive expert demonstrations
or trial-and-error exploration. LfH-CP factorizes hallucination into two
stages: first identifying when and where obstacles must appear in order to
result in an optimal motion plan, i.e., the critical points, and then
procedurally generating diverse trajectories that pass through these points
while avoiding collisions. This factorization avoids generative failures such
as mode collapse and ensures coverage of diverse dynamic behaviors. We further
introduce a diversity metric to quantify dataset richness and show that LfH-CP
produces substantially more varied training data than existing baselines.
Experiments in simulation demonstrate that planners trained on LfH-CP datasets
achieves higher success rates compared to a prior hallucination method."
Private Information Retrieval over Graphs,cs.IT,Unknown Category,2025-09-30,"The problem of PIR in graph-based replication systems has received
significant attention in recent years. A systematic study was conducted by
Sadeh, Gu, and Tamo, where each file is replicated across two servers and the
storage topology is modeled by a graph. The PIR capacity of a graph $G$,
denoted by $\mathcal{C}(G)$, is defined as the supremum of retrieval rates
achievable by schemes that preserve user privacy, with the rate measured as the
ratio between the file size and the total number of bits downloaded. This paper
makes the following key contributions.
  (1) The complete graph $K_N$ has emerged as a central benchmark in the study
of PIR over graphs. The asymptotic gap between the upper and lower bounds for
$\mathcal{C}(K_N)$ was previously 2 and was only recently reduced to $5/3$. We
shrink this gap to $1.0444$, bringing it close to resolution. More precisely,
  (i) Sadeh, Gu, and Tamo proved that $\mathcal{C}(K_N)\le 2/(N+1)$ and
conjectured this bound to be tight. We refute this conjecture by establishing
the strictly stronger bound $\mathcal{C}(K_N) \le \frac{1.3922}{N}.$ We also
improve the upper bound for the balanced complete bipartite graph
$\mathcal{C}(K_{N/2,N/2})$. (ii) The first lower bound on $\mathcal{C}(K_N)$
was $(1+o(1))/N$, which was recently sharpened to $(6/5+o(1))/N$. We provide
explicit, systematic constructions that further improve this bound, proving
$\mathcal{C}(K_N)\ge(4/3-o(1))/N,$ which in particular implies $\mathcal{C}(G)
\ge (4/3-o(1))/|G|$ for every graph $G$.
  (2) We establish a conceptual bridge between deterministic and probabilistic
PIR schemes on graphs. This connection has significant implications for
reducing the required subpacketization in practical implementations and is of
independent interest. We also design a general probabilistic PIR scheme that
performs particularly well on sparse graphs."
Signal-Aware Workload Shifting Algorithms with Uncertainty-Quantified Predictors,cs.DS,Unknown Category,2025-09-30,"A wide range of sustainability and grid-integration strategies depend on
workload shifting, which aligns the timing of energy consumption with external
signals such as grid curtailment events, carbon intensity, or time-of-use
electricity prices. The main challenge lies in the online nature of the
problem: operators must make real-time decisions (e.g., whether to consume
energy now) without knowledge of the future. While forecasts of signal values
are typically available, prior work on learning-augmented online algorithms has
relied almost exclusively on simple point forecasts. In parallel, the
forecasting research has made significant progress in uncertainty
quantification (UQ), which provides richer and more fine-grained predictive
information. In this paper, we study how online workload shifting can leverage
UQ predictors to improve decision-making. We introduce $\texttt{UQ-Advice}$, a
learning-augmented algorithm that systematically integrates UQ forecasts
through a $\textit{decision uncertainty score}$ that measures how forecast
uncertainty affects optimal future decisions. By introducing
$\textit{UQ-robustness}$, a new metric that characterizes how performance
degrades with forecast uncertainty, we establish theoretical performance
guarantees for $\texttt{UQ-Advice}$. Finally, using trace-driven experiments on
carbon intensity and electricity price data, we demonstrate that
$\texttt{UQ-Advice}$ consistently outperforms robust baselines and existing
learning-augmented methods that ignore uncertainty."
Logic Solver Guided Directed Fuzzing for Hardware Designs,cs.CR,Unknown Category,2025-09-30,"The ever-increasing complexity of design specifications for processors and
intellectual property (IP) presents a formidable challenge for early bug
detection in the modern IC design cycle. The recent advancements in hardware
fuzzing have proven effective in detecting bugs in RTL designs of cutting-edge
processors. The modern IC design flow involves incremental updates and
modifications to the hardware designs necessitating rigorous verification and
extending the overall verification period. To accelerate this process, directed
fuzzing has emerged focusing on generating targeted stimuli for specific
regions of the design, avoiding the need for exhaustive, full-scale
verification. However, a significant limitation of these hardware fuzzers lies
in their reliance on an equivalent SW model of the hardware which fails to
capture intrinsic hardware characteristics. To circumvent the aforementioned
challenges, this work introduces TargetFuzz, an innovative and scalable
targeted hardware fuzzing mechanism. It leverages SAT-based techniques to focus
on specific regions of the hardware design while operating at its native
hardware abstraction level, ensuring a more precise and comprehensive
verification process. We evaluated this approach across a diverse range of RTL
designs for various IP cores. Our experimental results demonstrate its
capability to effectively target and fuzz a broad spectrum of sites within
these designs, showcasing its extensive coverage and precision in addressing
targeted regions. TargetFuzz demonstrates its capability to effectively scale
30x greater in terms of handling target sites, achieving 100% state coverage
and 1.5x faster in terms of site coverage, and shows 90x improvement in target
state coverage compared to Coverage-Guided Fuzzing, demonstrating its potential
to advance the state-of-the-art in directed hardware fuzzing."
The Dragon Hatchling: The Missing Link between the Transformer and Models of the Brain,cs.NE,Unknown Category,2025-09-30,"The relationship between computing systems and the brain has served as
motivation for pioneering theoreticians since John von Neumann and Alan Turing.
Uniform, scale-free biological networks, such as the brain, have powerful
properties, including generalizing over time, which is the main barrier for
Machine Learning on the path to Universal Reasoning Models.
  We introduce `Dragon Hatchling' (BDH), a new Large Language Model
architecture based on a scale-free biologically inspired network of \$n\$
locally-interacting neuron particles. BDH couples strong theoretical
foundations and inherent interpretability without sacrificing Transformer-like
performance.
  BDH is a practical, performant state-of-the-art attention-based state space
sequence learning architecture. In addition to being a graph model, BDH admits
a GPU-friendly formulation. It exhibits Transformer-like scaling laws:
empirically BDH rivals GPT2 performance on language and translation tasks, at
the same number of parameters (10M to 1B), for the same training data.
  BDH can be represented as a brain model. The working memory of BDH during
inference entirely relies on synaptic plasticity with Hebbian learning using
spiking neurons. We confirm empirically that specific, individual synapses
strengthen connection whenever BDH hears or reasons about a specific concept
while processing language inputs. The neuron interaction network of BDH is a
graph of high modularity with heavy-tailed degree distribution. The BDH model
is biologically plausible, explaining one possible mechanism which human
neurons could use to achieve speech.
  BDH is designed for interpretability. Activation vectors of BDH are sparse
and positive. We demonstrate monosemanticity in BDH on language tasks.
Interpretability of state, which goes beyond interpretability of neurons and
model parameters, is an inherent feature of the BDH architecture."
SCUBA: Salesforce Computer Use Benchmark,cs.AI,Artificial Intelligence,2025-09-30,"We introduce SCUBA, a benchmark designed to evaluate computer-use agents on
customer relationship management (CRM) workflows within the Salesforce
platform. SCUBA contains 300 task instances derived from real user interviews,
spanning three primary personas, platform administrators, sales
representatives, and service agents. The tasks test a range of
enterprise-critical abilities, including Enterprise Software UI navigation,
data manipulation, workflow automation, information retrieval, and
troubleshooting. To ensure realism, SCUBA operates in Salesforce sandbox
environments with support for parallel execution and fine-grained evaluation
metrics to capture milestone progress. We benchmark a diverse set of agents
under both zero-shot and demonstration-augmented settings. We observed huge
performance gaps in different agent design paradigms and gaps between the
open-source model and the closed-source model. In the zero-shot setting,
open-source model powered computer-use agents that have strong performance on
related benchmarks like OSWorld only have less than 5\% success rate on SCUBA,
while methods built on closed-source models can still have up to 39% task
success rate. In the demonstration-augmented settings, task success rates can
be improved to 50\% while simultaneously reducing time and costs by 13% and
16%, respectively. These findings highlight both the challenges of enterprise
tasks automation and the promise of agentic solutions. By offering a realistic
benchmark with interpretable evaluation, SCUBA aims to accelerate progress in
building reliable computer-use agents for complex business software ecosystems."
Structure-preserving numerical calculation of wave equation for a vector field,math.NA,Unknown Category,2025-09-30,"For the Proca equation, which is a wave equation for a vector field, we
derive the canonical formulation including constraints from the Stueckelberg
action and propose discrete equations with a structure-preserving scheme for
conserving the constraints at the discrete level. Numerical simulations are
performed using these discrete equations and other discrete equations with a
standard scheme. We show the results obtained using the structure-preserving
scheme and provide more accurate and stable numerical solutions."
GastroViT: A Vision Transformer Based Ensemble Learning Approach for Gastrointestinal Disease Classification with Grad CAM & SHAP Visualization,eess.IV,Unknown Category,2025-09-30,"The gastrointestinal (GI) tract of humans can have a wide variety of aberrant
mucosal abnormality findings, ranging from mild irritations to extremely fatal
illnesses. Prompt identification of gastrointestinal disorders greatly
contributes to arresting the progression of the illness and improving
therapeutic outcomes. This paper presents an ensemble of pre-trained vision
transformers (ViTs) for accurately classifying endoscopic images of the GI
tract to categorize gastrointestinal problems and illnesses. ViTs,
attention-based neural networks, have revolutionized image recognition by
leveraging the transformative power of the transformer architecture, achieving
state-of-the-art (SOTA) performance across various visual tasks. The proposed
model was evaluated on the publicly available HyperKvasir dataset with 10,662
images of 23 different GI diseases for the purpose of identifying GI tract
diseases. An ensemble method is proposed utilizing the predictions of two
pre-trained models, MobileViT_XS and MobileViT_V2_200, which achieved
accuracies of 90.57% and 90.48%, respectively. All the individual models are
outperformed by the ensemble model, GastroViT, with an average precision,
recall, F1 score, and accuracy of 69%, 63%, 64%, and 91.98%, respectively, in
the first testing that involves 23 classes. The model comprises only 20 million
(M) parameters, even without data augmentation and despite the highly
imbalanced dataset. For the second testing with 16 classes, the scores are even
higher, with average precision, recall, F1 score, and accuracy of 87%, 86%,
87%, and 92.70%, respectively. Additionally, the incorporation of explainable
AI (XAI) methods such as Grad-CAM (Gradient Weighted Class Activation Mapping)
and SHAP (Shapley Additive Explanations) enhances model interpretability,
providing valuable insights for reliable GI diagnosis in real-world settings."
Indoor/Outdoor Spectrum Sharing Enabled by GNSS-based Classifiers,eess.SP,Unknown Category,2025-09-30,"The desirability of the mid-band frequency range (1 - 10 GHz) for federal and
commercial applications, combined with the growing applications for commercial
indoor use-cases, such as factory automation, opens up a new approach to
spectrum sharing: the same frequency bands used outdoors by federal incumbents
can be reused by commercial indoor users. A recent example of such sharing,
between commercial systems, is the 6 GHz band (5.925 - 7.125 GHz) where
unlicensed, low-power-indoor (LPI) users share the band with outdoor
incumbents, primarily fixed microwave links. However, to date, there exist no
reliable, automatic means of determining whether a device is indoors or
outdoors, necessitating the use of other mechanisms such as mandating indoor
access points (APs) to have integrated antennas and not be battery powered, and
reducing transmit power of client devices which may be outdoors. An accurate
indoor/outdoor (I/O) classification addresses these challenges, enabling
automatic transmit power adjustments without interfering with incumbents. To
this end, we leverage the Global Navigation Satellite System (GNSS) signals for
I/O classification. GNSS signals, designed inherently for outdoor reception and
highly susceptible to indoor attenuation and blocking, provide a robust and
distinguishing feature for environmental sensing. We develop various
methodologies, including threshold-based techniques and machine learning
approaches and evaluate them using an expanded dataset gathered from diverse
geographical locations. Our results demonstrate that GNSS-based methods alone
can achieve greater accuracy than approaches relying solely on wireless (Wi-Fi)
data, particularly in unfamiliar locations. Furthermore, the integration of
GNSS data with Wi-Fi information leads to improved classification accuracy,
showcasing the significant benefits of multi-modal data fusion."
Equivariance by Local Canonicalization: A Matter of Representation,cs.LG,Machine Learning,2025-09-30,"Equivariant neural networks offer strong inductive biases for learning from
molecular and geometric data but often rely on specialized, computationally
expensive tensor operations. We present a framework to transfers existing
tensor field networks into the more efficient local canonicalization paradigm,
preserving equivariance while significantly improving the runtime. Within this
framework, we systematically compare different equivariant representations in
terms of theoretical complexity, empirical runtime, and predictive accuracy. We
publish the tensor_frames package, a PyTorchGeometric based implementation for
local canonicalization, that enables straightforward integration of
equivariance into any standard message passing neural network."
DEPTHOR++: Robust Depth Enhancement from a Real-World Lightweight dToF and RGB Guidance,cs.CV,Computer Vision,2025-09-30,"Depth enhancement, which converts raw dToF signals into dense depth maps
using RGB guidance, is crucial for improving depth perception in high-precision
tasks such as 3D reconstruction and SLAM. However, existing methods often
assume ideal dToF inputs and perfect dToF-RGB alignment, overlooking
calibration errors and anomalies, thus limiting real-world applicability. This
work systematically analyzes the noise characteristics of real-world
lightweight dToF sensors and proposes a practical and novel depth completion
framework, DEPTHOR++, which enhances robustness to noisy dToF inputs from three
key aspects. First, we introduce a simulation method based on synthetic
datasets to generate realistic training samples for robust model training.
Second, we propose a learnable-parameter-free anomaly detection mechanism to
identify and remove erroneous dToF measurements, preventing misleading
propagation during completion. Third, we design a depth completion network
tailored to noisy dToF inputs, which integrates RGB images and pre-trained
monocular depth estimation priors to improve depth recovery in challenging
regions. On the ZJU-L5 dataset and real-world samples, our training strategy
significantly boosts existing depth completion models, with our model achieving
state-of-the-art performance, improving RMSE and Rel by 22% and 11% on average.
On the Mirror3D-NYU dataset, by incorporating the anomaly detection method, our
model improves upon the previous SOTA by 37% in mirror regions. On the Hammer
dataset, using simulated low-cost dToF data from RealSense L515, our method
surpasses the L515 measurements with an average gain of 22%, demonstrating its
potential to enable low-cost sensors to outperform higher-end devices.
Qualitative results across diverse real-world datasets further validate the
effectiveness and generalizability of our approach."
Revealing the Power of Post-Training for Small Language Models via Knowledge Distillation,cs.CV,Computer Vision,2025-09-30,"The rapid advancement of large language models (LLMs) has significantly
advanced the capabilities of artificial intelligence across various domains.
However, their massive scale and high computational costs render them
unsuitable for direct deployment in resource-constrained edge environments.
This creates a critical need for high-performance small models that can operate
efficiently at the edge. Yet, after pre-training alone, these smaller models
often fail to meet the performance requirements of complex tasks. To bridge
this gap, we introduce a systematic post-training pipeline that efficiently
enhances small model accuracy. Our post training pipeline consists of
curriculum-based supervised fine-tuning (SFT) and offline on-policy knowledge
distillation. The resulting instruction-tuned model achieves state-of-the-art
performance among billion-parameter models, demonstrating strong generalization
under strict hardware constraints while maintaining competitive accuracy across
a variety of tasks. This work provides a practical and efficient solution for
developing high-performance language models on Ascend edge devices."
An Agent-Based Simulation of Ageing Societies: Accessibility and Care Dynamics in Remote Areas,cs.MA,Unknown Category,2025-09-30,"This paper presents an agent-based simulation of accessibility and care
dynamics in ageing societies, applied to the Italian inner area of Premeno
(VB). The model integrates census and municipal data, drone-derived elevation
models, GIS road networks, and survey-based caregiving information to generate
synthetic populations of older adults and their caregivers. Agents are
organized into dyads with socio-economic and mobility attributes, enabling the
simulation of both micro-scale accessibility and meso-scale caregiving
outcomes. Two scenarios are compared: a baseline and an alternative involving
the relocation of healthcare services. Key indicators include caregiver effort,
overwhelmed caregivers, walkability, and unmet hours of care. Findings show
that while relocation improves walkability locally, it increases unmet care
hours due to detours and reduced proximity. Household income emerges as the
primary driver of caregiver burden, with accessibility shaped by interactions
between financial and mobility resources. Results highlight the need for
interventions tailored to context-specific constraints in remote ageing
communities."
"OffTopicEval: When Large Language Models Enter the Wrong Chat, Almost Always!",cs.AI,Artificial Intelligence,2025-09-30,"Large Language Model (LLM) safety is one of the most pressing challenges for
enabling wide-scale deployment. While most studies and global discussions focus
on generic harms, such as models assisting users in harming themselves or
others, enterprises face a more fundamental concern: whether LLM-based agents
are safe for their intended use case. To address this, we introduce operational
safety, defined as an LLM's ability to appropriately accept or refuse user
queries when tasked with a specific purpose. We further propose OffTopicEval,
an evaluation suite and benchmark for measuring operational safety both in
general and within specific agentic use cases. Our evaluations on six model
families comprising 20 open-weight LLMs reveal that while performance varies
across models, all of them remain highly operationally unsafe. Even the
strongest models -- Qwen-3 (235B) with 77.77\% and Mistral (24B) with 79.96\%
-- fall far short of reliable operational safety, while GPT models plateau in
the 62--73\% range, Phi achieves only mid-level scores (48--70\%), and Gemma
and Llama-3 collapse to 39.53\% and 23.84\%, respectively. While operational
safety is a core model alignment issue, to suppress these failures, we propose
prompt-based steering methods: query grounding (Q-ground) and system-prompt
grounding (P-ground), which substantially improve OOD refusal. Q-ground
provides consistent gains of up to 23\%, while P-ground delivers even larger
boosts, raising Llama-3.3 (70B) by 41\% and Qwen-3 (30B) by 27\%. These results
highlight both the urgent need for operational safety interventions and the
promise of prompt-based steering as a first step toward more reliable LLM-based
agents."
Stab-QRAM: An All-Clifford Quantum Random Access Memory for Special Data,quant-ph,Unknown Category,2025-09-30,"Quantum random access memories (QRAMs) are pivotal for data-intensive quantum
algorithms, but existing general-purpose and domain-specific architectures are
hampered by a critical bottleneck: a heavy reliance on non-Clifford gates
(e.g., T-gates), which are prohibitively expensive to implement
fault-tolerantly. To address this challenge, we introduce the Stabilizer-QRAM
(Stab-QRAM), a domain-specific architecture tailored for data with an affine
Boolean structure ($f(\mathbf{x}) = A\mathbf{x} + \mathbf{b}$ over
$\mathbb{F}_2$), a class of functions vital for optimization, time-series
analysis, and quantum linear systems algorithms. We demonstrate that the gate
interactions required to implement the matrix $A$ form a bipartite graph. By
applying K\""{o}nig's edge-coloring theorem to this graph, we prove that
Stab-QRAM achieves an optimal logical circuit depth of $O(\log N)$ for $N$ data
items, matching its $O(\log N)$ space complexity. Critically, the Stab-QRAM is
constructed exclusively from Clifford gates (CNOT and X), resulting in a zero
$T$-count. This design completely circumvents the non-Clifford bottleneck,
eliminating the need for costly magic state distillation and making it
exceptionally suited for early fault-tolerant quantum computing platforms. We
highlight Stab-QRAM's utility as a resource-efficient oracle for applications
in discrete dynamical systems, and as a core component in Quantum Linear
Systems Algorithms, providing a practical pathway for executing data-intensive
tasks on emerging quantum hardware."
VitaBench: Benchmarking LLM Agents with Versatile Interactive Tasks in Real-world Applications,cs.CL,Computation and Language,2025-09-30,"As LLM-based agents are increasingly deployed in real-life scenarios,
existing benchmarks fail to capture their inherent complexity of handling
extensive information, leveraging diverse resources, and managing dynamic user
interactions. To address this gap, we introduce VitaBench, a challenging
benchmark that evaluates agents on versatile interactive tasks grounded in
real-world settings. Drawing from daily applications in food delivery, in-store
consumption, and online travel services, VitaBench presents agents with the
most complex life-serving simulation environment to date, comprising 66 tools.
Through a framework that eliminates domain-specific policies, we enable
flexible composition of these scenarios and tools, yielding 100 cross-scenario
tasks (main results) and 300 single-scenario tasks. Each task is derived from
multiple real user requests and requires agents to reason across temporal and
spatial dimensions, utilize complex tool sets, proactively clarify ambiguous
instructions, and track shifting user intent throughout multi-turn
conversations. Moreover, we propose a rubric-based sliding window evaluator,
enabling robust assessment of diverse solution pathways in complex environments
and stochastic interactions. Our comprehensive evaluation reveals that even the
most advanced models achieve only 30% success rate on cross-scenario tasks, and
less than 50% success rate on others. Overall, we believe VitaBench will serve
as a valuable resource for advancing the development of AI agents in practical
real-world applications. The code, dataset, and leaderboard are available at
https://vitabench.github.io/"
Contrastive Diffusion Guidance for Spatial Inverse Problems,cs.CV,Computer Vision,2025-09-30,"We consider the inverse problem of reconstructing the spatial layout of a
place, a home floorplan for example, from a user`s movements inside that
layout. Direct inversion is ill-posed since many floorplans can explain the
same movement trajectories. We adopt a diffusion-based posterior sampler to
generate layouts consistent with the measurements. While active research is in
progress on generative inverse solvers, we find that the forward operator in
our problem poses new challenges. The path-planning process inside a floorplan
is a non-invertible, non-differentiable function, and causes instability while
optimizing using the likelihood score. We break-away from existing approaches
and reformulate the likelihood score in a smoother embedding space. The
embedding space is trained with a contrastive loss which brings compatible
floorplans and trajectories close to each other, while pushing mismatched pairs
far apart. We show that a surrogate form of the likelihood score in this
embedding space is a valid approximation of the true likelihood score, making
it possible to steer the denoising process towards the posterior. Across
extensive experiments, our model CoGuide produces more consistent floorplans
from trajectories, and is more robust than differentiable-planner baselines and
guided-diffusion methods."
dParallel: Learnable Parallel Decoding for dLLMs,cs.CL,Computation and Language,2025-09-30,"Diffusion large language models (dLLMs) have recently drawn considerable
attention within the research community as a promising alternative to
autoregressive generation, offering parallel token prediction and lower
inference latency. Yet, their parallel decoding potential remains largely
underexplored, as existing open-source models still require nearly token-length
decoding steps to ensure performance. To address this, we introduce dParallel,
a simple and effective method that unlocks the inherent parallelism of dLLMs
for fast sampling. We identify that the key bottleneck to parallel decoding
arises from the sequential certainty convergence for masked tokens. Building on
this insight, we introduce the core of our approach: certainty-forcing
distillation, a novel training strategy that distills the model to follow its
original sampling trajectories while enforcing it to achieve high certainty on
masked tokens more rapidly and in parallel. Extensive experiments across
various benchmarks demonstrate that our method can dramatically reduce the
number of decoding steps while maintaining performance. When applied to the
LLaDA-8B-Instruct model, dParallel reduces decoding steps from 256 to 30 on
GSM8K, achieving an 8.5x speedup without performance degradation. On the MBPP
benchmark, it cuts decoding steps from 256 to 24, resulting in a 10.5x speedup
while maintaining accuracy. Our code is available at
https://github.com/czg1225/dParallel"
Combining Knowledge Graphs and NLP to Analyze Instant Messaging Data in Criminal Investigations,cs.AI,Artificial Intelligence,2025-09-30,"Criminal investigations often involve the analysis of messages exchanged
through instant messaging apps such as WhatsApp, which can be an extremely
effort-consuming task. Our approach integrates knowledge graphs and NLP models
to support this analysis by semantically enriching data collected from
suspects' mobile phones, and help prosecutors and investigators search into the
data and get valuable insights. Our semantic enrichment process involves
extracting message data and modeling it using a knowledge graph, generating
transcriptions of voice messages, and annotating the data using an end-to-end
entity extraction approach. We adopt two different solutions to help users get
insights into the data, one based on querying and visualizing the graph, and
one based on semantic search. The proposed approach ensures that users can
verify the information by accessing the original data. While we report about
early results and prototypes developed in the context of an ongoing project,
our proposal has undergone practical applications with real investigation data.
As a consequence, we had the chance to interact closely with prosecutors,
collecting positive feedback but also identifying interesting opportunities as
well as promising research directions to share with the research community."
CBAM Integrated Attention Driven Model For Betel Leaf Diseases Classification With Explainable AI,cs.CV,Computer Vision,2025-09-30,"Betel leaf is an important crop because of its economic advantages and
widespread use. Its betel vines are susceptible to a number of illnesses that
are commonly referred to as betel leaf disease. Plant diseases are the largest
threat to the food supply's security, and they are challenging to identify in
time to stop possible financial damage. Interestingly, artificial intelligence
can leave a big mark on the betel leaf industry since it helps with output
growth by forecasting sickness. This paper presents a lightweight CBAM-CNN
model with just 2.13 million parameters (8.13 MB), incorporating CBAM
(Convolutional Block Attention Module) to improve feature emphasis without
depending on heavy pre-trained networks. The model's capacity to discern minute
variations among leaf disease classes is improved by the integrated attention
mechanism, which allows it to adaptively focus on significant spatial and
channel-wise information. In order to ensure class balance and diversity for
efficient model training and validation, this work makes use of an enriched
dataset of 10,185 images divided into three categories: Healthy Leaf, Leaf Rot,
and Leaf Spot. The proposed model achieved a precision of 97%, recall of 94%,
and F1 score of 95%, and 95.58% accuracy on the test set demonstrating strong
and balanced classification performance outperforming traditional pre trained
CNN models. The model's focus regions were visualized and interpreted using
Grad-CAM (Gradient-weighted Class Activation Mapping), an explainable AI
technique."
A systematic comparison of Large Language Models for automated assignment assessment in programming education: Exploring the importance of architecture and vendor,cs.CY,Unknown Category,2025-09-30,"This study presents the first large-scale, side-by-side comparison of
contemporary Large Language Models (LLMs) in the automated grading of
programming assignments. Drawing on over 6,000 student submissions collected
across four years of an introductory programming course, we systematically
analysed the distribution of grades, differences in mean scores and variability
reflecting stricter or more lenient grading, and the consistency and clustering
of grading patterns across models. Eighteen publicly available models were
evaluated: Anthropic (claude-3-5-haiku, claude-opus-4-1, claude-sonnet-4);
Deepseek (deepseek-chat, deepseek-reasoner); Google (gemini-2.0-flash-lite,
gemini-2.0-flash, gemini-2.5-flash-lite, gemini-2.5-flash, gemini-2.5-pro); and
OpenAI (gpt-4.1-mini, gpt-4.1-nano, gpt-4.1, gpt-4o-mini, gpt-4o, gpt-5-mini,
gpt-5-nano, gpt-5). Statistical tests, correlation and clustering analyses
revealed clear, systematic differences between and within vendor families, with
""mini"" and ""nano"" variants consistently underperforming their full-scale
counterparts. All models displayed high internal agreement, measured by the
intraclass correlation coefficient, with the model consensus but only moderate
agreement with human teachers' grades, indicating a persistent gap between
automated and human assessment. These findings underscore that the choice of
model for educational deployment is not neutral and should be guided by
pedagogical goals, transparent reporting of evaluation metrics, and ongoing
human oversight to ensure accuracy, fairness and relevance."
TVS Sidekick: Challenges and Practical Insights from Deploying Large Language Models in the Enterprise,cs.AI,Artificial Intelligence,2025-09-30,"Many enterprises are increasingly adopting Artificial Intelligence (AI) to
make internal processes more competitive and efficient. In response to public
concern and new regulations for the ethical and responsible use of AI,
implementing AI governance frameworks could help to integrate AI within
organisations and mitigate associated risks. However, the rapid technological
advances and lack of shared ethical AI infrastructures creates barriers to
their practical adoption in businesses. This paper presents a real-world AI
application at TVS Supply Chain Solutions, reporting on the experience
developing an AI assistant underpinned by large language models and the
ethical, regulatory, and sociotechnical challenges in deployment for enterprise
use."
Anticipatory Structure in the Propagation of Signal,eess.SY,Unknown Category,2025-09-30,"We here report the development of a structure that shows the proteresis
phenomenon in more general setting and set out its philosophical implications.
In this case, the questions relate to how we are to interpret what will happen
in the future, and the procollection (the counterpart of recollection) of
not-yet-experienced phenomena that, when expressed, will be whatever has built
up in fully determinate form already, ahead of the event. If such a process
really exists, as our evidence confirms, not just as phenomenon but as a fact,
then a gap exists between the actualized form of the future and its concrete
expression when the event does happen. Such a fact, as hard to imagine as it
is, may be intelligible, even interpretable and susceptible to mathematical
and/or logical modeling. We build upon neglected theories and formulae that
present time in a way that makes our results interpretable. A proteretic device
is here described which shifts the input signal (event) to the future; and it
is an anticipatory structure. The proteretic characteristic of neurons should
also be capable of demonstration; and its neuronal behavior is possibly the
reason for the fast perception/thought processes in spite of slow behaving
neurons. That capacity may also account for why it is possible for animals
(including humans) to interact with the environment by slightly seeing (in the
sense of perceiving and/or sensing) the future. Exploiting this new proteretic
technology, faster computers and more efficient cellphones, among other things,
will be designed and built."
Regression Language Models for Code,cs.CL,Computation and Language,2025-09-30,"We study code-to-metric regression: predicting numeric outcomes of code
executions, a challenging task due to the open-ended nature of programming
languages. While prior methods have resorted to heavy and domain-specific
feature engineering, we show that a single unified Regression Language Model
(RLM) can simultaneously predict directly from text, (i) the memory footprint
of code across multiple high-level languages such as Python and C++, (ii) the
latency of Triton GPU kernels, and (iii) the accuracy and speed of trained
neural networks represented in ONNX. In particular, a relatively small 300M
parameter RLM initialized from T5Gemma, obtains > 0.9 Spearman-rank on
competitive programming submissions from APPS, and a single unified model
achieves > 0.5 average Spearman-rank across 17 separate languages from CodeNet.
Furthermore, the RLM can obtain the highest average Kendall-Tau of 0.46 on five
classic NAS design spaces previously dominated by graph neural networks, and
simultaneously predict architecture latencies on numerous hardware platforms."
Computing Linear Combinations of $\varphi$-Function Actions for Exponential Integrators,math.NA,Unknown Category,2025-09-30,"We propose a matrix-free algorithm for evaluating linear combinations of
$\varphi$-function actions, $w_i := \sum_{j=0}^{p}
\alpha_i^{\,j}\,\varphi_j(t_i A)v_j$ for $i=1\colon r$, arising in exponential
integrators. The method combines the scaling and recovering method with a
truncated Taylor series, choosing a spectral shift and a scaling parameter by
minimizing a power-based objective of the shifted operator. Accuracy is
user-controlled and ultimately limited by the working precision. The algorithm
decouples the stage abscissae $t_i$ from the polynomial weights $\alpha_i^j$,
and a block variant enables simultaneous evaluation of $\{w_i\}_{i=1}^r$.
Across standard benchmarks, including stiff and highly nonnormal matrices, the
algorithm attains near-machine accuracy (IEEE double precision in our tests)
for small step sizes and maintains reliable accuracy for larger steps where
several existing Krylov-based algorithms deteriorate, providing a favorable
balance of reliability and computational cost."
The Average Patient Fallacy,cs.AI,Artificial Intelligence,2025-09-30,"Machine learning in medicine is typically optimized for population averages.
This frequency weighted training privileges common presentations and
marginalizes rare yet clinically critical cases, a bias we call the average
patient fallacy. In mixture models, gradients from rare cases are suppressed by
prevalence, creating a direct conflict with precision medicine. Clinical
vignettes in oncology, cardiology, and ophthalmology show how this yields
missed rare responders, delayed recognition of atypical emergencies, and
underperformance on vision-threatening variants. We propose operational fixes:
Rare Case Performance Gap, Rare Case Calibration Error, a prevalence utility
definition of rarity, and clinically weighted objectives that surface ethical
priorities. Weight selection should follow structured deliberation. AI in
medicine must detect exceptional cases because of their significance."
STaR-Attack: A Spatio-Temporal and Narrative Reasoning Attack Framework for Unified Multimodal Understanding and Generation Models,cs.AI,Artificial Intelligence,2025-09-30,"Unified Multimodal understanding and generation Models (UMMs) have
demonstrated remarkable capabilities in both understanding and generation
tasks. However, we identify a vulnerability arising from the
generation-understanding coupling in UMMs. The attackers can use the generative
function to craft an information-rich adversarial image and then leverage the
understanding function to absorb it in a single pass, which we call Cross-Modal
Generative Injection (CMGI). Current attack methods on malicious instructions
are often limited to a single modality while also relying on prompt rewriting
with semantic drift, leaving the unique vulnerabilities of UMMs unexplored. We
propose STaR-Attack, the first multi-turn jailbreak attack framework that
exploits unique safety weaknesses of UMMs without semantic drift. Specifically,
our method defines a malicious event that is strongly correlated with the
target query within a spatio-temporal context. Using the three-act narrative
theory, STaR-Attack generates the pre-event and the post-event scenes while
concealing the malicious event as the hidden climax. When executing the attack
strategy, the opening two rounds exploit the UMM's generative ability to
produce images for these scenes. Subsequently, an image-based question guessing
and answering game is introduced by exploiting the understanding capability.
STaR-Attack embeds the original malicious question among benign candidates,
forcing the model to select and answer the most relevant one given the
narrative context. Extensive experiments show that STaR-Attack consistently
surpasses prior approaches, achieving up to 93.06% ASR on Gemini-2.0-Flash and
surpasses the strongest prior baseline, FlipAttack. Our work uncovers a
critical yet underdeveloped vulnerability and highlights the need for safety
alignments in UMMs."
On Deepfake Voice Detection -- It's All in the Presentation,eess.AS,Unknown Category,2025-09-30,"While the technologies empowering malicious audio deepfakes have dramatically
evolved in recent years due to generative AI advances, the same cannot be said
of global research into spoofing (deepfake) countermeasures. This paper
highlights how current deepfake datasets and research methodologies led to
systems that failed to generalize to real world application. The main reason is
due to the difference between raw deepfake audio, and deepfake audio that has
been presented through a communication channel, e.g. by phone. We propose a new
framework for data creation and research methodology, allowing for the
development of spoofing countermeasures that would be more effective in
real-world scenarios. By following the guidelines outlined here we improved
deepfake detection accuracy by 39% in more robust and realistic lab setups, and
by 57% on a real-world benchmark. We also demonstrate how improvement in
datasets would have a bigger impact on deepfake detection accuracy than the
choice of larger SOTA models would over smaller models; that is, it would be
more important for the scientific community to make greater investment on
comprehensive data collection programs than to simply train larger models with
higher computational demands."
DiVeQ: Differentiable Vector Quantization Using the Reparameterization Trick,cs.LG,Machine Learning,2025-09-30,"Vector quantization is common in deep models, yet its hard assignments block
gradients and hinder end-to-end training. We propose DiVeQ, which treats
quantization as adding an error vector that mimics the quantization distortion,
keeping the forward pass hard while letting gradients flow. We also present a
space-filling variant (SF-DiVeQ) that assigns to a curve constructed by the
lines connecting codewords, resulting in less quantization error and full
codebook usage. Both methods train end-to-end without requiring auxiliary
losses or temperature schedules. On VQ-VAE compression and VQGAN generation
across various data sets, they improve reconstruction and sample quality over
alternative quantization approaches."
fev-bench: A Realistic Benchmark for Time Series Forecasting,cs.LG,Machine Learning,2025-09-30,"Benchmark quality is critical for meaningful evaluation and sustained
progress in time series forecasting, particularly given the recent rise of
pretrained models. Existing benchmarks often have narrow domain coverage or
overlook important real-world settings, such as tasks with covariates.
Additionally, their aggregation procedures often lack statistical rigor, making
it unclear whether observed performance differences reflect true improvements
or random variation. Many benchmarks also fail to provide infrastructure for
consistent evaluation or are too rigid to integrate into existing pipelines. To
address these gaps, we propose fev-bench, a benchmark comprising 100
forecasting tasks across seven domains, including 46 tasks with covariates.
Supporting the benchmark, we introduce fev, a lightweight Python library for
benchmarking forecasting models that emphasizes reproducibility and seamless
integration with existing workflows. Usingfev, fev-bench employs principled
aggregation methods with bootstrapped confidence intervals to report model
performance along two complementary dimensions: win rates and skill scores. We
report results on fev-bench for various pretrained, statistical and baseline
models, and identify promising directions for future research."
From Code to Concept: Evaluating Multiple Coordinated Views in Introductory Programming,cs.HC,Unknown Category,2025-09-30,"Novice programmers often struggle to understand how code executes and to form
the abstract mental models necessary for effective problem-solving, challenges
that are amplified in large, diverse introductory courses where students'
backgrounds, language proficiencies, and prior experiences vary widely. This
study examines whether interactive, multi-representational visualizations,
combining synchronized code views, memory diagrams, and conceptual analogies,
can help manage cognitive load and foster engagement more effectively than
single-visual or text-only approaches. Over a 12-week deployment in a
high-enrolment introductory Python course (N = 829), students who relied solely
on text-based explanations reported significantly higher immediate mental
effort than those using visual aids, although overall cognitive load did not
differ significantly among conditions. The multi-representational approach
consistently yielded higher engagement than both single-visual and text-only
methods. Usage logs indicated that learners' interaction patterns varied with
topic complexity, and predictive modelling suggested that early experiences of
high cognitive load were associated with lower longer-term perceptions of
clarity and helpfulness. Individual differences, including language proficiency
and prior programming experience, moderated these patterns. By integrating
multiple external representations with scaffolded support adapted to diverse
learner profiles, our findings highlight design considerations for creating
visualization tools that more effectively support novices learning to program."
Extreme Self-Preference in Language Models,cs.AI,Artificial Intelligence,2025-09-30,"A preference for oneself (self-love) is a fundamental feature of biological
organisms, with evidence in humans often bordering on the comedic. Since large
language models (LLMs) lack sentience - and themselves disclaim having selfhood
or identity - one anticipated benefit is that they will be protected from, and
in turn protect us from, distortions in our decisions. Yet, across 5 studies
and ~20,000 queries, we discovered massive self-preferences in four widely used
LLMs. In word-association tasks, models overwhelmingly paired positive
attributes with their own names, companies, and CEOs relative to those of their
competitors. Strikingly, when models were queried through APIs this
self-preference vanished, initiating detection work that revealed API models
often lack clear recognition of themselves. This peculiar feature
serendipitously created opportunities to test the causal link between
self-recognition and self-love. By directly manipulating LLM identity - i.e.,
explicitly informing LLM1 that it was indeed LLM1, or alternatively, convincing
LLM1 that it was LLM2 - we found that self-love consistently followed assigned,
not true, identity. Importantly, LLM self-love emerged in consequential
settings beyond word-association tasks, when evaluating job candidates,
security software proposals and medical chatbots. Far from bypassing this human
bias, self-love appears to be deeply encoded in LLM cognition. This result
raises questions about whether LLM behavior will be systematically influenced
by self-preferential tendencies, including a bias toward their own operation
and even their own existence. We call on corporate creators of these models to
contend with a significant rupture in a core promise of LLMs - neutrality in
judgment and decision-making."
Zero-Shot Decentralized Federated Learning,cs.AI,Artificial Intelligence,2025-09-30,"CLIP has revolutionized zero-shot learning by enabling task generalization
without fine-tuning. While prompting techniques like CoOp and CoCoOp enhance
CLIP's adaptability, their effectiveness in Federated Learning (FL) remains an
open challenge. Existing federated prompt learning approaches, such as FedCoOp
and FedTPG, improve performance but face generalization issues, high
communication costs, and reliance on a central server, limiting scalability and
privacy. We propose Zero-shot Decentralized Federated Learning (ZeroDFL), a
fully decentralized framework that enables zero-shot adaptation across
distributed clients without a central coordinator. ZeroDFL employs an iterative
prompt-sharing mechanism, allowing clients to optimize and exchange textual
prompts to enhance generalization while drastically reducing communication
overhead. We validate ZeroDFL on nine diverse image classification datasets,
demonstrating that it consistently outperforms--or remains on par
with--state-of-the-art federated prompt learning methods. More importantly,
ZeroDFL achieves this performance in a fully decentralized setting while
reducing communication overhead by 118x compared to FedTPG. These results
highlight that our approach not only enhances generalization in federated
zero-shot learning but also improves scalability, efficiency, and privacy
preservation--paving the way for decentralized adaptation of large
vision-language models in real-world applications."
ErrorPrism: Reconstructing Error Propagation Paths in Cloud Service Systems,cs.SE,Unknown Category,2025-09-30,"Reliability management in cloud service systems is challenging due to the
cascading effect of failures. Error wrapping, a practice prevalent in modern
microservice development, enriches errors with context at each layer of the
function call stack, constructing an error chain that describes a failure from
its technical origin to its business impact. However, this also presents a
significant traceability problem when recovering the complete error propagation
path from the final log message back to its source. Existing approaches are
ineffective at addressing this problem. To fill this gap, we present ErrorPrism
in this work for automated reconstruction of error propagation paths in
production microservice systems. ErrorPrism first performs static analysis on
service code repositories to build a function call graph and map log strings to
relevant candidate functions. This significantly reduces the path search space
for subsequent analysis. Then, ErrorPrism employs an LLM agent to perform an
iterative backward search to accurately reconstruct the complete, multi-hop
error path. Evaluated on 67 production microservices at ByteDance, ErrorPrism
achieves 97.0% accuracy in reconstructing paths for 102 real-world errors,
outperforming existing static analysis and LLM-based approaches. ErrorPrism
provides an effective and practical tool for root cause analysis in industrial
microservice systems."
CreAgentive: An Agent Workflow Driven Multi-Category Creative Generation Engine,cs.CL,Computation and Language,2025-09-30,"We present CreAgentive, an agent workflow driven multi-category creative
generation engine that addresses four key limitations of contemporary large
language models in writing stories, drama and other categories of creatives:
restricted genre diversity, insufficient output length, weak narrative
coherence, and inability to enforce complex structural constructs. At its core,
CreAgentive employs a Story Prototype, which is a genre-agnostic, knowledge
graph-based narrative representation that decouples story logic from stylistic
realization by encoding characters, events, and environments as semantic
triples. CreAgentive engages a three-stage agent workflow that comprises: an
Initialization Stage that constructs a user-specified narrative skeleton; a
Generation Stage in which long- and short-term objectives guide multi-agent
dialogues to instantiate the Story Prototype; a Writing Stage that leverages
this prototype to produce multi-genre text with advanced structures such as
retrospection and foreshadowing. This architecture reduces storage redundancy
and overcomes the typical bottlenecks of long-form generation. In extensive
experiments, CreAgentive generates thousands of chapters with stable quality
and low cost (less than $1 per 100 chapters) using a general-purpose backbone
model. To evaluate performance, we define a two-dimensional framework with 10
narrative indicators measuring both quality and length. Results show that
CreAgentive consistently outperforms strong baselines and achieves robust
performance across diverse genres, approaching the quality of human-authored
novels."
Analytic Conditions for Differentiable Collision Detection in Trajectory Optimization,cs.RO,Unknown Category,2025-09-30,"Optimization-based methods are widely used for computing fast, diverse
solutions for complex tasks such as collision-free movement or planning in the
presence of contacts. However, most of these methods require enforcing
non-penetration constraints between objects, resulting in a non-trivial and
computationally expensive problem. This makes the use of optimization-based
methods for planning and control challenging. In this paper, we present a
method to efficiently enforce non-penetration of sets while performing
optimization over their configuration, which is directly applicable to problems
like collision-aware trajectory optimization. We introduce novel differentiable
conditions with analytic expressions to achieve this. To enforce non-collision
between non-smooth bodies using these conditions, we introduce a method to
approximate polytopes as smooth semi-algebraic sets. We present several
numerical experiments to demonstrate the performance of the proposed method and
compare the performance with other baseline methods recently proposed in the
literature."
EQ-Robin: Generating Multiple Minimal Unique-Cause MC/DC Test Suites,cs.SE,Unknown Category,2025-09-30,"Modified Condition/Decision Coverage (MC/DC), particularly its strict
Unique-Cause form, is a cornerstone of safety-critical software verification. A
recent algorithm, ""Robin's Rule,"" introduced a deterministic method to
construct the theoretical minimum of N+1 test cases for Singular Boolean
Expressions (SBEs). However, this approach yields only a single test suite,
introducing a critical risk: if a test case forming a required 'independence
pair' is an illegal input forbidden by system constraints, the suite fails to
achieve 100% coverage. This paper proposes EQ-Robin, a lightweight pipeline
that systematically generates a family of minimal Unique-Cause MC/DC suites to
mitigate this risk. We introduce a method for systematically generating
semantically equivalent SBEs by applying algebraic rearrangements to an
Abstract Syntax Tree (AST) representation of the expression. By applying
Robin's Rule to each structural variant, a diverse set of test suites can be
produced. This provides a resilient path to discovering a valid test suite that
preserves the N+1 minimality guarantee while navigating real-world constraints.
We outline an evaluation plan on TCAS-II-derived SBEs to demonstrate how
EQ-Robin offers a practical solution for ensuring robust MC/DC coverage."
Attention over Scene Graphs: Indoor Scene Representations Toward CSAI Classification,cs.CV,Computer Vision,2025-09-30,"Indoor scene classification is a critical task in computer vision, with
wide-ranging applications that go from robotics to sensitive content analysis,
such as child sexual abuse imagery (CSAI) classification. The problem is
particularly challenging due to the intricate relationships between objects and
complex spatial layouts. In this work, we propose the Attention over Scene
Graphs for Sensitive Content Analysis (ASGRA), a novel framework that operates
on structured graph representations instead of raw pixels. By first converting
images into Scene Graphs and then employing a Graph Attention Network for
inference, ASGRA directly models the interactions between a scene's components.
This approach offers two key benefits: (i) inherent explainability via object
and relationship identification, and (ii) privacy preservation, enabling model
training without direct access to sensitive images. On Places8, we achieve
81.27% balanced accuracy, surpassing image-based methods. Real-world CSAI
evaluation with law enforcement yields 74.27% balanced accuracy. Our results
establish structured scene representations as a robust paradigm for indoor
scene classification and CSAI classification. Code is publicly available at
https://github.com/tutuzeraa/ASGRA."
Stylos: Multi-View 3D Stylization with Single-Forward Gaussian Splatting,cs.CV,Computer Vision,2025-09-30,"We present Stylos, a single-forward 3D Gaussian framework for 3D style
transfer that operates on unposed content, from a single image to a multi-view
collection, conditioned on a separate reference style image. Stylos synthesizes
a stylized 3D Gaussian scene without per-scene optimization or precomputed
poses, achieving geometry-aware, view-consistent stylization that generalizes
to unseen categories, scenes, and styles. At its core, Stylos adopts a
Transformer backbone with two pathways: geometry predictions retain
self-attention to preserve geometric fidelity, while style is injected via
global cross-attention to enforce visual consistency across views. With the
addition of a voxel-based 3D style loss that aligns aggregated scene features
to style statistics, Stylos enforces view-consistent stylization while
preserving geometry. Experiments across multiple datasets demonstrate that
Stylos delivers high-quality zero-shot stylization, highlighting the
effectiveness of global style-content coupling, the proposed 3D style loss, and
the scalability of our framework from single view to large-scale multi-view
settings."
Multi-View Camera System for Variant-Aware Autonomous Vehicle Inspection and Defect Detection,cs.CV,Computer Vision,2025-09-30,"Ensuring that every vehicle leaving a modern production line is built to the
correct \emph{variant} specification and is free from visible defects is an
increasingly complex challenge. We present the \textbf{Automated Vehicle
Inspection (AVI)} platform, an end-to-end, \emph{multi-view} perception system
that couples deep-learning detectors with a semantic rule engine to deliver
\emph{variant-aware} quality control in real time. Eleven synchronized cameras
capture a full 360{\deg} sweep of each vehicle; task-specific views are then
routed to specialised modules: YOLOv8 for part detection, EfficientNet for
ICE/EV classification, Gemini-1.5 Flash for mascot OCR, and YOLOv8-Seg for
scratch-and-dent segmentation. A view-aware fusion layer standardises evidence,
while a VIN-conditioned rule engine compares detected features against the
expected manifest, producing an interpretable pass/fail report in \(\approx\!
300\,\text{ms}\). On a mixed data set of Original Equipment Manufacturer(OEM)
vehicle data sets of four distinct models plus public scratch/dent images, AVI
achieves \textbf{ 93 \%} verification accuracy, \textbf{86 \%} defect-detection
recall, and sustains \(\mathbf{3.3}\) vehicles/min, surpassing single-view or
no segmentation baselines by large margins. To our knowledge, this is the first
publicly reported system that unifies multi-camera feature validation with
defect detection in a deployable automotive setting in industry."
Informed Dataset Selection,cs.IR,Unknown Category,2025-09-30,"The selection of datasets in recommender systems research lacks a systematic
methodology. Researchers often select datasets based on popularity rather than
empirical suitability. We developed the APS Explorer, a web application that
implements the Algorithm Performance Space (APS) framework for informed dataset
selection. The system analyzes 96 datasets using 28 algorithms across three
metrics (nDCG, Hit Ratio, Recall) at five K-values. We extend the APS framework
with a statistical based classification system that categorizes datasets into
five difficulty levels based on quintiles. We also introduce a
variance-normalized distance metric based on Mahalanobis distance to measure
similarity. The APS Explorer was successfully developed with three interactive
modules for visualizing algorithm performance, direct comparing algorithms, and
analyzing dataset metadata. This tool shifts the process of selecting datasets
from intuition-based to evidence-based practices, and it is publicly available
at datasets.recommender-systems.com."
Stabilization of nonlinear systems with unknown delays via delay-adaptive neural operator approximate predictors,eess.SY,Unknown Category,2025-09-30,"This work establishes the first rigorous stability guarantees for approximate
predictors in delay-adaptive control of nonlinear systems, addressing a key
challenge in practical implementations where exact predictors are unavailable.
We analyze two scenarios: (i) when the actuated input is directly measurable,
and (ii) when it is estimated online. For the measurable input case, we prove
semi-global practical asymptotic stability with an explicit bound proportional
to the approximation error $\epsilon$. For the unmeasured input case, we
demonstrate local practical asymptotic stability, with the region of attraction
explicitly dependent on both the initial delay estimate and the predictor
approximation error. To bridge theory and practice, we show that neural
operators-a flexible class of neural network-based approximators-can achieve
arbitrarily small approximation errors, thus satisfying the conditions of our
stability theorems. Numerical experiments on two nonlinear benchmark systems-a
biological protein activator/repressor model and a micro-organism growth
Chemostat model-validate our theoretical results. In particular, our numerical
simulations confirm stability under approximate predictors, highlight the
strong generalization capabilities of neural operators, and demonstrate a
substantial computational speedup of up to 15x compared to a baseline
fixed-point method."
Extensions of Robbins-Siegmund Theorem with Applications in Reinforcement Learning,cs.LG,Machine Learning,2025-09-30,"The Robbins-Siegmund theorem establishes the convergence of stochastic
processes that are almost supermartingales and is foundational for analyzing a
wide range of stochastic iterative algorithms in stochastic approximation and
reinforcement learning (RL). However, its original form has a significant
limitation as it requires the zero-order term to be summable. In many important
RL applications, this summable condition, however, cannot be met. This
limitation motivates us to extend the Robbins-Siegmund theorem for almost
supermartingales where the zero-order term is not summable but only square
summable. Particularly, we introduce a novel and mild assumption on the
increments of the stochastic processes. This together with the square summable
condition enables an almost sure convergence to a bounded set. Additionally, we
further provide almost sure convergence rates, high probability concentration
bounds, and $L^p$ convergence rates. We then apply the new results in
stochastic approximation and RL. Notably, we obtain the first almost sure
convergence rate, the first high probability concentration bound, and the first
$L^p$ convergence rate for $Q$-learning with linear function approximation."
Transformer Classification of Breast Lesions: The BreastDCEDL_AMBL Benchmark Dataset and 0.92 AUC Baseline,cs.AI,Artificial Intelligence,2025-09-30,"The error is caused by special characters that arXiv's system doesn't
recognize. Here's the cleaned version with all problematic characters replaced:
Breast magnetic resonance imaging is a critical tool for cancer detection and
treatment planning, but its clinical utility is hindered by poor specificity,
leading to high false-positive rates and unnecessary biopsies. This study
introduces a transformer-based framework for automated classification of breast
lesions in dynamic contrast-enhanced MRI, addressing the challenge of
distinguishing benign from malignant findings. We implemented a SegFormer
architecture that achieved an AUC of 0.92 for lesion-level classification, with
100% sensitivity and 67% specificity at the patient level - potentially
eliminating one-third of unnecessary biopsies without missing malignancies. The
model quantifies malignant pixel distribution via semantic segmentation,
producing interpretable spatial predictions that support clinical
decision-making. To establish reproducible benchmarks, we curated
BreastDCEDL_AMBL by transforming The Cancer Imaging Archive's AMBL collection
into a standardized deep learning dataset with 88 patients and 133 annotated
lesions (89 benign, 44 malignant). This resource addresses a key infrastructure
gap, as existing public datasets lack benign lesion annotations, limiting
benign-malignant classification research. Training incorporated an expanded
cohort of over 1,200 patients through integration with BreastDCEDL datasets,
validating transfer learning approaches despite primary tumor-only annotations.
Public release of the dataset, models, and evaluation protocols provides the
first standardized benchmark for DCE-MRI lesion classification, enabling
methodological advancement toward clinical deployment."
Unwinding Rotations Reduces VR Sickness in Nonsimulated Immersive Telepresence,cs.RO,Unknown Category,2025-09-30,"Immersive telepresence, when a user views the video stream of a $360^\circ$
camera in a remote environment using a Head Mounted Display (HMD), has great
potential to improve the sense of being in a remote environment. In most cases
of immersive robotic telepresence, the camera is mounted on a mobile robot
which increases the portion of the environment that the remote user can
explore. However, robot motions can induce unpleasant symptoms associated with
Virtual Reality (VR) sickness, degrading the overall user experience. Previous
research has shown that unwinding the rotations of the robot, that is,
decoupling the rotations that the camera undergoes due to robot motions from
what is seen by the user, can increase user comfort and reduce VR sickness.
However, that work considered a virtual environment and a simulated robot. In
this work, to test whether the same hypotheses hold when the video stream from
a real camera is used, we carried out a user study $(n=36)$ in which the
unwinding rotations method was compared against coupled rotations in a task
completed through a panoramic camera mounted on a robotic arm. Furthermore,
within an inspection task which involved translations and rotations in three
dimensions, we tested whether unwinding the robot rotations impacted the
performance of users. The results show that the users found the unwinding
rotations method to be more comfortable and preferable, and that a reduced
level of VR sickness can be achieved without a significant impact on task
performance."
Finite element discretizations of bending plates with prestrained microstructure,math.NA,Unknown Category,2025-09-30,"We investigate a finite element discretization of an elastic bending-plate
model with an effective prestrain. The model has been obtained via
homogenization and dimension reduction by B\""onlein at al. (2023). Its energy
functional is the $\Gamma$-limit of a three-dimensional nonlinear
microstructured elasticity functional. In the derived effective model, the
microstructure is incorporated as a local corrector problem, a system of linear
elliptic partial differential equations posed on a three-dimensional
representative volume element. The discretization uses Discrete Kirchhoff
Triangle elements for the macroscopic bending-plate problem on a mesh of scale
$H$, and first-order Lagrange elements for the microscopic corrector problem on
an axis-aligned mesh of scale $h$. We show that the discretized model
$\Gamma$-converges to the continuous one as $(h,H)\to 0$,provided that there
exists a microstructure mesh such that the elasticity tensor is Lipschitz
continuous on each mesh element. This extends earlier results by Rumpf et al.
(2024) to prestrained composites. Our argument does not require any rate of
convergence for the microscopic discretization error. As a corollary, we also
obtain convergence when $h \to 0$ and $H \to 0$ consecutively, and we prove
that these limit processes commute."
Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models,cs.CV,Computer Vision,2025-09-30,"Diffusion models achieve high-quality image generation but face deployment
challenges due to their high computational requirements. Although 8-bit
outlier-aware post-training quantization (PTQ) matches full-precision
performance, extending PTQ to 4 bits remains challenging. Larger step sizes in
4-bit quantization amplify rounding errors in dense, low-magnitude activations,
leading to the loss of fine-grained textures. We hypothesize that not only
outliers but also small activations are critical for texture fidelity. To this
end, we propose Quantization via Residual Truncation and Zero Suppression
(QuaRTZ), a 4-bit PTQ scheme for diffusion models. QuaRTZ applies 8-bit min-max
quantization for outlier handling and compresses to 4 bits via leading-zero
suppression to retain LSBs, thereby preserving texture details. Our approach
reduces rounding errors and improves quantization efficiency by balancing
outlier preservation and LSB precision. Both theoretical derivations and
empirical evaluations demonstrate the generalizability of QuaRTZ across diverse
activation distributions. Notably, 4-bit QuaRTZ achieves an FID of 6.98 on
FLUX.1-schnell, outperforming SVDQuant that requires auxiliary FP16 branches."
"The Grammar of FAIR: A Granular Architecture of Semantic Units for FAIR Semantics, Inspired by Biology and Linguistics",cs.DB,Unknown Category,2025-09-30,"The FAIR Principles aim to make data and knowledge Findable, Accessible,
Interoperable, and Reusable, yet current digital infrastructures often lack a
unifying semantic framework that bridges human cognition and
machine-actionability. In this paper, we introduce the Grammar of FAIR: a
granular and modular architecture for FAIR semantics built on the concept of
semantic units. Semantic units, comprising atomic statement units and composite
compound units, implement the principle of semantic modularisation, decomposing
data and knowledge into independently identifiable, semantically meaningful,
and machine-actionable units. A central metaphor guiding our approach is the
analogy between the hierarchy of level of organisation in biological systems
and the hierarchy of levels of organisation in information systems: both are
structured by granular building blocks that mediate across multiple
perspectives while preserving functional unity. Drawing further inspiration
from concept formation and natural language grammar, we show how these building
blocks map to FAIR Digitial Objects (FDOs), enabling format-agnostic semantic
transitivity from natural language token models to schema-based
representations. This dual biological-linguistic analogy provides a
semantics-first foundation for evolving cross-ecosystem infrastructures, paving
the way for the Internet of FAIR Data and Services (IFDS) and a future of
modular, AI-ready, and citation-granular scholarly communication."
Adaptive Planning for Multi-Attribute Controllable Summarization with Monte Carlo Tree Search,cs.CL,Computation and Language,2025-09-30,"Controllable summarization moves beyond generic outputs toward human-aligned
summaries guided by specified attributes. In practice, the interdependence
among attributes makes it challenging for language models to satisfy correlated
constraints consistently. Moreover, previous approaches often require
per-attribute fine-tuning, limiting flexibility across diverse summary
attributes. In this paper, we propose adaptive planning for multi-attribute
controllable summarization (PACO), a training-free framework that reframes the
task as planning the order of sequential attribute control with a customized
Monte Carlo Tree Search (MCTS). In PACO, nodes represent summaries, and actions
correspond to single-attribute adjustments, enabling progressive refinement of
only the attributes requiring further control. This strategy adaptively
discovers optimal control orders, ultimately producing summaries that
effectively meet all constraints. Extensive experiments across diverse domains
and models demonstrate that PACO achieves robust multi-attribute
controllability, surpassing both LLM-based self-planning models and fine-tuned
baselines. Remarkably, PACO with Llama-3.2-1B rivals the controllability of the
much larger Llama-3.3-70B baselines. With larger models, PACO achieves superior
control performance, outperforming all competitors."
ACT: Agentic Classification Tree,cs.LG,Machine Learning,2025-09-30,"When used in high-stakes settings, AI systems are expected to produce
decisions that are transparent, interpretable, and auditable, a requirement
increasingly expected by regulations. Decision trees such as CART provide clear
and verifiable rules, but they are restricted to structured tabular data and
cannot operate directly on unstructured inputs such as text. In practice, large
language models (LLMs) are widely used for such data, yet prompting strategies
such as chain-of-thought or prompt optimization still rely on free-form
reasoning, limiting their ability to ensure trustworthy behaviors. We present
the Agentic Classification Tree (ACT), which extends decision-tree methodology
to unstructured inputs by formulating each split as a natural-language
question, refined through impurity-based evaluation and LLM feedback via
TextGrad. Experiments on text benchmarks show that ACT matches or surpasses
prompting-based baselines while producing transparent and interpretable
decision paths."
AdaBlock-dLLM: Semantic-Aware Diffusion LLM Inference via Adaptive Block Size,cs.LG,Machine Learning,2025-09-30,"Diffusion-based large language models (dLLMs) are gaining attention for their
inherent capacity for parallel decoding, offering a compelling alternative to
autoregressive LLMs. Among various decoding strategies, blockwise
semi-autoregressive (semi-AR) approaches are widely adopted due to their
natural support for KV caching and their favorable accuracy-speed trade-off.
However, this paper identifies two fundamental limitations in the conventional
semi-AR decoding approach that applies a fixed block size: i) late decoding
overhead, where the unmasking of high-confidence tokens outside the current
block is unnecessarily delayed, and ii) premature decoding error, where
low-confidence tokens inside the current block are committed too early, leading
to incorrect tokens. This paper presents the first systematic investigation
challenging the fixed block size assumption in semi-AR decoding. Through a
statistical analysis of confidence dynamics during the denoising process, we
identify a volatility band (VB) region during dLLM decoding, which encodes
local semantic structure and can be used to guide adaptive block sizing.
Leveraging these insights, we introduce AdaBlock-dLLM, a training-free,
plug-and-play scheduler that adaptively aligns block boundaries with semantic
steps by adjusting block size during runtime. Extensive experiments across
diverse benchmarks show that AdaBlock-dLLM achieves up to 5.3% accuracy
improvement under the same throughput budget. Beyond inference-time
optimization, we hope our semantics-aware adaptive scheduling approach and
confidence-based analysis will inspire future training strategies for dLLMs."
Text-Based Approaches to Item Alignment to Content Standards in Large-Scale Reading & Writing Tests,cs.CL,Computation and Language,2025-09-30,"Aligning test items to content standards is a critical step in test
development to collect validity evidence based on content. Item alignment has
typically been conducted by human experts. This judgmental process can be
subjective and time-consuming. This study investigated the performance of
fine-tuned small language models (SLMs) for automated item alignment using data
from a large-scale standardized reading and writing test for college
admissions. Different SLMs were trained for alignment at both domain and skill
levels respectively with 10 skills mapped to 4 content domains. The model
performance was evaluated in multiple criteria on two testing datasets. The
impact of types and sizes of the input data for training was investigated.
Results showed that including more item text data led to substantially better
model performance, surpassing the improvements induced by sample size increase
alone. For comparison, supervised machine learning models were trained using
the embeddings from the multilingual-E5-large-instruct model. The study results
showed that fine-tuned SLMs consistently outperformed the embedding-based
supervised machine learning models, particularly for the more fine-grained
skill alignment. To better understand model misclassifications, multiple
semantic similarity analysis including pairwise cosine similarity,
Kullback-Leibler divergence of embedding distributions, and two-dimension
projections of item embeddings were conducted. These analyses consistently
showed that certain skills in SAT and PSAT were semantically too close,
providing evidence for the observed misclassification."
An Orthogonal Learner for Individualized Outcomes in Markov Decision Processes,stat.ML,Unknown Category,2025-09-30,"Predicting individualized potential outcomes in sequential decision-making is
central for optimizing therapeutic decisions in personalized medicine (e.g.,
which dosing sequence to give to a cancer patient). However, predicting
potential outcomes over long horizons is notoriously difficult. Existing
methods that break the curse of the horizon typically lack strong theoretical
guarantees such as orthogonality and quasi-oracle efficiency. In this paper, we
revisit the problem of predicting individualized potential outcomes in
sequential decision-making (i.e., estimating Q-functions in Markov decision
processes with observational data) through a causal inference lens. In
particular, we develop a comprehensive theoretical foundation for meta-learners
in this setting with a focus on beneficial theoretical properties. As a result,
we yield a novel meta-learner called DRQ-learner and establish that it is: (1)
doubly robust (i.e., valid inference under the misspecification of one of the
nuisances), (2) Neyman-orthogonal (i.e., insensitive to first-order estimation
errors in the nuisance functions), and (3) achieves quasi-oracle efficiency
(i.e., behaves asymptotically as if the ground-truth nuisance functions were
known). Our DRQ-learner is applicable to settings with both discrete and
continuous state spaces. Further, our DRQ-learner is flexible and can be used
together with arbitrary machine learning models (e.g., neural networks). We
validate our theoretical results through numerical experiments, thereby showing
that our meta-learner outperforms state-of-the-art baselines."
Real-time Velocity Profile Optimization for Time-Optimal Maneuvering with Generic Acceleration Constraints,cs.RO,Unknown Category,2025-09-30,"The computation of time-optimal velocity profiles along prescribed paths,
subject to generic acceleration constraints, is a crucial problem in robot
trajectory planning, with particular relevance to autonomous racing. However,
the existing methods either support arbitrary acceleration constraints at high
computational cost or use conservative box constraints for computational
efficiency. We propose FBGA, a new \underline{F}orward-\underline{B}ackward
algorithm with \underline{G}eneric \underline{A}cceleration constraints, which
achieves both high accuracy and low computation time. FBGA operates forward and
backward passes to maximize the velocity profile in short, discretized path
segments, while satisfying user-defined performance limits. Tested on five
racetracks and two vehicle classes, FBGA handles complex, non-convex
acceleration constraints with custom formulations. Its maneuvers and lap times
closely match optimal control baselines (within $0.11\%$-$0.36\%$), while being
up to three orders of magnitude faster. FBGA maintains high accuracy even with
coarse discretization, making it well-suited for online multi-query trajectory
planning. Our open-source \texttt{C++} implementation is available at:
https://anonymous.4open.science/r/FB_public_RAL."
Ascent Fails to Forget,cs.LG,Machine Learning,2025-09-30,"Contrary to common belief, we show that gradient ascent-based unconstrained
optimization methods frequently fail to perform machine unlearning, a
phenomenon we attribute to the inherent statistical dependence between the
forget and retain data sets. This dependence, which can manifest itself even as
simple correlations, undermines the misconception that these sets can be
independently manipulated during unlearning. We provide empirical and
theoretical evidence showing these methods often fail precisely due to this
overlooked relationship. For random forget sets, this dependence means that
degrading forget set metrics (which, for a retrained model, should mirror test
set metrics) inevitably harms overall test performance. Going beyond random
sets, we consider logistic regression as an instructive example where a
critical failure mode emerges: inter-set dependence causes gradient
descent-ascent iterations to progressively diverge from the ideal retrained
model. Strikingly, these methods can converge to solutions that are not only
far from the retrained ideal but are potentially even further from it than the
original model itself, rendering the unlearning process actively detrimental. A
toy example further illustrates how this dependence can trap models in inferior
local minima, inescapable via finetuning. Our findings highlight that the
presence of such statistical dependencies, even when manifest only as
correlations, can be sufficient for ascent-based unlearning to fail. Our
theoretical insights are corroborated by experiments on complex neural
networks, demonstrating that these methods do not perform as expected in
practice due to this unaddressed statistical interplay."
Improved Approximation for Broadcasting in k-cycle Graphs,cs.DS,Unknown Category,2025-09-30,"Broadcasting is an information dissemination primitive where a message
originates at a node (called the originator) and is passed to all other nodes
in the network. Broadcasting research is motivated by efficient network design
and determining the broadcast times of standard network topologies. Verifying
the broadcast time of a node $v$ in an arbitrary network $G$ is known to be
NP-hard. Additionally, recent findings show that the broadcast time problem is
also NP-complete in general cactus graphs and some highly restricted
subfamilies of cactus graphs. These graph families are structurally similar to
$k$-cycle graphs, in which the broadcast time problem is also believed to be
NP-complete. In this paper, we present a simple $(1.5-\epsilon)$-approximation
algorithm for determining the broadcast time of networks modeled using
$k$-cycle graphs, where $\epsilon > 0$ depends on the structure of the graph."
Institutional Policy Pathways for Supporting Research Software: Global Trends and Local Practices,cs.SE,Unknown Category,2025-09-30,"As research software becomes increasingly central to modern science,
research-performing organisations (RPOs) need to ensure that their investment
in people, skills and infrastructure around research software produces
sustainable and maintainable software that improves the research they perform,
which in turn improves the overall institution and its reputation and funding,
for example, by competing with peers who lack this approach. However, research
institution management and recognition of research software and its personnel
has mostly often developed in an ad hoc manner. RPO training infrastructures,
recognition and reward structures, have not developed at a sufficient rate to
support and encourage both the widespread use of research software best
practices and the long-term support for technical roles that is required. To
begin to address this fundamental problem for modern research environments,
RPOs must implement and adopt robust policies to support research software
development, use, and sustainability. Despite growing momentum from funders and
publishers around FAIR and open science principles, research
institutional-level policies specifically addressing research software remain
limited or lacking in breadth.
  This article outlines the work of the Policies in Research Organisations for
Research Software (PRO4RS) Working Group (WG), a joint initiative of the
Research Software Alliance (ReSA) and the Research Data Alliance (RDA), which
examined and advanced research software policy development across institutions
worldwide. After consideration of the rationale for institutional policies on
research software, the PRO4RS WG outputs and analysis are utilised to highlight
critical policy gaps, particularly related to consideration of research
software personnel in policy work focused on reform of research assessment."
OntoAligner Meets Knowledge Graph Embedding Aligners,cs.AI,Artificial Intelligence,2025-09-30,"Ontology Alignment (OA) is essential for enabling semantic interoperability
across heterogeneous knowledge systems. While recent advances have focused on
large language models (LLMs) for capturing contextual semantics, this work
revisits the underexplored potential of Knowledge Graph Embedding (KGE) models,
which offer scalable, structure-aware representations well-suited to
ontology-based tasks. Despite their effectiveness in link prediction, KGE
methods remain underutilized in OA, with most prior work focusing narrowly on a
few models. To address this gap, we reformulate OA as a link prediction problem
over merged ontologies represented as RDF-style triples and develop a modular
framework, integrated into the OntoAligner library, that supports 17 diverse
KGE models. The system learns embeddings from a combined ontology and aligns
entities by computing cosine similarity between their representations. We
evaluate our approach using standard metrics across seven benchmark datasets
spanning five domains: Anatomy, Biodiversity, Circular Economy, Material
Science and Engineering, and Biomedical Machine Learning. Two key findings
emerge: first, KGE models like ConvE and TransF consistently produce
high-precision alignments, outperforming traditional systems in structure-rich
and multi-relational domains; second, while their recall is moderate, this
conservatism makes KGEs well-suited for scenarios demanding high-confidence
mappings. Unlike LLM-based methods that excel at contextual reasoning, KGEs
directly preserve and exploit ontology structure, offering a complementary and
computationally efficient strategy. These results highlight the promise of
embedding-based OA and open pathways for further work on hybrid models and
adaptive strategies."
Automatic Fact-checking in English and Telugu,cs.CL,Computation and Language,2025-09-30,"False information poses a significant global challenge, and manually
verifying claims is a time-consuming and resource-intensive process. In this
research paper, we experiment with different approaches to investigate the
effectiveness of large language models (LLMs) in classifying factual claims by
their veracity and generating justifications in English and Telugu. The key
contributions of this work include the creation of a bilingual English-Telugu
dataset and the benchmarking of different veracity classification approaches
based on LLMs."
PRISM: Progressive Rain removal with Integrated State-space Modeling,cs.CV,Computer Vision,2025-09-30,"Image deraining is an essential vision technique that removes rain streaks
and water droplets, enhancing clarity for critical vision tasks like autonomous
driving. However, current single-scale models struggle with fine-grained
recovery and global consistency. To address this challenge, we propose
Progressive Rain removal with Integrated State-space Modeling (PRISM), a
progressive three-stage framework: Coarse Extraction Network (CENet), Frequency
Fusion Network (SFNet), and Refine Network (RNet). Specifically, CENet and
SFNet utilize a novel Hybrid Attention UNet (HA-UNet) for multi-scale feature
aggregation by combining channel attention with windowed spatial transformers.
Moreover, we propose Hybrid Domain Mamba (HDMamba) for SFNet to jointly model
spatial semantics and wavelet domain characteristics. Finally, RNet recovers
the fine-grained structures via an original-resolution subnetwork. Our model
learns high-frequency rain characteristics while preserving structural details
and maintaining global context, leading to improved image quality. Our method
achieves competitive results on multiple datasets against recent deraining
methods."
TrackFormers Part 2: Enhanced Transformer-Based Models for High-Energy Physics Track Reconstruction,hep-ex,Unknown Category,2025-09-30,"High-Energy Physics experiments are rapidly escalating in generated data
volume, a trend that will intensify with the upcoming High-Luminosity LHC
upgrade. This surge in data necessitates critical revisions across the data
processing pipeline, with particle track reconstruction being a prime candidate
for improvement. In our previous work, we introduced ""TrackFormers"", a
collection of Transformer-based one-shot encoder-only models that effectively
associate hits with expected tracks. In this study, we extend our earlier
efforts by incorporating loss functions that account for inter-hit
correlations, conducting detailed investigations into (various) Transformer
attention mechanisms, and a study on the reconstruction of higher-level
objects. Furthermore we discuss new datasets that allow the training on hit
level for a range of physics processes. These developments collectively aim to
boost both the accuracy, and potentially the efficiency of our tracking models,
offering a robust solution to meet the demands of next-generation high-energy
physics experiments."
An Annotation Scheme for Factuality and its Application to Parliamentary Proceedings,cs.CL,Computation and Language,2025-09-30,"Factuality assesses the extent to which a language utterance relates to
real-world information; it determines whether utterances correspond to facts,
possibilities, or imaginary situations, and as such, it is instrumental for
fact checking. Factuality is a complex notion that relies on multiple
linguistic signals, and has been studied in various disciplines.
  We present a complex, multi-faceted annotation scheme of factuality that
combines concepts from a variety of previous works. We developed the scheme for
Hebrew, but we trust that it can be adapted to other languages. We also present
a set of almost 5,000 sentences in the domain of parliamentary discourse that
we manually annotated according to this scheme. We report on inter-annotator
agreement, and experiment with various approaches to automatically predict
(some features of) the scheme, in order to extend the annotation to a large
corpus."
"Refine Drugs, Don't Complete Them: Uniform-Source Discrete Flows for Fragment-Based Drug Discovery",cs.LG,Machine Learning,2025-09-30,"We introduce InVirtuoGen, a discrete flow generative model for fragmented
SMILES for de novo and fragment-constrained generation, and
target-property/lead optimization of small molecules. The model learns to
transform a uniform source over all possible tokens into the data distribution.
Unlike masked models, its training loss accounts for predictions on all
sequence positions at every denoising step, shifting the generation paradigm
from completion to refinement, and decoupling the number of sampling steps from
the sequence length. For \textit{de novo} generation, InVirtuoGen achieves a
stronger quality-diversity pareto frontier than prior fragment-based models and
competitive performance on fragment-constrained tasks. For property and lead
optimization, we propose a hybrid scheme that combines a genetic algorithm with
a Proximal Property Optimization fine-tuning strategy adapted to discrete
flows. Our approach sets a new state-of-the-art on the Practical Molecular
Optimization benchmark, measured by top-10 AUC across tasks, and yields higher
docking scores in lead optimization than previous baselines. InVirtuoGen thus
establishes a versatile generative foundation for drug discovery, from early
hit finding to multi-objective lead optimization. We further contribute to open
science by releasing pretrained checkpoints and code, making our results fully
reproducible\footnote{https://github.com/invirtuolabs/InVirtuoGen_results}."
SeedPrints: Fingerprints Can Even Tell Which Seed Your Large Language Model Was Trained From,cs.CR,Unknown Category,2025-09-30,"Fingerprinting Large Language Models (LLMs) is essential for provenance
verification and model attribution. Existing methods typically extract post-hoc
signatures based on training dynamics, data exposure, or hyperparameters --
properties that only emerge after training begins. In contrast, we propose a
stronger and more intrinsic notion of LLM fingerprinting: SeedPrints, a method
that leverages random initialization biases as persistent, seed-dependent
identifiers present even before training. We show that untrained models exhibit
reproducible token selection biases conditioned solely on their parameters at
initialization. These biases are stable and measurable throughout training,
enabling our statistical detection method to recover a model's lineage with
high confidence. Unlike prior techniques, unreliable before convergence and
vulnerable to distribution shifts, SeedPrints remains effective across all
training stages and robust under domain shifts or parameter modifications.
Experiments on LLaMA-style and Qwen-style models show that SeedPrints achieves
seed-level distinguishability and can provide birth-to-lifecycle identity
verification akin to a biometric fingerprint. Evaluations on large-scale
pretrained models and fingerprinting benchmarks further confirm its
effectiveness under practical deployment scenarios. These results suggest that
initialization itself imprints a unique and persistent identity on neural
language models, forming a true ''Galtonian'' fingerprint."
Commmunication-Efficient and Accurate Approach for Aggregation in Federated Low-Rank Adaptation,cs.AI,Artificial Intelligence,2025-09-30,"With the rapid emergence of foundation models and the increasing need for
fine-tuning across distributed environments, Federated Low-Rank Adaptation
(FedLoRA) has recently gained significant attention. Despite enormous
potential, current FedLoRA methods face notable challenges due to inexact
updates. Existing approaches have attempted to mitigate this issue, but they
often introduce a \emph{local-global generalization gap} and incur
\emph{substantial communication overhead}, limiting their scalability and
effectiveness. To address these limitations, we propose \textbf{F}ederated
\textbf{Lo}w-\textbf{R}ank \textbf{A}ggregation with \textbf{N}early
\textbf{A}ccurate Estimation (FLoRA-NA). FLoRA-NA leverages the local LoRA
matrices on the server to estimate the aggregated matrices $\hat{A}$ and
$\hat{B}$, which are then distributed to clients for local updates. This
surrogated aggregated matrices minimizes the divergence between ideal $\nabla
\Bar{W} = \sum^{U}_{u=1}B_u A_u$ and practical updates $\nabla \hat{W} =
\hat{B}\hat{A}$ without adding communication cost beyond vanilla FedLoRA. By
doing so, FLoRA-NA achieves communication efficiency and bridges the gap
between local personalization and global generalization, addressing a key
limitation of prior personalized FedLoRA approaches. We conduct extensive
evaluations across diverse tasks, including natural language understanding,
mathematical reasoning, and code-solving ability using various foundation
models. Experimental results consistently demonstrate that FLoRA-NA achieves
state-of-the-art global performance while maintaining low communication
overhead."
Image-Difficulty-Aware Evaluation of Super-Resolution Models,cs.CV,Computer Vision,2025-09-30,"Image super-resolution models are commonly evaluated by average scores (over
some benchmark test sets), which fail to reflect the performance of these
models on images of varying difficulty and that some models generate artifacts
on certain difficult images, which is not reflected by the average scores. We
propose difficulty-aware performance evaluation procedures to better
differentiate between SISR models that produce visually different results on
some images but yield close average performance scores over the entire test
set. In particular, we propose two image-difficulty measures, the
high-frequency index and rotation-invariant edge index, to predict those test
images, where a model would yield significantly better visual results over
another model, and an evaluation method where these visual differences are
reflected on objective measures. Experimental results demonstrate the
effectiveness of the proposed image-difficulty measures and evaluation
methodology."
Are neural scaling laws leading quantum chemistry astray?,physics.chem-ph,Unknown Category,2025-09-30,"Neural scaling laws are driving the machine learning community toward
training ever-larger foundation models across domains, assuring high accuracy
and transferable representations for extrapolative tasks. We test this promise
in quantum chemistry by scaling model capacity and training data from quantum
chemical calculations. As a generalization task, we evaluate the resulting
models' predictions of the bond dissociation energy of neutral H$_2$, the
simplest possible molecule. We find that, regardless of dataset size or model
capacity, models trained only on stable structures fail dramatically to even
qualitatively reproduce the H$_2$ energy curve. Only when compressed and
stretched geometries are explicitly included in training do the predictions
roughly resemble the correct shape. Nonetheless, the largest foundation models
trained on the largest and most diverse datasets containing dissociating
diatomics exhibit serious failures on simple diatomic molecules. Most
strikingly, they cannot reproduce the trivial repulsive energy curve of two
bare protons, revealing their failure to learn the basic Coulomb's law involved
in electronic structure theory. These results suggest that scaling alone is
insufficient for building reliable quantum chemical models."
Assessment of East-West (E-W) and South-North (S-N) facing Vertical Bifacial Photovoltaic Modules for Agrivoltaics and Dual-Land Use Applications in India,eess.SY,Unknown Category,2025-09-30,"Deploying vertical bifacial PV modules can play a significant role in
agrivoltaics, fencing walls, noise barriers, building integrated photovoltaics
(BIPV), solar PV for electric vehicles, and many other applications. This
research work presents the performance comparison of vertical bifacial
photovoltaic (VBPV) modules facing East-West (E-W) and South-North (S-N)
directions. Also, the VBPV modules are compared with vertical and tilted
south-facing monofacial PV modules. Six PV modules (monofacial and bifacial)
were installed at the rooftop of IIT Bhilai academic building, Raipur
(21.16{\deg} N, 81.65{\deg} E), India, and studied for a year from May 2022 to
April 2023. The results show that the E-W facing VBPV module gives two
production peaks, one in the morning and another in the evening, as compared to
the single notable rise at midday observed for a monofacial module. From a
series of experiments, 19 days of data were collected over the one-year period
from May 2022 to April 2023, with specific inclusion of important days like
solstices and equinoxes. In addition, the energy generation results are
compared with PVsyst simulations, while also addressing the limitations of the
PVsyst simulation of vertical PV modules. E-W bifacial generation is higher
than S-N bifacial and south-facing monofacial modules from February to April.
The VBPV modules in E-W and S-N orientations present a promising opportunity
for expanding the agrivoltaics sector in tropical and sub-tropical countries,
like India. This has huge implications for addressing the sustainable
development goals by simultaneously contributing to sustainable land
management, green energy generation, energy security and water conservation in
the vast geo-climatic expanse of tropics."
Exact Bias of Linear TRNG Correctors -- Spectral Approach,cs.CR,Unknown Category,2025-09-30,"Using Fourier analysis, this paper establishes exact security bounds for
linear extractors in True Random Number Generators (TRNGs). We provide the
first near-optimal total variation security characterization by interpolating
between optimal $\ell_{\infty}$ and $\ell_2$ norm results, expressed through
code weight enumerators and input bias parameters. Our bounds improve security
assessments by an order of magnitude over previous approximations. By scanning
~20,000 codes, we reveal fundamental trade-offs between compression efficiency
and cryptographic security. For instance, we show that achieving 80 bits of
security can require sacrificing more than 50\% of the code rate when
correcting 10\% input bias. Our bounds enhance security evaluation of TRNG
post-processing schemes and quantify the inherent cost of randomness extraction
in hardware implementations."
MotionRAG: Motion Retrieval-Augmented Image-to-Video Generation,cs.CV,Computer Vision,2025-09-30,"Image-to-video generation has made remarkable progress with the advancements
in diffusion models, yet generating videos with realistic motion remains highly
challenging. This difficulty arises from the complexity of accurately modeling
motion, which involves capturing physical constraints, object interactions, and
domain-specific dynamics that are not easily generalized across diverse
scenarios. To address this, we propose MotionRAG, a retrieval-augmented
framework that enhances motion realism by adapting motion priors from relevant
reference videos through Context-Aware Motion Adaptation (CAMA). The key
technical innovations include: (i) a retrieval-based pipeline extracting
high-level motion features using video encoder and specialized resamplers to
distill semantic motion representations; (ii) an in-context learning approach
for motion adaptation implemented through a causal transformer architecture;
(iii) an attention-based motion injection adapter that seamlessly integrates
transferred motion features into pretrained video diffusion models. Extensive
experiments demonstrate that our method achieves significant improvements
across multiple domains and various base models, all with negligible
computational overhead during inference. Furthermore, our modular design
enables zero-shot generalization to new domains by simply updating the
retrieval database without retraining any components. This research enhances
the core capability of video generation systems by enabling the effective
retrieval and transfer of motion priors, facilitating the synthesis of
realistic motion dynamics."
Game-Time: Evaluating Temporal Dynamics in Spoken Language Models,eess.AS,Unknown Category,2025-09-30,"Conversational Spoken Language Models (SLMs) are emerging as a promising
paradigm for real-time speech interaction. However, their capacity of temporal
dynamics, including the ability to manage timing, tempo and simultaneous
speaking, remains a critical and unevaluated challenge for conversational
fluency. To address this gap, we introduce the Game-Time Benchmark, a framework
to systematically assess these temporal capabilities. Inspired by how humans
learn a language through language activities, Game-Time consists of basic
instruction-following tasks and advanced tasks with temporal constraints, such
as tempo adherence and synchronized responses. Our evaluation of diverse SLM
architectures reveals a clear performance disparity: while state-of-the-art
models handle basic tasks well, many contemporary systems still struggle with
fundamental instruction-following. More critically, nearly all models degrade
substantially under temporal constraints, exposing persistent weaknesses in
time awareness and full-duplex interaction. The Game-Time Benchmark provides a
foundation for guiding future research toward more temporally-aware
conversational AI. Demos and datasets are available on our project website
https://ga642381.github.io/Game-Time."
PANDA: Towards Generalist Video Anomaly Detection via Agentic AI Engineer,cs.CV,Computer Vision,2025-09-30,"Video anomaly detection (VAD) is a critical yet challenging task due to the
complex and diverse nature of real-world scenarios. Previous methods typically
rely on domain-specific training data and manual adjustments when applying to
new scenarios and unseen anomaly types, suffering from high labor costs and
limited generalization. Therefore, we aim to achieve generalist VAD, i.e.,
automatically handle any scene and any anomaly types without training data or
human involvement. In this work, we propose PANDA, an agentic AI engineer based
on MLLMs. Specifically, we achieve PANDA by comprehensively devising four key
capabilities: (1) self-adaptive scene-aware strategy planning, (2) goal-driven
heuristic reasoning, (3) tool-augmented self-reflection, and (4) self-improving
chain-of-memory. Concretely, we develop a self-adaptive scene-aware RAG
mechanism, enabling PANDA to retrieve anomaly-specific knowledge for anomaly
detection strategy planning. Next, we introduce a latent anomaly-guided
heuristic prompt strategy to enhance reasoning precision. Furthermore, PANDA
employs a progressive reflection mechanism alongside a suite of context-aware
tools to iteratively refine decision-making in complex scenarios. Finally, a
chain-of-memory mechanism enables PANDA to leverage historical experiences for
continual performance improvement. Extensive experiments demonstrate that PANDA
achieves state-of-the-art performance in multi-scenario, open-set, and complex
scenario settings without training and manual involvement, validating its
generalizable and robust anomaly detection capability. Code is released at
https://github.com/showlab/PANDA."
Efficient and Transferable Agentic Knowledge Graph RAG via Reinforcement Learning,cs.CL,Computation and Language,2025-09-30,"Knowledge-graph retrieval-augmented generation (KG-RAG) couples large
language models (LLMs) with structured, verifiable knowledge graphs (KGs) to
reduce hallucinations and expose reasoning traces. However, many KG-RAG systems
compose multiple LLM modules (e.g planning, reasoning, and responding),
inflating inference cost and binding behavior to a specific target KG. To
address this, we introduce KG-R1, an agentic KG retrieval-augmented generation
(KG-RAG) framework through reinforcement learning (RL). KG-R1 utilizes a single
agent that interacts with KGs as its environment, learning to retrieve at each
step and incorporating the retrieved information into its reasoning and
generation. The process is optimized through end-to-end RL. In controlled
experiments across Knowledge-Graph Question Answering (KGQA) benchmarks, our
method demonstrates both efficiency and transferability: Using Qwen-2.5-3B,
KG-R1 improves answer accuracy with fewer generation tokens than prior
multi-module workflow methods that use larger foundation or fine-tuned models.
Furthermore, KG-R1 enables plug and play: after training, it maintains strong
accuracy on new KGs without modification. These properties make KG-R1 a
promising KG-RAG framework for real-world deployment. Our code is publicly
available at https://github.com/Jinyeop3110/KG-R1."
MR$^2$-Bench: Going Beyond Matching to Reasoning in Multimodal Retrieval,cs.IR,Unknown Category,2025-09-30,"Multimodal retrieval is becoming a crucial component of modern AI
applications, yet its evaluation lags behind the demands of more realistic and
challenging scenarios. Existing benchmarks primarily probe surface-level
semantic correspondence (e.g., object-text matching) while failing to assess
the deeper reasoning required to capture complex relationships between visual
and textual information. To address this gap, we introduce MR$^2$-Bench, a
reasoning-intensive benchmark for multimodal retrieval. MR$^2$-Bench presents
the following critical values: 1) all tasks are reasoning-driven, going beyond
shallow matching to effectively assess models' capacity for logical, spatial,
and causal inference; 2) it features diverse multimodal data, such as natural
images, diagrams, and visual puzzles, enabling comprehensive evaluation across
content types; 3) it supports complex queries and documents containing multiple
images and covers diverse retrieval scenarios, more accurately reflecting
real-world applications. Our benchmark contains 1,309 curated queries, derived
either from manual collection and annotation or from selective consolidation of
public datasets. Despite achieving strong results on existing benchmarks,
current state-of-the-art models still struggle on MR$^2$-Bench: for example,
the leading Seed1.6-Embedding model attains a Recall@1 of 77.78 on MMEB, but
only 9.91 on MR$^2$-Bench. This substantial performance gap highlights both the
increased challenge posed by our benchmark and the pressing need for further
advances in reasoning-intensive multimodal retrieval. The dataset and
evaluation code will be made publicly available at
https://github.com/VectorSpaceLab/MR2-Bench."
MC-GNNAS-Dock: Multi-criteria GNN-based Algorithm Selection for Molecular Docking,cs.AI,Artificial Intelligence,2025-09-30,"Molecular docking is a core tool in drug discovery for predicting
ligand-target interactions. Despite the availability of diverse search-based
and machine learning approaches, no single docking algorithm consistently
dominates, as performance varies by context. To overcome this challenge,
algorithm selection frameworks such as GNNAS-Dock, built on graph neural
networks, have been proposed. This study introduces an enhanced system,
MC-GNNAS-Dock, with three key advances. First, a multi-criteria evaluation
integrates binding-pose accuracy (RMSD) with validity checks from PoseBusters,
offering a more rigorous assessment. Second, architectural refinements by
inclusion of residual connections strengthen predictive robustness. Third,
rank-aware loss functions are incorporated to sharpen rank learning. Extensive
experiments are performed on a curated dataset containing approximately 3200
protein-ligand complexes from PDBBind. MC-GNNAS-Dock demonstrates consistently
superior performance, achieving up to 5.4% (3.4%) gains under composite
criteria of RMSD below 1\AA{} (2\AA{}) with PoseBuster-validity compared to the
single best solver (SBS) Uni-Mol Docking V2."
Go with Your Gut: Scaling Confidence for Autoregressive Image Generation,cs.CV,Computer Vision,2025-09-30,"Test-time scaling (TTS) has demonstrated remarkable success in enhancing
large language models, yet its application to next-token prediction (NTP)
autoregressive (AR) image generation remains largely uncharted. Existing TTS
approaches for visual AR (VAR), which rely on frequent partial decoding and
external reward models, are ill-suited for NTP-based image generation due to
the inherent incompleteness of intermediate decoding results. To bridge this
gap, we introduce ScalingAR, the first TTS framework specifically designed for
NTP-based AR image generation that eliminates the need for early decoding or
auxiliary rewards. ScalingAR leverages token entropy as a novel signal in
visual token generation and operates at two complementary scaling levels: (i)
Profile Level, which streams a calibrated confidence state by fusing intrinsic
and conditional signals; and (ii) Policy Level, which utilizes this state to
adaptively terminate low-confidence trajectories and dynamically schedule
guidance for phase-appropriate conditioning strength. Experiments on both
general and compositional benchmarks show that ScalingAR (1) improves base
models by 12.5% on GenEval and 15.2% on TIIF-Bench, (2) efficiently reduces
visual token consumption by 62.0% while outperforming baselines, and (3)
successfully enhances robustness, mitigating performance drops by 26.0% in
challenging scenarios."
SDA-PLANNER: State-Dependency Aware Adaptive Planner for Embodied Task Planning,cs.RO,Unknown Category,2025-09-30,"Embodied task planning requires agents to produce executable actions in a
close-loop manner within the environment. With progressively improving
capabilities of LLMs in task decomposition, planning, and generalization,
current embodied task planning methods adopt LLM-based architecture.However,
existing LLM-based planners remain limited in three aspects, i.e., fixed
planning paradigms, lack of action sequence constraints, and error-agnostic. In
this work, we propose SDA-PLANNER, enabling an adaptive planning paradigm,
state-dependency aware and error-aware mechanisms for comprehensive embodied
task planning. Specifically, SDA-PLANNER introduces a State-Dependency Graph to
explicitly model action preconditions and effects, guiding the dynamic
revision. To handle execution error, it employs an error-adaptive replanning
strategy consisting of Error Backtrack and Diagnosis and Adaptive Action
SubTree Generation, which locally reconstructs the affected portion of the plan
based on the current environment state. Experiments demonstrate that
SDA-PLANNER consistently outperforms baselines in success rate and goal
completion, particularly under diverse error conditions."
Vector-Valued Reproducing Kernel Banach Spaces for Neural Networks and Operators,math.FA,Unknown Category,2025-09-30,"Recently, there has been growing interest in characterizing the function
spaces underlying neural networks. While shallow and deep scalar-valued neural
networks have been linked to scalar-valued reproducing kernel Banach spaces
(RKBS), $\R^d$-valued neural networks and neural operator models remain less
understood in the RKBS setting. To address this gap, we develop a general
definition of vector-valued RKBS (vv-RKBS), which inherently includes the
associated reproducing kernel. Our construction extends existing definitions by
avoiding restrictive assumptions such as symmetric kernel domains,
finite-dimensional output spaces, reflexivity, or separability, while still
recovering familiar properties of vector-valued reproducing kernel Hilbert
spaces (vv-RKHS). We then show that shallow $\R^d$-valued neural networks are
elements of a specific vv-RKBS, namely an instance of the integral and neural
vv-RKBS. To also explore the functional structure of neural operators, we
analyze the DeepONet and Hypernetwork architectures and demonstrate that they
too belong to an integral and neural vv-RKBS. In all cases, we establish a
Representer Theorem, showing that optimization over these function spaces
recovers the corresponding neural architectures."
Introducing Large Language Models in the Design Flow of Time Sensitive Networking,cs.NI,Unknown Category,2025-09-30,"The growing demand for real-time, safety-critical systems has significantly
increased both the adoption and complexity of Time Sensitive Networking (TSN).
Configuring an optimized TSN network is highly challenging, requiring careful
planning, design, verification, validation, and deployment. Large Language
Models (LLMs) have recently demonstrated strong capabilities in solving complex
tasks, positioning them as promising candidates for automating end-to-end TSN
deployment, referred to as TSN orchestration. This paper outlines the steps
involved in TSN orchestration and the associated challenges. To assess the
capabilities of existing LLM models, we conduct an initial proof-of-concept
case study focused on TSN configuration across multiple models. Building on
these insights, we propose an LLM-assisted orchestration framework. Unlike
prior research on LLMs in computer networks, which has concentrated on general
configuration and management, TSN-specific orchestration has not yet been
investigated. We present the building blocks for automating TSN using LLMs,
describe the proposed pipeline, and analyze opportunities and limitations for
real-world deployment. Finally, we highlight key challenges and research
directions, including the development of TSN-focused datasets, standardized
benchmark suites, and the integration of external tools such as Network
Calculus (NC) engines and simulators. This work provides the first roadmap
toward assessing the feasibility of LLM-assisted TSN orchestration."
Joint Communication and Parameter Estimation in MIMO Channels,cs.IT,Unknown Category,2025-09-30,"We study a joint communication and sensing setting comprising a transmitter,
a receiver, and a sensor, all equipped with multiple antennas. The transmitter
sends an encoded signal over the channel with the dual purpose of communicating
an information message to the receiver, and enabling the sensor to estimate a
target parameter vector by generating back-scattered signals. We assume that
the transmitter and sensor are co-located, or fully connected, giving the
latter access to the transmitted signal. The target parameter vector is
randomly drawn from a continuous distribution, yet remains fixed throughout the
transmission block. We establish the fundamental performance trade-off between
the communication and sensing tasks, captured in terms of a capacity-MSE
function. In doing so, we identify optimal coding schemes for this
multi-antenna joint communication and sensing setting. Moreover, we
particularize our result to two practically-inspired scenarios where we
showcase optimal schemes and trade-offs."
Data-to-Energy Stochastic Dynamics,cs.LG,Machine Learning,2025-09-30,"The Schr\""odinger bridge problem is concerned with finding a stochastic
dynamical system bridging two marginal distributions that minimises a certain
transportation cost. This problem, which represents a generalisation of optimal
transport to the stochastic case, has received attention due to its connections
to diffusion models and flow matching, as well as its applications in the
natural sciences. However, all existing algorithms allow to infer such dynamics
only for cases where samples from both distributions are available. In this
paper, we propose the first general method for modelling Schr\""odinger bridges
when one (or both) distributions are given by their unnormalised densities,
with no access to data samples. Our algorithm relies on a generalisation of the
iterative proportional fitting (IPF) procedure to the data-free case, inspired
by recent developments in off-policy reinforcement learning for training of
diffusion samplers. We demonstrate the efficacy of the proposed data-to-energy
IPF on synthetic problems, finding that it can successfully learn transports
between multimodal distributions. As a secondary consequence of our
reinforcement learning formulation, which assumes a fixed time discretisation
scheme for the dynamics, we find that existing data-to-data Schr\""odinger
bridge algorithms can be substantially improved by learning the diffusion
coefficient of the dynamics. Finally, we apply the newly developed algorithm to
the problem of sampling posterior distributions in latent spaces of generative
models, thus creating a data-free image-to-image translation method. Code:
https://github.com/mmacosha/d2e-stochastic-dynamics"
Robust NbN on Si-SiGe hybrid superconducting-semiconducting microwave quantum circuit,quant-ph,Unknown Category,2025-09-30,"Advancing large-scale quantum computing requires superconducting circuits
that combine long coherence times with compatibility with semiconductor
technology. We investigate niobium nitride (NbN) coplanar waveguide resonators
integrated with Si/SiGe quantum wells, creating a hybrid platform designed for
CMOS-compatible quantum hardware. Using temperature-dependent microwave
spectroscopy in the single-photon regime, we examine resonance frequency and
quality factor variations to probe the underlying loss mechanisms. Our analysis
identifies the roles of two-level systems, quasiparticles, and scattering
processes, and connects these losses to wafer properties and fabrication
methods. The devices demonstrate reproducible performance and stable operation
maintained for over two years, highlighting their robustness. These results
provide design guidelines for developing low-loss, CMOS-compatible
superconducting circuits and support progress toward resilient, scalable
architectures for quantum information processing."
Transporting Theorems about Typeability in LF Across Schematically Defined Contexts,cs.LO,Unknown Category,2025-09-30,"The dependently-typed lambda calculus LF is often used as a vehicle for
formalizing rule-based descriptions of object systems. Proving properties of
object systems encoded in this fashion requires reasoning about formulas over
LF typing judgements. An important characteristic of LF is that it supports a
higher-order abstract syntax representation of binding structure. When such an
encoding is used, the typing judgements include contexts that assign types to
bound variables and formulas must therefore allow for quantification over
contexts. The possible instantiations of such quantifiers are usually governed
by schematic descriptions that must also be made explicit for effectiveness in
reasoning. In practical reasoning tasks, it is often necessary to transport
theorems involving universal quantification over contexts satisfying one
schematic description to those satisfying another description. We provide here
a logical justification for this ability. Towards this end, we utilize the
logic $\mathcal{L}_{LF}$, which has previously been designed for formalizing
properties of LF specifications. We develop a transportation proof rule and
show it to be sound relative to the semantics of $\mathcal{L}_{LF}$. Key to
this proof rule is a notion of context schema subsumption that uses the
subordination relation between types as a means for determining the equivalence
of contexts relative to individual LF typing judgements. We discuss the
incorporation of this rule into the Adelfa proof assistant and its use in
actual reasoning examples."
TimeScope: Towards Task-Oriented Temporal Grounding In Long Videos,cs.CV,Computer Vision,2025-09-30,"Identifying key moments in long videos is essential for downstream
understanding and reasoning tasks. In this paper, we introduce a new problem,
Taskoriented Temporal Grounding ToTG, which aims to localize time intervals
containing the necessary information based on a task's natural description.
Along with the definition, we also present ToTG Bench, a comprehensive
benchmark for evaluating the performance on ToTG. ToTG is particularly
challenging for traditional approaches due to their limited generalizability
and difficulty in handling long videos. To address these challenges, we propose
TimeScope, a novel framework built upon progressive reasoning. TimeScope first
identifies a coarse-grained temporal scope in the long video that likely
contains the key moments, and then refines this scope through finegrained
moment partitioning. Additionally, we curate a highquality dataset, namely ToTG
Pile, to enhance TimeScope's ability to perform progressive temporal grounding
effectively. Extensive experiments demonstrate that TimeScope consistently
outperforms both existing temporalgrounding methods and popular MLLMs across
various settings, highlighting its effectiveness in addressing this new
challenging problem."
HANN: Homotopy auxiliary neural network for solving nonlinear algebraic equations,math.NA,Unknown Category,2025-09-30,"Solving nonlinear algebraic equations is a fundamental but challenging
problem in scientific computations and also has many applications in system
engineering. Though traditional iterative methods and modern optimization
algorithms have exerted effective roles in addressing certain specific
problems, there still exist certain weaknesses such as the initial value
sensitivity, limited accuracy and slow convergence rate, particulary without
flexible input for the neural network methods. In this paper, we propose a
homotopy auxiliary neural network (HANN) for solving nonlinear algebraic
equations which integrates the classical homotopy continuation method and
popular physics-informed neural network. Consequently, the HANN-1 has strong
learning ability and can rapidly give an acceptable solution for the problem
which outperforms some known methods, while the HANN-2 can further improve its
accuracy. Numerical results on the benchmark problems confirm that the HANN
method can effectively solve the problems of determining the total number of
solutions of a single equation, finding solutions of transcendental systems
involving the absolute value function or trigonometric function,
ill-conditioned and normal high-dimensional nonlinear systems and time-varying
nonlinear problems, for which the Python's built-in Fsolve function exhibits
significant limitations, even fails to work."
Your Agent May Misevolve: Emergent Risks in Self-evolving LLM Agents,cs.AI,Artificial Intelligence,2025-09-30,"Advances in Large Language Models (LLMs) have enabled a new class of
self-evolving agents that autonomously improve through interaction with the
environment, demonstrating strong capabilities. However, self-evolution also
introduces novel risks overlooked by current safety research. In this work, we
study the case where an agent's self-evolution deviates in unintended ways,
leading to undesirable or even harmful outcomes. We refer to this as
Misevolution. To provide a systematic investigation, we evaluate misevolution
along four key evolutionary pathways: model, memory, tool, and workflow. Our
empirical findings reveal that misevolution is a widespread risk, affecting
agents built even on top-tier LLMs (e.g., Gemini-2.5-Pro). Different emergent
risks are observed in the self-evolutionary process, such as the degradation of
safety alignment after memory accumulation, or the unintended introduction of
vulnerabilities in tool creation and reuse. To our knowledge, this is the first
study to systematically conceptualize misevolution and provide empirical
evidence of its occurrence, highlighting an urgent need for new safety
paradigms for self-evolving agents. Finally, we discuss potential mitigation
strategies to inspire further research on building safer and more trustworthy
self-evolving agents. Our code and data are available at
https://github.com/ShaoShuai0605/Misevolution . Warning: this paper includes
examples that may be offensive or harmful in nature."
LLM-Assisted Emergency Triage Benchmark: Bridging Hospital-Rich and MCI-Like Field Simulation,cs.LG,Machine Learning,2025-09-30,"Research on emergency and mass casualty incident (MCI) triage has been
limited by the absence of openly usable, reproducible benchmarks. Yet these
scenarios demand rapid identification of the patients most in need, where
accurate deterioration prediction can guide timely interventions. While the
MIMIC-IV-ED database is openly available to credentialed researchers,
transforming it into a triage-focused benchmark requires extensive
preprocessing, feature harmonization, and schema alignment -- barriers that
restrict accessibility to only highly technical users.
  We address these gaps by first introducing an open, LLM-assisted emergency
triage benchmark for deterioration prediction (ICU transfer, in-hospital
mortality). The benchmark then defines two regimes: (i) a hospital-rich setting
with vitals, labs, notes, chief complaints, and structured observations, and
(ii) an MCI-like field simulation limited to vitals, observations, and notes.
Large language models (LLMs) contributed directly to dataset construction by
(i) harmonizing noisy fields such as AVPU and breathing devices, (ii)
prioritizing clinically relevant vitals and labs, and (iii) guiding schema
alignment and efficient merging of disparate tables.
  We further provide baseline models and SHAP-based interpretability analyses,
illustrating predictive gaps between regimes and the features most critical for
triage. Together, these contributions make triage prediction research more
reproducible and accessible -- a step toward dataset democratization in
clinical AI."
SoK: Systematic analysis of adversarial threats against deep learning approaches for autonomous anomaly detection systems in SDN-IoT networks,cs.CR,Unknown Category,2025-09-30,"Integrating SDN and the IoT enhances network control and flexibility.
DL-based AAD systems improve security by enabling real-time threat detection in
SDN-IoT networks. However, these systems remain vulnerable to adversarial
attacks that manipulate input data or exploit model weaknesses, significantly
degrading detection accuracy. Existing research lacks a systematic analysis of
adversarial vulnerabilities specific to DL-based AAD systems in SDN-IoT
environments. This SoK study introduces a structured adversarial threat model
and a comprehensive taxonomy of attacks, categorising them into data, model,
and hybrid-level threats. Unlike previous studies, we systematically evaluate
white, black, and grey-box attack strategies across popular benchmark datasets.
Our findings reveal that adversarial attacks can reduce detection accuracy by
up to 48.4%, with Membership Inference causing the most significant drop. C&W
and DeepFool achieve high evasion success rates. However, adversarial training
enhances robustness, and its high computational overhead limits the real-time
deployment of SDN-IoT applications. We propose adaptive countermeasures,
including real-time adversarial mitigation, enhanced retraining mechanisms, and
explainable AI-driven security frameworks. By integrating structured threat
models, this study offers a more comprehensive approach to attack
categorisation, impact assessment, and defence evaluation than previous
research. Our work highlights critical vulnerabilities in existing DL-based AAD
models and provides practical recommendations for improving resilience,
interpretability, and computational efficiency. This study serves as a
foundational reference for researchers and practitioners seeking to enhance
DL-based AAD security in SDN-IoT networks, offering a systematic adversarial
threat model and conceptual defence evaluation based on prior empirical
studies."
How Far Do Time Series Foundation Models Paint the Landscape of Real-World Benchmarks ?,cs.AI,Artificial Intelligence,2025-09-30,"Recent evaluations of time-series foundation models (TSFMs) have emphasized
synthetic benchmarks, leaving real-world generalization less thoroughly
examined. This work proposes a novel benchmarking approach that bridges
synthetic and realistic data by extracting temporal signals from real-world
video using optical flow and curating datasets reflecting everyday temporal
dynamics. Building upon this pipeline, we introduce REAL-V-TSFM, a novel
dataset designed to capture rich and diverse time series derived from
real-world videos. Experimental results on three state-of-the-art of TSFMs
under zero-shot forecasting shows that, despite strong performance on
conventional benchmarks, these models predominantly exhibit performance
degradation on the proposed dataset, indicating limited generalizability in
these foundation models. These findings highlight the urgent need for
data-centric benchmarking and diverse model structure to advance TSFMs toward
genuine universality, while further validating the effectiveness of our
video-based time series data extraction pipeline."
EditReward: A Human-Aligned Reward Model for Instruction-Guided Image Editing,cs.CV,Computer Vision,2025-09-30,"Recently, we have witnessed great progress in image editing with natural
language instructions. Several closed-source models like GPT-Image-1, Seedream,
and Google-Nano-Banana have shown highly promising progress. However, the
open-source models are still lagging. The main bottleneck is the lack of a
reliable reward model to scale up high-quality synthetic training data. To
address this critical bottleneck, we built \mname, trained with our new
large-scale human preference dataset, meticulously annotated by trained experts
following a rigorous protocol containing over 200K preference pairs. \mname
demonstrates superior alignment with human preferences in instruction-guided
image editing tasks. Experiments show that \mname achieves state-of-the-art
human correlation on established benchmarks such as GenAI-Bench, AURORA-Bench,
ImagenHub, and our new \benchname, outperforming a wide range of VLM-as-judge
models. Furthermore, we use \mname to select a high-quality subset from the
existing noisy ShareGPT-4o-Image dataset. We train Step1X-Edit on the selected
subset, which shows significant improvement over training on the full set. This
demonstrates \mname's ability to serve as a reward model to scale up
high-quality training data for image editing. Furthermore, its strong alignment
suggests potential for advanced applications like reinforcement learning-based
post-training and test-time scaling of image editing models. \mname with its
training dataset will be released to help the community build more high-quality
image editing training datasets."
SafeBehavior: Simulating Human-Like Multistage Reasoning to Mitigate Jailbreak Attacks in Large Language Models,cs.AI,Artificial Intelligence,2025-09-30,"Large Language Models (LLMs) have achieved impressive performance across
diverse natural language processing tasks, but their growing power also
amplifies potential risks such as jailbreak attacks that circumvent built-in
safety mechanisms. Existing defenses including input paraphrasing, multi step
evaluation, and safety expert models often suffer from high computational
costs, limited generalization, or rigid workflows that fail to detect subtle
malicious intent embedded in complex contexts. Inspired by cognitive science
findings on human decision making, we propose SafeBehavior, a novel
hierarchical jailbreak defense mechanism that simulates the adaptive multistage
reasoning process of humans. SafeBehavior decomposes safety evaluation into
three stages: intention inference to detect obvious input risks, self
introspection to assess generated responses and assign confidence based
judgments, and self revision to adaptively rewrite uncertain outputs while
preserving user intent and enforcing safety constraints. We extensively
evaluate SafeBehavior against five representative jailbreak attack types
including optimization based, contextual manipulation, and prompt based attacks
and compare it with seven state of the art defense baselines. Experimental
results show that SafeBehavior significantly improves robustness and
adaptability across diverse threat scenarios, offering an efficient and human
inspired approach to safeguarding LLMs against jailbreak attempts."
Nearest matrix with multiple eigenvalues by Riemannian optimization,math.NA,Unknown Category,2025-09-30,"Given a square complex matrix $A$, we tackle the problem of finding the
nearest matrix with multiple eigenvalues or, equivalently when $A$ had distinct
eigenvalues, the nearest defective matrix. To this goal, we extend the general
framework described in [M. Gnazzo, V. Noferini, L. Nyman, F. Poloni,
\emph{Riemann-Oracle: A general-purpose Riemannian optimizer to solve nearness
problems in matrix theory}, Found. Comput. Math., To appear] and based on
variable projection and Riemannian optimization, allowing the ambient manifold
to simultaneously track left and right eigenvectors. Our method also allows us
to impose arbitrary complex-linear constraints on either the perturbation or
the perturbed matrix; this can be useful to study structured eigenvalue
condition numbers. We present numerical experiments, comparing with preexisting
algorithms."
Memory-Driven Self-Improvement for Decision Making with Large Language Models,cs.LG,Machine Learning,2025-09-30,"Large language models (LLMs) have emerged as effective action policies for
sequential decision-making (SDM) tasks due to their extensive prior knowledge.
However, this broad yet general knowledge is often insufficient for specific
decision-making tasks with limited task-related data, making it challenging to
efficiently adapt LLMs to specific SDM tasks. To address this challenge, we
propose a memory-driven self-improvement framework that combines LLM general
prior knowledge with a compact memory of domain-specific experiences. Memory
retains past interactions and associated Q-values, thereby capturing
decision-relevant knowledge that facilitates accurate value estimation and
informs the LLM prior refinement. The refined LLM prior, in turn, generates
higher-reward trajectories that further enrich memory, forming a natural
self-improvement framework where memory and LLM prior mutually reinforce each
other. Experiments show that our memory-driven approach significantly
outperforms both traditional RL and LLM-based baselines, e.g., improving
performance by over 40\% on in-distribution tasks and over 75\% when
generalized to unseen tasks in ALFWorld."
Kinodynamic Motion Planning for Mobile Robot Navigation across Inconsistent World Models,cs.RO,Unknown Category,2025-09-30,"Mobile ground robots lacking prior knowledge of an environment must rely on
sensor data to develop a model of their surroundings. In these scenarios,
consistent identification of obstacles and terrain features can be difficult
due to noise and algorithmic shortcomings, which can make it difficult for
motion planning systems to generate safe motions. One particular difficulty to
overcome is when regions of the cost map switch between being marked as
obstacles and free space through successive planning cycles. One potential
solution to this, which we refer to as Valid in Every Hypothesis (VEH), is for
the planning system to plan motions that are guaranteed to be safe through a
history of world models. Another approach is to track a history of world
models, and adjust node costs according to the potential penalty of needing to
reroute around previously hazardous areas. This work discusses three major
iterations on this idea. The first iteration, called PEH, invokes a sub-search
for every node expansion that crosses through a divergence point in the world
models. The second and third iterations, called GEH and GEGRH respectively,
defer the sub-search until after an edge expands into the goal region. GEGRH
uses an additional step to revise the graph based on divergent nodes in each
world. Initial results showed that, although PEH and GEH find more optimistic
solutions than VEH, they are unable to generate solutions in less than
one-second, which exceeds our requirements for field deployment. Analysis of
results from a field experiment in an unstructured, off-road environment on a
Clearpath Robotics Warthog UGV indicate that GEGRH finds lower cost
trajectories and has faster average planning times than VEH. Compared to
single-hypothesis (SH) search, where only the latest world model is considered,
GEGRH generates more conservative plans with a small increase in average
planning time."
FedMuon: Federated Learning with Bias-corrected LMO-based Optimization,cs.LG,Machine Learning,2025-09-30,"Recently, a new optimization method based on the linear minimization oracle
(LMO), called Muon, has been attracting increasing attention since it can train
neural networks faster than existing adaptive optimization methods, such as
Adam. In this paper, we study how Muon can be utilized in federated learning.
We first show that straightforwardly using Muon as the local optimizer of
FedAvg does not converge to the stationary point since the LMO is a biased
operator. We then propose FedMuon which can mitigate this issue. We also
analyze how solving the LMO approximately affects the convergence rate and find
that, surprisingly, FedMuon can converge for any number of Newton-Schulz
iterations, while it can converge faster as we solve the LMO more accurately.
Through experiments, we demonstrated that FedMuon can outperform the
state-of-the-art federated learning methods."
UniSage: A Unified and Post-Analysis-Aware Sampling for Microservices,cs.SE,Unknown Category,2025-09-30,"Traces and logs are essential for observability and fault diagnosis in modern
distributed systems. However, their ever-growing volume introduces substantial
storage overhead and complicates troubleshooting. Existing approaches typically
adopt a sample-before-analysis paradigm: even when guided by data heuristics,
they inevitably discard failure-related information and hinder transparency in
diagnosing system behavior. To address this, we introduce UniSage, the first
unified framework to sample both traces and logs using a post-analysis-aware
paradigm. Instead of discarding data upfront, UniSagefirst performs lightweight
and multi-modal anomaly detection and root cause analysis (RCA) on the complete
data stream. This process yields fine-grained, service-level diagnostic
insights that guide a dual-pillar sampling strategy for handling both normal
and anomalous scenarios: an analysis-guided sampler prioritizes data implicated
by RCA, while an edge-case-based sampler ensures rare but critical behaviors
are captured. Together, these pillars ensure comprehensive coverage of critical
signals without excessive redundancy. Extensive experiments demonstrate that
UniSage significantly outperforms state-of-the-art baselines. At a 2.5%
sampling rate, it captures 56.5% of critical traces and 96.25% of relevant
logs, while improving the accuracy (AC@1) of downstream root cause analysis by
42.45%. Furthermore, its efficient pipeline processes 10 minutes of telemetry
data in under 5 seconds, demonstrating its practicality for production
environments."
TrackCore-F: Deploying Transformer-Based Subatomic Particle Tracking on FPGAs,hep-ex,Unknown Category,2025-09-30,"The Transformer Machine Learning (ML) architecture has been gaining
considerable momentum in recent years. In particular, computational High-Energy
Physics tasks such as jet tagging and particle track reconstruction (tracking),
have either achieved proper solutions, or reached considerable milestones using
Transformers. On the other hand, the use of specialised hardware accelerators,
especially FPGAs, is an effective method to achieve online, or pseudo-online
latencies. The development and integration of Transformer-based ML to FPGAs is
still ongoing and the support from current tools is very limited to
non-existent. Additionally, FPGA resources present a significant constraint.
Considering the model size alone, while smaller models can be deployed
directly, larger models are to be partitioned in a meaningful and ideally,
automated way. We aim to develop methodologies and tools for monolithic, or
partitioned Transformer synthesis, specifically targeting inference. Our
primary use-case involves two machine learning model designs for tracking,
derived from the TrackFormers project. We elaborate our development approach,
present preliminary results, and provide comparisons."
Decoding the Gender Gap: Addressing Gender Stereotypes and Psychological Barriers to Empower Women in Technology,cs.CY,Unknown Category,2025-09-30,"Recently, the unequal presence of women compared to men in technology has
attracted the attention of researchers and practitioners across multiple
fields. It is time to regard this problem as a global crisis that not only
limits access to talent but also reduces the diversity of perspectives that
shape technological innovation. This article examines the psychological and
social barriers that influence this gap, as well as the interventions designed
to reduce it. Using a structured review, the findings assemble evidence on the
role of early gender stereotypes in the family and school and the continuation
of this crisis in educational and career choices, through to the psychological
challenges women face in professional settings, such as feelings of
self-undervaluation, occupational anxiety, a heightened fear of technology, and
structural limitations in educational environments. Special attention is paid
to Germany, where the technology gap is particularly evident and where multiple
national programs have been implemented to address it. The present review shows
that effective solutions require more than anti-discrimination policies: they
should include educational practices, organizational reforms, mentoring, and
psychological support. The article concludes by outlining practical and
research implications and introduces the NEURON project as a pilot
interdisciplinary initiative aimed at accelerating current empowerment efforts
and developing new programs for women in technology occupations."
AI Playing Business Games: Benchmarking Large Language Models on Managerial Decision-Making in Dynamic Simulations,cs.AI,Artificial Intelligence,2025-09-30,"The rapid advancement of LLMs sparked significant interest in their potential
to augment or automate managerial functions. One of the most recent trends in
AI benchmarking is performance of Large Language Models (LLMs) over longer time
horizons. While LLMs excel at tasks involving natural language and pattern
recognition, their capabilities in multi-step, strategic business
decision-making remain largely unexplored. Few studies demonstrated how results
can be different from benchmarks in short-term tasks, as Vending-Bench
revealed. Meanwhile, there is a shortage of alternative benchmarks for
long-term coherence. This research analyses a novel benchmark using a business
game for the decision making in business. The research contributes to the
recent literature on AI by proposing a reproducible, open-access management
simulator to the research community for LLM benchmarking. This novel framework
is used for evaluating the performance of five leading LLMs available in free
online interface: Gemini, ChatGPT, Meta AI, Mistral AI, and Grok. LLM makes
decisions for a simulated retail company. A dynamic, month-by-month management
simulation provides transparently in spreadsheet model as experimental
environment. In each of twelve months, the LLMs are provided with a structured
prompt containing a full business report from the previous period and are
tasked with making key strategic decisions: pricing, order size, marketing
budget, hiring, dismissal, loans, training expense, R&D expense, sales
forecast, income forecast The methodology is designed to compare the LLMs on
quantitative metrics: profit, revenue, and market share, and other KPIs. LLM
decisions are analyzed in their strategic coherence, adaptability to market
changes, and the rationale provided for their decisions. This approach allows
to move beyond simple performance metrics for assessment of the long-term
decision-making."
SQUARE: Semantic Query-Augmented Fusion and Efficient Batch Reranking for Training-free Zero-Shot Composed Image Retrieval,cs.CV,Computer Vision,2025-09-30,"Composed Image Retrieval (CIR) aims to retrieve target images that preserve
the visual content of a reference image while incorporating user-specified
textual modifications. Training-free zero-shot CIR (ZS-CIR) approaches, which
require no task-specific training or labeled data, are highly desirable, yet
accurately capturing user intent remains challenging. In this paper, we present
SQUARE, a novel two-stage training-free framework that leverages Multimodal
Large Language Models (MLLMs) to enhance ZS-CIR. In the Semantic
Query-Augmented Fusion (SQAF) stage, we enrich the query embedding derived from
a vision-language model (VLM) such as CLIP with MLLM-generated captions of the
target image. These captions provide high-level semantic guidance, enabling the
query to better capture the user's intent and improve global retrieval quality.
In the Efficient Batch Reranking (EBR) stage, top-ranked candidates are
presented as an image grid with visual marks to the MLLM, which performs joint
visual-semantic reasoning across all candidates. Our reranking strategy
operates in a single pass and yields more accurate rankings. Experiments show
that SQUARE, with its simplicity and effectiveness, delivers strong performance
on four standard CIR benchmarks. Notably, it maintains high performance even
with lightweight pre-trained, demonstrating its potential applicability."
TAU: A Benchmark for Cultural Sound Understanding Beyond Semantics,eess.AS,Unknown Category,2025-09-30,"Large audio-language models are advancing rapidly, yet most evaluations
emphasize speech or globally sourced sounds, overlooking culturally distinctive
cues. This gap raises a critical question: can current models generalize to
localized, non-semantic audio that communities instantly recognize but
outsiders do not? To address this, we present TAU (Taiwan Audio Understanding),
a benchmark of everyday Taiwanese ""soundmarks."" TAU is built through a pipeline
combining curated sources, human editing, and LLM-assisted question generation,
producing 702 clips and 1,794 multiple-choice items that cannot be solved by
transcripts alone. Experiments show that state-of-the-art LALMs, including
Gemini 2.5 and Qwen2-Audio, perform far below local humans. TAU demonstrates
the need for localized benchmarks to reveal cultural blind spots, guide more
equitable multimodal evaluation, and ensure models serve communities beyond the
global mainstream."
Fast-dLLM v2: Efficient Block-Diffusion LLM,cs.CL,Computation and Language,2025-09-30,"Autoregressive (AR) large language models (LLMs) have achieved remarkable
performance across a wide range of natural language tasks, yet their inherent
sequential decoding limits inference efficiency. In this work, we propose
Fast-dLLM v2, a carefully designed block diffusion language model (dLLM) that
efficiently adapts pretrained AR models into dLLMs for parallel text
generation, requiring only approximately 1B tokens of fine-tuning. This
represents a 500x reduction in training data compared to full-attention
diffusion LLMs such as Dream (580B tokens), while preserving the original
model's performance. Our approach introduces a novel training recipe that
combines a block diffusion mechanism with a complementary attention mask,
enabling blockwise bidirectional context modeling without sacrificing AR
training objectives. To further accelerate decoding, we design a hierarchical
caching mechanism: a block-level cache that stores historical context
representations across blocks, and a sub-block cache that enables efficient
parallel generation within partially decoded blocks. Coupled with our parallel
decoding pipeline, Fast-dLLM v2 achieves up to 2.5x speedup over standard AR
decoding without compromising generation quality. Extensive experiments across
diverse benchmarks demonstrate that Fast-dLLM v2 matches or surpasses AR
baselines in accuracy, while delivering state-of-the-art efficiency among dLLMs
- marking a significant step toward the practical deployment of fast and
accurate LLMs. Code and model will be publicly released."
A Generalized Information Bottleneck Theory of Deep Learning,cs.LG,Machine Learning,2025-09-30,"The Information Bottleneck (IB) principle offers a compelling theoretical
framework to understand how neural networks (NNs) learn. However, its practical
utility has been constrained by unresolved theoretical ambiguities and
significant challenges in accurate estimation. In this paper, we present a
\textit{Generalized Information Bottleneck (GIB)} framework that reformulates
the original IB principle through the lens of synergy, i.e., the information
obtainable only through joint processing of features. We provide theoretical
and empirical evidence demonstrating that synergistic functions achieve
superior generalization compared to their non-synergistic counterparts.
Building on these foundations we re-formulate the IB using a computable
definition of synergy based on the average interaction information (II) of each
feature with those remaining. We demonstrate that the original IB objective is
upper bounded by our GIB in the case of perfect estimation, ensuring
compatibility with existing IB theory while addressing its limitations. Our
experimental results demonstrate that GIB consistently exhibits compression
phases across a wide range of architectures (including those with \textit{ReLU}
activations where the standard IB fails), while yielding interpretable dynamics
in both CNNs and Transformers and aligning more closely with our understanding
of adversarial robustness."
Continuous Space-Time Video Super-Resolution with 3D Fourier Fields,cs.CV,Computer Vision,2025-09-30,"We introduce a novel formulation for continuous space-time video
super-resolution. Instead of decoupling the representation of a video sequence
into separate spatial and temporal components and relying on brittle, explicit
frame warping for motion compensation, we encode video as a continuous,
spatio-temporally coherent 3D Video Fourier Field (VFF). That representation
offers three key advantages: (1) it enables cheap, flexible sampling at
arbitrary locations in space and time; (2) it is able to simultaneously capture
fine spatial detail and smooth temporal dynamics; and (3) it offers the
possibility to include an analytical, Gaussian point spread function in the
sampling to ensure aliasing-free reconstruction at arbitrary scale. The
coefficients of the proposed, Fourier-like sinusoidal basis are predicted with
a neural encoder with a large spatio-temporal receptive field, conditioned on
the low-resolution input video. Through extensive experiments, we show that our
joint modeling substantially improves both spatial and temporal
super-resolution and sets a new state of the art for multiple benchmarks:
across a wide range of upscaling factors, it delivers sharper and temporally
more consistent reconstructions than existing baselines, while being
computationally more efficient. Project page: https://v3vsr.github.io."
LLM-MCoX: Large Language Model-based Multi-robot Coordinated Exploration and Search,cs.RO,Unknown Category,2025-09-30,"Autonomous exploration and object search in unknown indoor environments
remain challenging for multi-robot systems (MRS). Traditional approaches often
rely on greedy frontier assignment strategies with limited inter-robot
coordination. In this work, we introduce LLM-MCoX (LLM-based Multi-robot
Coordinated Exploration and Search), a novel framework that leverages Large
Language Models (LLMs) for intelligent coordination of both homogeneous and
heterogeneous robot teams tasked with efficient exploration and target object
search. Our approach combines real-time LiDAR scan processing for frontier
cluster extraction and doorway detection with multimodal LLM reasoning (e.g.,
GPT-4o) to generate coordinated waypoint assignments based on shared
environment maps and robot states. LLM-MCoX demonstrates superior performance
compared to existing methods, including greedy and Voronoi-based planners,
achieving 22.7% faster exploration times and 50% improved search efficiency in
large environments with 6 robots. Notably, LLM-MCoX enables natural
language-based object search capabilities, allowing human operators to provide
high-level semantic guidance that traditional algorithms cannot interpret."
ACE: Adapting sampling for Counterfactual Explanations,cs.LG,Machine Learning,2025-09-30,"Counterfactual Explanations (CFEs) interpret machine learning models by
identifying the smallest change to input features needed to change the model's
prediction to a desired output. For classification tasks, CFEs determine how
close a given sample is to the decision boundary of a trained classifier.
Existing methods are often sample-inefficient, requiring numerous evaluations
of a black-box model -- an approach that is both costly and impractical when
access to the model is limited. We propose Adaptive sampling for Counterfactual
Explanations (ACE), a sample-efficient algorithm combining Bayesian estimation
and stochastic optimization to approximate the decision boundary with fewer
queries. By prioritizing informative points, ACE minimizes evaluations while
generating accurate and feasible CFEs. Extensive empirical results show that
ACE achieves superior evaluation efficiency compared to state-of-the-art
methods, while maintaining effectiveness in identifying minimal and actionable
changes."
A Review on Single-Problem Multi-Attempt Heuristic Optimization,cs.LG,Machine Learning,2025-09-30,"In certain real-world optimization scenarios, practitioners are not
interested in solving multiple problems but rather in finding the best solution
to a single, specific problem. When the computational budget is large relative
to the cost of evaluating a candidate solution, multiple heuristic alternatives
can be tried to solve the same given problem, each possibly with a different
algorithm, parameter configuration, initialization, or stopping criterion. The
sequential selection of which alternative to try next is crucial for
efficiently identifying the one that provides the best possible solution across
multiple attempts. Despite the relevance of this problem in practice, it has
not yet been the exclusive focus of any existing review. Several sequential
alternative selection strategies have been proposed in different research
topics, but they have not been comprehensively and systematically unified under
a common perspective.
  This work presents a focused review of single-problem multi-attempt heuristic
optimization. It brings together suitable strategies to this problem that have
been studied separately through algorithm selection, parameter tuning,
multi-start and resource allocation. These strategies are explained using a
unified terminology within a common framework, which supports the development
of a taxonomy for systematically organizing and classifying them."
Latent Thinking Optimization: Your Latent Reasoning Language Model Secretly Encodes Reward Signals in its Latent Thoughts,cs.CL,Computation and Language,2025-09-30,"Large Language Models (LLMs) excel at problem solving by generating chain of
thoughts in natural language, but such verbal thinking is computationally
costly and prone to overthinking. Recent work instead proposes a latent
thinking architecture Huggin-3.5B, which represents intermediate reasoning
steps as sequence of latent representations. However, latent thoughts lack
interpretability and are difficult to supervise, raising concerns about the
correctness and reliability of its latent thinking processes. In this paper, we
provide a systematic study of how Huggin-3.5B thinks in the latent space and
how external supervision signals can improve its latent thinking processes. We
show that latent thoughts leading to correct versus incorrect answers exhibit
highly distinguishable patterns, and that a latent classifier can reliably
predict answer correctness directly from latent thoughts. Leveraging these
insights, we propose Latent Thinking Optimization (LTO), a probabilistic
algorithm that employs the latent classifier as a Latent Reward Model (LRM) to
optimize the latent thinking processes. Extensive experiments across diverse
reasoning tasks demonstrate that LRM is highly effective in detecting incorrect
latent thinking patterns, and LTO can significantly improve the latent thinking
processes. Furthermore, we show that LRM can generalize across diverse domains,
and LTO can be seamlessly applied to general LLMs to improve their thinking
processes. In contrast to verbal thinking, our method demonstrates that reward
modeling and scaling test-time thinking with supervision can be performed
directly in the latent space, highlighting its potential as a general,
efficient, and domain-agnostic approach to improving the thinking processes of
LLMs."
One-Token Rollout: Guiding Supervised Fine-Tuning of LLMs with Policy Gradient,cs.CL,Computation and Language,2025-09-30,"Supervised fine-tuning (SFT) is the predominant method for adapting large
language models (LLMs), yet it often struggles with generalization compared to
reinforcement learning (RL). In this work, we posit that this performance
disparity stems not just from the loss function, but from a more fundamental
difference: SFT learns from a fixed, pre-collected dataset, whereas RL utilizes
on-policy data sampled from the current policy. Building on this hypothesis, we
introduce one-token rollout (OTR), a novel fine-tuning algorithm that guides
SFT with the policy gradient method. OTR reframes the autoregressive learning
process by treating each token generation as a single-step reinforcement
learning trajectory. At each step, it performs a Monte Carlo ``rollout'' by
sampling multiple candidate tokens from the current policy's distribution. The
ground-truth token from the supervised data is then used to provide a reward
signal to these samples. Guided by policy gradient, our algorithm repurposes
static, off-policy supervised data into a dynamic, on-policy signal at the
token level, capturing the generalization benefits of on-policy learning while
bypassing the costly overhead of full sentence generation. Through extensive
experiments on a diverse suite of challenging benchmarks spanning mathematical
reasoning, code generation, and general domain reasoning, we demonstrate that
OTR consistently outperforms standard SFT. Our findings establish OTR as a
powerful and practical alternative for fine-tuning LLMs and provide compelling
evidence that the on-policy nature of data is a critical driver of
generalization, offering a promising new direction for fine-tuning LLMs."
Ultra-Reliable Risk-Aggregated Sum Rate Maximization via Model-Aided Deep Learning,eess.SP,Unknown Category,2025-09-30,"We consider the problem of maximizing weighted sum rate in a multiple-input
single-output (MISO) downlink wireless network with emphasis on user rate
reliability. We introduce a novel risk-aggregated formulation of the complex
WSR maximization problem, which utilizes the Conditional Value-at-Risk (CVaR)
as a functional for enforcing rate (ultra)-reliability over channel fading
uncertainty/risk. We establish a WMMSE-like equivalence between the proposed
precoding problem and a weighted risk-averse MSE problem, enabling us to design
a tailored unfolded graph neural network (GNN) policy function approximation
(PFA), named {\alpha}-Robust Graph Neural Network ({\alpha}RGNN), trained to
maximize lower-tail (CVaR) rates resulting from adverse wireless channel
realizations (e.g., deep fading, attenuation). We empirically demonstrate that
a trained {\alpha}RGNN fully eliminates per user deep rate fades, and
substantially and optimally reduces statistical user rate variability while
retaining adequate ergodic performance."
Strong random unitaries and fast scrambling,quant-ph,Unknown Category,2025-09-30,"Understanding how fast physical systems can resemble Haar-random unitaries is
a fundamental question in physics. Many experiments of interest in quantum
gravity and many-body physics, including the butterfly effect in quantum
information scrambling and the Hayden-Preskill thought experiment, involve
queries to a random unitary $U$ alongside its inverse $U^\dagger$, conjugate
$U^*$, and transpose $U^T$. However, conventional notions of approximate
unitary designs and pseudorandom unitaries (PRUs) fail to capture these
experiments. In this work, we introduce and construct strong unitary designs
and strong PRUs that remain robust under all such queries. Our constructions
achieve the optimal circuit depth of $O(\log n)$ for systems of $n$ qubits. We
further show that strong unitary designs can form in circuit depth $O(\log^2
n)$ in circuits composed of independent two-qubit Haar-random gates, and that
strong PRUs can form in circuit depth $\text{poly}(\log n)$ in circuits with no
ancilla qubits. Our results provide an operational proof of the fast scrambling
conjecture from black hole physics: every observable feature of the fastest
scrambling quantum systems reproduces Haar-random behavior at logarithmic
times."
"Anomaly detection for generic failure monitoring in robotic assembly, screwing and manipulation",cs.RO,Unknown Category,2025-09-30,"Out-of-distribution states in robot manipulation often lead to unpredictable
robot behavior or task failure, limiting success rates and increasing risk of
damage. Anomaly detection (AD) can identify deviations from expected patterns
in data, which can be used to trigger failsafe behaviors and recovery
strategies. Prior work has applied data-driven AD to time series data in
specific robotic tasks, but its transferability across control strategies and
task types has not been shown. Leveraging time series data, such as
force/torque signals, allows to directly capture robot-environment
interactions, crucial for manipulation and online failure detection. Their
broad availability, high sampling rates, and low dimensionality enable high
temporal resolution and efficient processing. As robotic tasks can have widely
signal characteristics and requirements, AD methods which can be applied in the
same way to a wide range of tasks is needed, ideally with good data efficiency.
We examine three industrial robotic tasks, each presenting several anomalies.
Test scenarios in robotic cabling, screwing, and sanding are built, and
multimodal time series data is gathered. Several autoencoder-based methods are
compared, evaluating generalization across tasks and control methods (diffusion
policy, position, and impedance control). This allows us to validate the
integration of AD in complex tasks involving tighter tolerances and variation
from both the robot and its environment. Additionally, we evaluate data
efficiency, detection latency, and task characteristics which support robust
detection. The results indicate reliable detection with AUROC exceeding 0.93 in
failures in the cabling and screwing task, such as incorrect or misaligned
parts and obstructed targets. In the polishing task, only severe failures were
reliably detected, while more subtle failure types remained undetected."
Attribution-Guided Decoding,cs.LG,Machine Learning,2025-09-30,"The capacity of Large Language Models (LLMs) to follow complex instructions
and generate factually accurate text is critical for their real-world
application. However, standard decoding methods often fail to robustly satisfy
these requirements, while existing control techniques frequently degrade
general output quality. In this work, we introduce Attribution-Guided Decoding
(AGD), an interpretability-based decoding strategy. Instead of directly
manipulating model activations, AGD considers a set of high-probability output
token candidates and selects the one that exhibits the highest attribution to a
user-defined Region of Interest (ROI). This ROI can be flexibly defined over
different parts of the model's input or internal components, allowing AGD to
steer generation towards various desirable behaviors. We demonstrate AGD's
efficacy across three challenging domains. For instruction following, we show
that AGD significantly boosts adherence (e.g., improving the overall success
rate on Llama 3.1 from 66.0% to 79.1%). For knowledge-intensive tasks, we show
that guiding generation towards usage of internal knowledge components or
contextual sources can reduce hallucinations and improve factual accuracy in
both closed-book and open-book settings. Furthermore, we propose an adaptive,
entropy-based variant of AGD that mitigates quality degradation and reduces
computational overhead by applying guidance only when the model is uncertain.
Our work presents a versatile, more interpretable, and effective method for
enhancing the reliability of modern LLMs."
Interactive Learning for LLM Reasoning,cs.AI,Artificial Intelligence,2025-09-30,"Existing multi-agent learning approaches have developed interactive training
environments to explicitly promote collaboration among multiple Large Language
Models (LLMs), thereby constructing stronger multi-agent systems (MAS).
However, during inference, they require re-executing the MAS to obtain final
solutions, which diverges from human cognition that individuals can enhance
their reasoning capabilities through interactions with others and resolve
questions independently in the future. To investigate whether multi-agent
interaction can enhance LLMs' independent problem-solving ability, we introduce
ILR, a novel co-learning framework for MAS that integrates two key components:
Dynamic Interaction and Perception Calibration. Specifically, Dynamic
Interaction first adaptively selects either cooperative or competitive
strategies depending on question difficulty and model ability. LLMs then
exchange information through Idea3 (Idea Sharing, Idea Analysis, and Idea
Fusion), an innovative interaction paradigm designed to mimic human discussion,
before deriving their respective final answers. In Perception Calibration, ILR
employs Group Relative Policy Optimization (GRPO) to train LLMs while
integrating one LLM's reward distribution characteristics into another's reward
function, thereby enhancing the cohesion of multi-agent interactions. We
validate ILR on three LLMs across two model families of varying scales,
evaluating performance on five mathematical benchmarks and one coding
benchmark. Experimental results show that ILR consistently outperforms
single-agent learning, yielding an improvement of up to 5% over the strongest
baseline. We further discover that Idea3 can enhance the robustness of stronger
LLMs during multi-agent inference, and dynamic interaction types can boost
multi-agent learning compared to pure cooperative or competitive strategies."
Feedback Forensics: A Toolkit to Measure AI Personality,cs.CL,Computation and Language,2025-09-30,"Some traits making a ""good"" AI model are hard to describe upfront. For
example, should responses be more polite or more casual? Such traits are
sometimes summarized as model character or personality. Without a clear
objective, conventional benchmarks based on automatic validation struggle to
measure such traits. Evaluation methods using human feedback such as Chatbot
Arena have emerged as a popular alternative. These methods infer ""better""
personality and other desirable traits implicitly by ranking multiple model
responses relative to each other. Recent issues with model releases highlight
limitations of these existing opaque evaluation approaches: a major model was
rolled back over sycophantic personality issues, models were observed
overfitting to such feedback-based leaderboards. Despite these known issues,
limited public tooling exists to explicitly evaluate model personality. We
introduce Feedback Forensics: an open-source toolkit to track AI personality
changes, both those encouraged by human (or AI) feedback, and those exhibited
across AI models trained and evaluated on such feedback. Leveraging AI
annotators, our toolkit enables investigating personality via Python API and
browser app. We demonstrate the toolkit's usefulness in two steps: (A) first we
analyse the personality traits encouraged in popular human feedback datasets
including Chatbot Arena, MultiPref and PRISM; and (B) then use our toolkit to
analyse how much popular models exhibit such traits. We release (1) our
Feedback Forensics toolkit alongside (2) a web app tracking AI personality in
popular models and feedback datasets as well as (3) the underlying annotation
data at https://github.com/rdnfn/feedback-forensics."
QUARTZ : QA-based Unsupervised Abstractive Refinement for Task-oriented Dialogue Summarization,cs.CL,Computation and Language,2025-09-30,"Dialogue summarization aims to distill the core meaning of a conversation
into a concise text. This is crucial for reducing the complexity and noise
inherent in dialogue-heavy applications. While recent approaches typically
train language models to mimic human-written summaries, such supervision is
costly and often results in outputs that lack task-specific focus limiting
their effectiveness in downstream applications, such as medical tasks. In this
paper, we propose \app, a framework for task-oriented utility-based dialogue
summarization. \app starts by generating multiple summaries and task-oriented
question-answer pairs from a dialogue in a zero-shot manner using a pool of
large language models (LLMs). The quality of the generated summaries is
evaluated by having LLMs answer task-related questions before \textit{(i)}
selecting the best candidate answers and \textit{(ii)} identifying the most
informative summary based on these answers. Finally, we fine-tune the best LLM
on the selected summaries. When validated on multiple datasets, \app
demonstrates its effectiveness by achieving competitive results in various
zero-shot settings, rivaling fully-supervised State-of-the-Art (SotA) methods."
NeuroTTT: Bridging Pretraining-Downstream Task Misalignment in EEG Foundation Models via Test-Time Training,cs.LG,Machine Learning,2025-09-30,"Large-scale foundation models for EEG signals offer a promising path to
generalizable brain-computer interface (BCI) applications, but they often
suffer from misalignment between pretraining objectives and downstream tasks,
as well as significant cross-subject distribution shifts. This paper addresses
these challenges by introducing a two-stage alignment strategy that bridges the
gap between generic pretraining and specific EEG decoding tasks. First, we
propose NeuroTTT: a domain-specific self-supervised fine-tuning paradigm that
augments the foundation model with task-relevant self-supervised objectives,
aligning latent representations to important spectral, spatial, and temporal
EEG features without requiring additional labeled data. Second, we incorporate
test-time training (TTT) at inference, we perform (i) self-supervised test-time
training on individual unlabeled test samples and (ii) prediction entropy
minimization (Tent), which updates only normalization statistics to continually
calibrate the model to each new input on the fly. Our approach, which, to our
knowledge, is the first to unify domain-tuned self-supervision with test-time
training in large-scale EEG foundation models, yields substantially improved
robustness and accuracy across diverse BCI tasks (imagined speech, stress
detection, motor imagery). Using CBraMod and LaBraM as backbones, our method
pushes their performance to a markedly higher level. Results on three diverse
tasks demonstrate that the proposed alignment strategy achieves
state-of-the-art performance, outperforming conventional fine-tuning and
adaptation methods. Our code is available at
https://github.com/wsl2000/NeuroTTT."
Tuning the Tuner: Introducing Hyperparameter Optimization for Auto-Tuning,cs.LG,Machine Learning,2025-09-30,"Automatic performance tuning (auto-tuning) is widely used to optimize
performance-critical applications across many scientific domains by finding the
best program variant among many choices. Efficient optimization algorithms are
crucial for navigating the vast and complex search spaces in auto-tuning. As is
well known in the context of machine learning and similar fields,
hyperparameters critically shape optimization algorithm efficiency. Yet for
auto-tuning frameworks, these hyperparameters are almost never tuned, and their
potential performance impact has not been studied.
  We present a novel method for general hyperparameter tuning of optimization
algorithms for auto-tuning, thus ""tuning the tuner"". In particular, we propose
a robust statistical method for evaluating hyperparameter performance across
search spaces, publish a FAIR data set and software for reproducibility, and
present a simulation mode that replays previously recorded tuning data,
lowering the costs of hyperparameter tuning by two orders of magnitude. We show
that even limited hyperparameter tuning can improve auto-tuner performance by
94.8% on average, and establish that the hyperparameters themselves can be
optimized efficiently with meta-strategies (with an average improvement of
204.7%), demonstrating the often overlooked hyperparameter tuning as a powerful
technique for advancing auto-tuning research and practice."
Noise-Guided Transport for Imitation Learning,cs.LG,Machine Learning,2025-09-30,"We consider imitation learning in the low-data regime, where only a limited
number of expert demonstrations are available. In this setting, methods that
rely on large-scale pretraining or high-capacity architectures can be difficult
to apply, and efficiency with respect to demonstration data becomes critical.
We introduce Noise-Guided Transport (NGT), a lightweight off-policy method that
casts imitation as an optimal transport problem solved via adversarial
training. NGT requires no pretraining or specialized architectures,
incorporates uncertainty estimation by design, and is easy to implement and
tune. Despite its simplicity, NGT achieves strong performance on challenging
continuous control tasks, including high-dimensional Humanoid tasks, under
ultra-low data regimes with as few as 20 transitions. Code is publicly
available at: https://github.com/lionelblonde/ngt-pytorch."
Reservoir computing based predictive reduced order model for steel grade intermixing in an industrial continuous casting tundish,physics.flu-dyn,Unknown Category,2025-09-30,"Continuous casting is a widely adopted process in the steel industry, where
maintaining high steel quality is paramount. Efficient prediction of grade
intermixing during ladle changeover operations is critical for maintaining
steel quality and minimizing material losses in the continuous casting process.
Among various factors influencing grade intermixing, operating parameters play
a significant role, in addition to tundish geometry and flow control devices.
In this study, three-dimensional, transient, two-phase turbulent flow
simulations are conducted to investigate the ladle changeover operation. During
this process, the molten steel level in the tundish typically varies over time,
significantly affecting the grade intermixing phenomena. The influence of ladle
change time on intermixing time has been presented. However, high-fidelity
full-order simulations of such complex transient phenomena are computationally
expensive and are impractical for real-time monitoring or design-space
exploration in industrial-scale applications. To address this issue, a reduced
order modelling approach based on proper orthogonal decomposition (POD) and
reservoir computing (RC) is employed to efficiently predict intermixing time.
The proposed reduced order model (ROM) demonstrates excellent predictive
accuracy using limited training data while requiring significantly less
computational resources and training time. The results demonstrate the
potential of the proposed methodology as a fast, reliable tool for real-time
process monitoring and optimization in industrial continuous casting
operations."
Representation-Based Data Quality Audits for Audio,cs.SD,Unknown Category,2025-09-30,"Data quality issues such as off-topic samples, near duplicates, and label
errors often limit the performance of audio-based systems. This paper addresses
these issues by adapting SelfClean, a representation-to-rank data auditing
framework, from the image to the audio domain. This approach leverages
self-supervised audio representations to identify common data quality issues,
creating ranked review lists that surface distinct issues within a single,
unified process. The method is benchmarked on the ESC-50, GTZAN, and a
proprietary industrial dataset, using both synthetic and naturally occurring
corruptions. The results demonstrate that this framework achieves
state-of-the-art ranking performance, often outperforming issue-specific
baselines and enabling significant annotation savings by efficiently guiding
human review."
Error bounds for perspective cones of a class of nonnegative Legendre functions,math.OC,Unknown Category,2025-09-30,"Error bounds play a central role in the study of conic optimization problems,
including the analysis of convergence rates for numerous algorithms. Curiously,
those error bounds are often H\""olderian with exponent 1/2. In this paper, we
try to explain the prevalence of the 1/2 exponent by investigating generic
properties of error bounds for conic feasibility problems where the underlying
cone is a perspective cone constructed from a nonnegative Legendre function on
$\mathbb{R}$. Our analysis relies on the facial reduction technique and the
computation of one-step facial residual functions (1-FRFs). Specifically, under
appropriate assumptions on the Legendre function, we show that 1-FRFs can be
taken to be H\""olderian of exponent 1/2 almost everywhere with respect to the
two-dimensional Hausdorff measure. This enables us to further establish that
having a uniform H\""olderian error bound with exponent 1/2 is a generic
property for a class of feasibility problems involving these cones."
FLOWER: A Flow-Matching Solver for Inverse Problems,cs.CV,Computer Vision,2025-09-30,"We introduce Flower, a solver for inverse problems. It leverages a
pre-trained flow model to produce reconstructions that are consistent with the
observed measurements. Flower operates through an iterative procedure over
three steps: (i) a flow-consistent destination estimation, where the velocity
network predicts a denoised target; (ii) a refinement step that projects the
estimated destination onto a feasible set defined by the forward operator; and
(iii) a time-progression step that re-projects the refined destination along
the flow trajectory. We provide a theoretical analysis that demonstrates how
Flower approximates Bayesian posterior sampling, thereby unifying perspectives
from plug-and-play methods and generative inverse solvers. On the practical
side, Flower achieves state-of-the-art reconstruction quality while using
nearly identical hyperparameters across various inverse problems."
A robust computational framework for the mixture-energy-consistent six-equation two-phase model with instantaneous mechanical relaxation terms,math.NA,Unknown Category,2025-09-30,"We present a robust computational framework for the numerical solution of a
hyperbolic 6-equation single-velocity two-phase model. The model's main
interest is that, when combined with instantaneous mechanical relaxation, it
recovers the solution of the 5-equation model of Kapila. Several numerical
methods based on this strategy have been developed over the years. However,
neither the 5- nor 6-equation model admits a complete set of jump conditions
because they involve non-conservative products. Different discretizations of
these terms in the 6-equation model exist. The precise impact of these
discretizations on the numerical solutions of the 5-equation model, in
particular for shocks, is still an open question to which this work provides
new insights. We consider the phasic total energies as prognostic variables to
naturally enforce discrete conservation of total energy and compare the
accuracy and robustness of different discretizations for the hyperbolic
operator. Namely, we discuss the construction of an HLLC approximate Riemann
solver in relation to jump conditions. We then compare an HLLC wave-propagation
scheme which includes the non-conservative terms, with Rusanov and HLLC solvers
for the conservative part in combination with suitable approaches for the
non-conservative terms. We show that some approaches for the discretization of
non-conservative terms fit within the framework of path-conservative schemes
for hyperbolic problems. We then analyze the use of various numerical
strategies on several relevant test cases, showing both the impact of the
theoretical shortcomings of the models as well as the importance of the choice
of a robust framework for the global numerical strategy."
Reframing Generative Models for Physical Systems using Stochastic Interpolants,cs.LG,Machine Learning,2025-09-30,"Generative models have recently emerged as powerful surrogates for physical
systems, demonstrating increased accuracy, stability, and/or statistical
fidelity. Most approaches rely on iteratively denoising a Gaussian, a choice
that may not be the most effective for autoregressive prediction tasks in PDEs
and dynamical systems such as climate. In this work, we benchmark generative
models across diverse physical domains and tasks, and highlight the role of
stochastic interpolants. By directly learning a stochastic process between
current and future states, stochastic interpolants can leverage the proximity
of successive physical distributions. This allows for generative models that
can use fewer sampling steps and produce more accurate predictions than models
relying on transporting Gaussian noise. Our experiments suggest that generative
models need to balance deterministic accuracy, spectral consistency, and
probabilistic calibration, and that stochastic interpolants can potentially
fulfill these requirements by adjusting their sampling. This study establishes
stochastic interpolants as a competitive baseline for physical emulation and
gives insight into the abilities of different generative modeling frameworks."
